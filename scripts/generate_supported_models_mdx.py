#!/usr/bin/env python3
"""
THIS SCRIPT IS AUTOGENERATED WITH CURSOR.

Script to generate a static MDX file for supported models with cost tracking.
This script reads the model_prices_and_context_window.json file and generates
a static markdown documentation page listing all supported models by provider.
"""

import json
import os
from collections import defaultdict
from typing import Dict, List, Any

# Mapping from litellm_provider names to Opik provider names
PROVIDER_MAPPING = {
    "openai": "openai",
    "vertex_ai-language-models": "google_vertexai",
    "gemini": "google_ai",
    "anthropic": "anthropic",
    "vertex_ai-anthropic_models": "anthropic_vertexai",
    "bedrock": "bedrock",
    "bedrock_converse": "bedrock"
}

# Provider display names and descriptions
PROVIDER_INFO = {
    "openai": {
        "name": "OpenAI",
        "description": "Models hosted by OpenAI",
        "url": "https://platform.openai.com"
    },
    "google_vertexai": {
        "name": "Google Vertex AI", 
        "description": "Gemini models hosted in Google Vertex AI",
        "url": "https://cloud.google.com/vertex-ai"
    },
    "google_ai": {
        "name": "Google AI",
        "description": "Gemini models hosted in Google AI Studio", 
        "url": "https://ai.google.dev/aistudio"
    },
    "anthropic": {
        "name": "Anthropic",
        "description": "Anthropic models hosted by Anthropic",
        "url": "https://www.anthropic.com"
    },
    "anthropic_vertexai": {
        "name": "Anthropic on Vertex AI",
        "description": "Anthropic models hosted in Google Vertex AI",
        "url": "https://cloud.google.com/vertex-ai"
    },
    "bedrock": {
        "name": "AWS Bedrock",
        "description": "Models hosted by AWS Bedrock", 
        "url": "https://aws.amazon.com/bedrock"
    }
}



def process_model_data(json_file_path: str) -> Dict[str, Any]:
    """Process the JSON file and extract supported models."""
    with open(json_file_path, 'r') as f:
        raw_data = json.load(f)
    
    provider_models = defaultdict(list)
    provider_counts = defaultdict(int)
    
    for model_name, model_info in raw_data.items():
        # Skip sample_spec and non-model entries
        if model_name == "sample_spec" or not isinstance(model_info, dict):
            continue
            
        provider = model_info.get("litellm_provider")
        if not provider or provider not in PROVIDER_MAPPING:
            continue
            
        # Skip bedrock models with "/" in name (legacy models)
        if provider in ["bedrock", "bedrock_converse"] and "/" in model_name:
            continue
            
        # Check if model has cost information
        input_cost = model_info.get("input_cost_per_token", 0)
        output_cost = model_info.get("output_cost_per_token", 0)
        
        if input_cost > 0 or output_cost > 0:
            opik_provider = PROVIDER_MAPPING[provider]
            
            # Clean up model name by removing provider prefixes
            clean_model_name = model_name
            prefixes_to_remove = [
                "openai/", "vertex_ai/", "gemini/", "anthropic/", 
                "bedrock/", "ai21.", "amazon.", "anthropic.", "cohere.",
                "meta.", "mistral.", "stability.", "apac.", "eu.", "us."
            ]
            for prefix in prefixes_to_remove:
                if clean_model_name.startswith(prefix):
                    clean_model_name = clean_model_name[len(prefix):]
                    break
            
            model_data = {
                "name": clean_model_name
            }
            
            provider_models[opik_provider].append(model_data)
            provider_counts[opik_provider] += 1
    
    # Sort models within each provider
    for provider in provider_models:
        provider_models[provider].sort(key=lambda x: x["name"])
    
    total_models = sum(provider_counts.values())
    total_providers = len(provider_models)
    
    return {
        "models": dict(provider_models),
        "counts": dict(provider_counts),
        "total_models": total_models,
        "total_providers": total_providers
    }

def generate_mdx_content(processed_data: Dict[str, Any]) -> str:
    """Generate the MDX content."""
    models = processed_data["models"]
    counts = processed_data["counts"]
    total_models = processed_data["total_models"]
    total_providers = processed_data["total_providers"]
    
    # Sort providers for consistent output
    sorted_providers = sorted(models.keys(), key=lambda p: PROVIDER_INFO[p]["name"])
    
    mdx_content = f"""---
title: "Supported Models for Cost Tracking"
description: "Complete list of models supported for automatic cost tracking in Opik"
---

# Supported Models for Cost Tracking

This page lists all models that Opik supports for automatic cost tracking. Cost tracking is automatically enabled when using any of the [supported integrations](/tracing/cost_tracking#supported-models-providers-and-integrations) with these models.

<Note>
  This page is automatically generated from the latest model pricing data and shows which models have cost tracking support.
</Note>

## Overview

Opik supports cost tracking for **{total_models} models** across **{total_providers} providers**:

"""
    
    # Add provider summary with navigation links
    for provider in sorted_providers:
        provider_info = PROVIDER_INFO[provider]
        model_count = counts[provider]
        # Create anchor link from provider name (lowercase, replace spaces with hyphens)
        anchor = provider_info['name'].lower().replace(' ', '-')
        mdx_content += f"- **[{provider_info['name']}](#{anchor})**: {model_count} models\n"
    
    mdx_content += "\n"
    
    # Add detailed provider sections
    for provider in sorted_providers:
        provider_info = PROVIDER_INFO[provider]
        model_list = models[provider]
        model_count = counts[provider]
        
        # Create anchor ID from provider name (lowercase, replace spaces with hyphens)
        anchor_id = provider_info['name'].lower().replace(' ', '-')
        
        mdx_content += f"""## {provider_info['name']} {{#{anchor_id}}}

{provider_info['description']} ‚Ä¢ [Learn more]({provider_info['url']})

**{model_count} models supported**

<details>
<summary>View all {provider_info['name']} models</summary>

"""
        
        # Create a simple bulleted list of models
        for model in model_list:
            mdx_content += f"- `{model['name']}`\n"
        
        mdx_content += "\n</details>\n\n"
    
    # Add footer
    mdx_content += """---

## How Cost Tracking Works

Opik automatically calculates costs for the models listed above when using [supported integrations](/tracing/cost_tracking#supported-models-providers-and-integrations). The cost calculation is handled by backend services that:

1. **Detect the model** used in your LLM calls
2. **Count tokens** in inputs and outputs  
3. **Apply current pricing** from our model database
4. **Store cost information** with your traces and spans

## Technical Implementation

- **Backend Services**: Cost calculation is implemented in the [Opik backend services](https://github.com/comet-ml/opik/tree/main/apps/opik-backend/src/main/java/com/comet/opik/domain)
- **Pricing Data**: Model prices are sourced from the [model pricing JSON file](https://github.com/comet-ml/opik/blob/main/apps/opik-backend/src/main/resources/model_prices_and_context_window.json) as a fallback mechanism
- **Real-time Updates**: This page is automatically updated when model pricing data changes

## Need Support for Additional Models?

If you need cost tracking support for additional models or providers, please [open a feature request](https://github.com/comet-ml/opik/issues) on our GitHub repository.

<Tip>
  For the most up-to-date list of supported providers and their enum values, check the `opik.LLMProvider` enum in the Python SDK.
</Tip>
"""
    
    return mdx_content

def main():
    """Main function to generate the supported models MDX file."""
    # Paths
    json_file_path = "apps/opik-backend/src/main/resources/model_prices_and_context_window.json"
    output_mdx_path = "apps/opik-documentation/documentation/fern/docs/tracing/supported_models.mdx"
    
    # Check if JSON file exists
    if not os.path.exists(json_file_path):
        print(f"Error: JSON file not found at {json_file_path}")
        return 1
    
    # Process the data
    print("Processing model data...")
    processed_data = process_model_data(json_file_path)
    
    # Generate MDX content
    print("Generating MDX content...")
    mdx_content = generate_mdx_content(processed_data)
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_mdx_path), exist_ok=True)
    
    # Write the MDX file
    with open(output_mdx_path, 'w') as f:
        f.write(mdx_content)
    
    print(f"‚úÖ Generated MDX file: {output_mdx_path}")
    print(f"üìä Total models: {processed_data['total_models']}")
    print(f"üè¢ Total providers: {processed_data['total_providers']}")
    
    return 0

if __name__ == "__main__":
    exit(main())
