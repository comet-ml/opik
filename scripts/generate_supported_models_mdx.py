#!/usr/bin/env python3
"""
THIS SCRIPT IS AUTOGENERATED WITH CURSOR.

Script to generate a static MDX file for supported models with cost tracking.
This script reads the model_prices_and_context_window.json file and generates
a static markdown documentation page listing all supported models by provider.

*TO ADD A NEW PROVIDER, YOU ONLY NEED TO:*
1. Add the provider name mapping (litellm provider name => Opik provider name) to the PROVIDER_MAPPING dictionary
2. Add the provider information to the PROVIDER_INFO dictionary
3. Run the script to generate the MDX file

The script automatically handles prefix removal and all other logic based on these dictionaries.
"""

import json
import os
from collections import defaultdict
from typing import Dict, List, Any

# Mapping from litellm_provider names to Opik provider names
PROVIDER_MAPPING = {
    "openai": "openai",
    "vertex_ai-language-models": "google_vertexai",
    "gemini": "google_ai",
    "anthropic": "anthropic",
    "vertex_ai-anthropic_models": "anthropic_vertexai",
    "bedrock": "bedrock",
    "bedrock_converse": "bedrock",
    "groq": "groq",
}

# Provider display names and descriptions
PROVIDER_INFO = {
    "openai": {
        "name": "OpenAI",
        "description": "Models hosted by OpenAI",
        "url": "https://platform.openai.com"
    },
    "google_vertexai": {
        "name": "Google Vertex AI", 
        "description": "Gemini models hosted in Google Vertex AI",
        "url": "https://cloud.google.com/vertex-ai"
    },
    "google_ai": {
        "name": "Google AI",
        "description": "Gemini models hosted in Google AI Studio", 
        "url": "https://ai.google.dev/aistudio"
    },
    "anthropic": {
        "name": "Anthropic",
        "description": "Anthropic models hosted by Anthropic",
        "url": "https://www.anthropic.com"
    },
    "anthropic_vertexai": {
        "name": "Anthropic on Vertex AI",
        "description": "Anthropic models hosted in Google Vertex AI",
        "url": "https://cloud.google.com/vertex-ai"
    },
    "bedrock": {
        "name": "AWS Bedrock",
        "description": "Models hosted by AWS Bedrock", 
        "url": "https://aws.amazon.com/bedrock"
    },
    "groq": {
        "name": "Groq",
        "description": "Models hosted by Groq",
        "url": "https://groq.com"
    }
}



def process_model_data(json_file_path: str) -> Dict[str, Any]:
    """Process the JSON file and extract supported models."""
    with open(json_file_path, 'r') as f:
        raw_data = json.load(f)
    
    provider_models = defaultdict(list)
    provider_counts = defaultdict(int)
    
    for model_name, model_info in raw_data.items():
        # Skip sample_spec and non-model entries
        if model_name == "sample_spec" or not isinstance(model_info, dict):
            continue
            
        provider = model_info.get("litellm_provider")
        if not provider or provider not in PROVIDER_MAPPING:
            continue
            
        # Skip bedrock models with "/" in name (legacy models)
        if provider in ["bedrock", "bedrock_converse"] and "/" in model_name:
            continue
            
        # Check if model has cost information
        input_cost = model_info.get("input_cost_per_token", 0)
        output_cost = model_info.get("output_cost_per_token", 0)
        
        if input_cost > 0 or output_cost > 0:
            opik_provider = PROVIDER_MAPPING[provider]
            
            # Clean up model name by removing provider prefixes
            clean_model_name = model_name
            
            # Generate prefixes to remove from PROVIDER_MAPPING keys
            # This ensures we automatically handle new providers without manual updates
            provider_prefixes = [f"{provider}/" for provider in PROVIDER_MAPPING.keys()]
            
            # Additional common prefixes that may appear in model names
            # These are company/organization prefixes and regional prefixes found in the JSON
            additional_prefixes = [
                "ai21.", "amazon.", "anthropic.", "cohere.", "meta.", "mistral.", "stability.",
                "us.", "eu.", "apac.", "vertex_ai/"
            ]
            
            prefixes_to_remove = provider_prefixes + additional_prefixes
            
            for prefix in prefixes_to_remove:
                if clean_model_name.startswith(prefix):
                    clean_model_name = clean_model_name[len(prefix):]
                    break
            
            model_data = {
                "name": clean_model_name
            }
            
            provider_models[opik_provider].append(model_data)
            provider_counts[opik_provider] += 1
    
    # Sort models within each provider
    for provider in provider_models:
        provider_models[provider].sort(key=lambda x: x["name"])
    
    total_models = sum(provider_counts.values())
    total_providers = len(provider_models)
    
    return {
        "models": dict(provider_models),
        "counts": dict(provider_counts),
        "total_models": total_models,
        "total_providers": total_providers
    }

def generate_mdx_content(processed_data: Dict[str, Any]) -> str:
    """Generate the MDX content."""
    models = processed_data["models"]
    counts = processed_data["counts"]
    total_models = processed_data["total_models"]
    total_providers = processed_data["total_providers"]
    
    # Sort providers for consistent output
    sorted_providers = sorted(models.keys(), key=lambda p: PROVIDER_INFO[p]["name"])
    
    mdx_content = f"""---
title: "Supported Models for Cost Tracking"
description: "Complete list of models supported for automatic cost tracking in Opik"
---

# Supported Models for Cost Tracking

This page lists all models that Opik supports for automatic cost tracking. Cost tracking is automatically enabled when using any of the [supported integrations](/tracing/cost_tracking#supported-models-providers-and-integrations) with these models.

<Note>
  This page is automatically generated from the latest model pricing data and shows which models have cost tracking support.
</Note>

## Overview

Opik supports cost tracking for **{total_models} models** across **{total_providers} providers**:

"""
    
    # Add provider summary with navigation links
    for provider in sorted_providers:
        provider_info = PROVIDER_INFO[provider]
        model_count = counts[provider]
        # Create anchor link from provider name (lowercase, replace spaces with hyphens)
        anchor = provider_info['name'].lower().replace(' ', '-')
        mdx_content += f"- **[{provider_info['name']}](#{anchor})**: {model_count} models\n"
    
    mdx_content += "\n"
    
    # Add detailed provider sections
    for provider in sorted_providers:
        provider_info = PROVIDER_INFO[provider]
        model_list = models[provider]
        model_count = counts[provider]
        
        # Create anchor ID from provider name (lowercase, replace spaces with hyphens)
        anchor_id = provider_info['name'].lower().replace(' ', '-')
        
        mdx_content += f"""<h2 id="{anchor_id}">{provider_info['name']}</h2>

{provider_info['description']} ‚Ä¢ [Learn more]({provider_info['url']})

**{model_count} models supported**

<details>
<summary>View all {provider_info['name']} models</summary>

"""
        
        # Create a simple bulleted list of models
        for model in model_list:
            mdx_content += f"- `{model['name']}`\n"
        
        mdx_content += "\n</details>\n\n"
    
    # Add footer
    mdx_content += """---

## How Cost Tracking Works

Opik automatically calculates costs for the models listed above when using [supported integrations](/tracing/cost_tracking#supported-models-providers-and-integrations). The cost calculation is handled by backend services that:

1. **Detect the model** used in your LLM calls
2. **Count tokens** in inputs, outputs, and cache if available
3. **Apply current pricing** from our model database
4. **Store cost information** with your traces and spans

## Pricing Data

- **Pricing Data**: Model prices are sourced from the [model pricing JSON file](https://github.com/comet-ml/opik/blob/main/apps/opik-backend/src/main/resources/model_prices_and_context_window.json)
- **Real-time Updates**: This page is automatically updated when model pricing data changes

## Need Support for Additional Models?

If you need cost tracking support for additional models or providers, please [open a feature request](https://github.com/comet-ml/opik/issues) on our GitHub repository.

<Tip>
  For the most up-to-date list of supported providers and their enum values, check the `opik.LLMProvider` enum in the Python SDK.
</Tip>
"""
    
    return mdx_content

def main():
    """Main function to generate the supported models MDX file."""
    # Paths
    json_file_path = "apps/opik-backend/src/main/resources/model_prices_and_context_window.json"
    output_mdx_path = "apps/opik-documentation/documentation/fern/docs/tracing/supported_models.mdx"
    
    # Check if JSON file exists
    if not os.path.exists(json_file_path):
        print(f"Error: JSON file not found at {json_file_path}")
        return 1
    
    # Process the data
    print("Processing model data...")
    processed_data = process_model_data(json_file_path)
    
    # Generate MDX content
    print("Generating MDX content...")
    mdx_content = generate_mdx_content(processed_data)
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_mdx_path), exist_ok=True)
    
    # Write the MDX file
    with open(output_mdx_path, 'w') as f:
        f.write(mdx_content)
    
    print(f"‚úÖ Generated MDX file: {output_mdx_path}")
    print(f"üìä Total models: {processed_data['total_models']}")
    print(f"üè¢ Total providers: {processed_data['total_providers']}")
    
    return 0

if __name__ == "__main__":
    exit(main())
