---
description: Opik Test Workflow
globs: 
alwaysApply: true
---
# Opik Test Workflow

## **Initial Testing Framework Setup**

Before implementing the Test workflow, ensure your project has a proper testing framework configured. This section covers setup for different technology stacks.

### **Detecting Project Type & Framework Needs**

**AI Agent Assessment Checklist:**

1. **Language Detection**: Check for `pom.xml` (Java), `package.json` (TypeScript), `requirements.txt` (Python) etc.
2. **Existing Tests**: Look for test directories or test files (`Test`, `test_`, `.test.`, `.spec.`, `_test.` etc.)
3. **Framework Detection**: Check for existing test runners in dependencies
4. **Project Structure**: Analyze directory structure for testing patterns

### **Generic Testing Framework Setup (Any Language)**

#### **Universal Testing Principles**

**Test Organization:**

- **Unit Tests**: Fast, isolated, no external dependencies
- **Integration Tests**: Test component interactions
- **E2E Tests**: Test complete user workflows
- **Performance Tests**: Load and stress testing (if applicable)

**Naming Conventions:**

- **Test Files**: `Test`, `test_`, `.test.`, `.spec.` etc. or language-specific patterns
- **Test Functions**: Descriptive names (e.g., `should_return_error_for_invalid_input`)
- **Test Directories**: Organized by test type and mirroring source structure

## **Test Maintenance & Evolution**

### **Adding Tests for New Features**

1. **Create test file** following the location conventions
2. **Follow established patterns**
3. **Use existing fixtures**
4. **Apply proper mocking** follow the patterns for dependencies
5. **Meet coverage thresholds** for the component being tested

### **Test Performance Optimization**

1. **Parallel Execution**: Ensure unit tests can run in parallel
2. **Test Isolation**: Each test should be independent
3. **Mock Dependencies**: Mock external services and databases
4. **Efficient Setup**: Use fixtures and setup methods appropriately
5. **Database efficiency**: Avoid unnecessary cleanups
6. **Avoid Sleep**: Use proper waiting mechanisms instead of `Thread.sleep()` etc.

### **When to Update Tests**

1. **New Features**: Always add tests for new functionality
2. **Bug Fixes**: Add tests to prevent regression
3. **Refactoring**: Update tests to match new implementation
4. **API Changes**: Update tests when interfaces change

### **Test Review Checklist**

- [ ] Tests cover all code paths
- [ ] Edge cases are tested
- [ ] Error conditions are handled
- [ ] Tests are readable and maintainable
- [ ] Test data is randomly generated, but realistic
- [ ] Mocks are used appropriately
- [ ] Tests run in reasonable time

## **Test Execution Guidelines**

### **Running Tests**

**Java:**

```bash
# Run all tests
mvn test

# Run specific test class
mvn test -Dtest="UserServiceTest"

# Run specific test method
mvn test -Dtest="UserServiceTest#shouldCreateUser_whenValidRequest"

# Skip tests (for compilation check)
mvn compile -DskipTests
```

**TypeScript:**

```bash
# Run all tests
npm test

# Run tests in watch mode
npm run test:watch

# Run specific test file
npm test -- UserProfile.test.tsx

# Run e2e tests
npm run test:e2e
```

**Python:**

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/unit/test_user.py

# Run specific test function
pytest tests/unit/test_user.py::test_create_user_success

# Run with coverage
pytest --cov=opik
```

---

**Key References:**

- [Project Structure](mdc:.cursor/rules/project-structure.mdc)
- [Technology stack](mdc:.cursor/rules/tech-stack.mdc)
- [Git Workflow](mdc:.cursor/rules/git-workflow.mdc)
