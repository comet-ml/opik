---
description: R2DBC reactive query patterns for ClickHouse with async/reactive streams using Mono and Flux
---

# R2DBC Reactive Patterns (ClickHouse)

> **Note**: This rule documents patterns and conventions. For current table schemas:
> - Check [ClickHouse Schema Patterns](mdc:.cursor/rules/clickhouse-schema-patterns.mdc)
> - Search for existing DAO implementations: `codebase_search("TraceDAOImpl class")`
> - Review migrations: [db-app-analytics/migrations/](mdc:apps/opik-backend/src/main/resources/liquibase/db-app-analytics/migrations/)

This rule documents R2DBC reactive patterns used in Opik for ClickHouse database access with asynchronous, non-blocking operations.

## Core Principles

1. **Reactive Streams**: Use `Mono<T>` for single results, `Flux<T>` for streams
2. **Non-Blocking**: All operations are async - no blocking calls
3. **Connection Management**: Use `TransactionTemplateAsync` for connection handling
4. **SQL Building**: Use StringTemplate4 (ST4) for dynamic SQL construction
5. **Parameter Binding**: Manual binding via `Statement.bind()`
6. **Row Mapping**: Manual mapping from `Row` objects
7. **Context Propagation**: Thread-local context (workspace, user) must be explicitly propagated
8. **No Transactions**: ClickHouse doesn't support traditional ACID transactions

## DAO Implementation Structure

### Interface and Implementation Pattern
```java
package com.comet.opik.domain;

import com.google.inject.ImplementedBy;
import reactor.core.publisher.Mono;
import reactor.core.publisher.Flux;
import io.r2dbc.spi.Connection;
import java.util.UUID;

// Interface
@ImplementedBy(EntityDAOImpl.class)
interface EntityDAO {
    Mono<UUID> insert(Entity entity, Connection connection);
    Mono<Void> update(UUID id, EntityUpdate update, Connection connection);
    Mono<Entity> findById(UUID id, Connection connection);
    Flux<Entity> search(int limit, SearchCriteria criteria);
}

// Implementation
@Slf4j
@Singleton
@RequiredArgsConstructor(onConstructor_ = @Inject)
class EntityDAOImpl implements EntityDAO {
    
    private static final String INSERT = """
        INSERT INTO entities (id, name, workspace_id, created_by)
        VALUES (:id, :name, :workspace_id, :user_name)
        """;
    
    private final @NonNull TransactionTemplateAsync asyncTemplate;
    private final @NonNull Provider<RequestContext> requestContext;
    
    @Override
    public Mono<UUID> insert(Entity entity, Connection connection) {
        Statement statement = connection.createStatement(INSERT)
            .bind("id", entity.id())
            .bind("name", entity.name());
        
        return makeMonoContextAware(bindWorkspaceIdToMono(statement))
            .thenReturn(entity.id());
    }
}
```

## Connection and Transaction Management

### TransactionTemplateAsync

**Location**: [TransactionTemplateAsync.java](mdc:apps/opik-backend/src/main/java/com/comet/opik/infrastructure/db/TransactionTemplateAsync.java)

```java
// Non-transactional operation (ClickHouse doesn't have traditional transactions)
public <T> Mono<T> nonTransaction(TransactionCallback<T> callback);

// Stream operation
public <T> Flux<T> stream(NoTransactionStream<T> callback);
```

### Usage in Service Layer

```java
@Singleton
@RequiredArgsConstructor(onConstructor_ = @Inject)
class TraceService {
    
    private final TransactionTemplateAsync asyncTemplate;
    private final TraceDAO traceDAO;
    
    public Mono<Trace> create(TraceCreate request) {
        return asyncTemplate.nonTransaction(READ_ONLY, connection -> {
            return traceDAO.insert(trace, connection);
        });
    }
    
    public Flux<Trace> search(SearchCriteria criteria) {
        return asyncTemplate.stream(connection -> {
            return traceDAO.search(criteria, connection);
        });
    }
}
```

### Transaction Constants

```java
import static com.comet.opik.infrastructure.db.TransactionTemplateAsync.READ_ONLY;
import static com.comet.opik.infrastructure.db.TransactionTemplateAsync.WRITE;

// Use READ_ONLY for queries
asyncTemplate.nonTransaction(READ_ONLY, connection -> { ... });

// Use WRITE for inserts/updates
asyncTemplate.nonTransaction(WRITE, connection -> { ... });
```

## SQL Query Building with StringTemplate4

### Dynamic SQL Construction

**Example**: [TraceDAOImpl](mdc:apps/opik-backend/src/main/java/com/comet/opik/domain/TraceDAO.java)

```java
// 1. Define SQL template as constant
private static final String INSERT = """
    INSERT INTO traces (
        id, project_id, workspace_id, name, start_time, end_time, input, output
    )
    SELECT
        :id as id,
        :project_id as project_id,
        :workspace_id as workspace_id,
        :name as name,
        parseDateTime64BestEffort(:start_time, 9) as start_time,
        <if(end_time)> parseDateTime64BestEffort(:end_time, 9) as end_time, <else> null as end_time, <endif>
        :input as input,
        :output as output
    ;
    """;

// 2. Build template with conditional values
private ST buildInsertTemplate(Trace trace) {
    ST template = new ST(INSERT);
    
    // Add values only if present
    Optional.ofNullable(trace.endTime())
        .ifPresent(endTime -> template.add("end_time", endTime));
    
    return template;
}

// 3. Render SQL and create statement
public Mono<UUID> insert(Trace trace, Connection connection) {
    ST template = buildInsertTemplate(trace);
    String sql = template.render();  // Render to final SQL
    
    Statement statement = connection.createStatement(sql);
    bindInsertParams(trace, statement);
    
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .thenReturn(trace.id());
}
```

### Template Conditionals

```java
// Conditional fields
<if(field_name)> AND column = :param <endif>

// Conditional with else
<if(end_time)> 
    parseDateTime64BestEffort(:end_time, 9) as end_time,
<else> 
    null as end_time,
<endif>

// Multiple conditions
<if(filters)> WHERE <filters> <endif>
<if(sorting)> ORDER BY <sorting> <endif>
<if(pagination)> LIMIT :limit OFFSET :offset <endif>
```

### Batch Insert Template

```java
private static final String BATCH_INSERT = """
    INSERT INTO traces(id, name, workspace_id, created_by)
    VALUES
        <items:{item |
            (
                :id<item.index>,
                :name<item.index>,
                :workspace_id,
                :user_name
            )
            <if(item.hasNext)>,<endif>
        }>
    ;
    """;

// Build template with list
ST template = new ST(BATCH_INSERT);
template.add("items", traces);  // Add list for iteration

String sql = template.render();
```

## Parameter Binding

### Simple Value Binding

```java
Statement statement = connection.createStatement(sql);

// Strings
statement.bind("id", trace.id().toString());
statement.bind("name", trace.name());

// UUIDs (bind as strings for FixedString(36))
statement.bind("id", id);  // Automatically converted to string

// Numbers
statement.bind("value", 0.95);

// Booleans
statement.bind("enabled", true);

// Null values (explicit type required)
statement.bindNull("end_time", String.class);
```

### Array Binding

```java
// String arrays for Array(String) columns
if (trace.tags() != null) {
    statement.bind("tags", trace.tags().toArray(String[]::new));
} else {
    statement.bind("tags", new String[]{});  // Empty array, not null
}
```

### Conditional Binding

```java
private void bindInsertParams(Trace trace, Statement statement) {
    // Always bind
    statement.bind("id", trace.id());
    statement.bind("name", trace.name());
    statement.bind("workspace_id", trace.workspaceId());
    
    // Conditional binding with Optional
    Optional.ofNullable(trace.endTime())
        .ifPresent(endTime -> statement.bind("end_time", endTime.toString()));
    
    // Conditional with StringUtils
    if (StringUtils.isNotBlank(trace.threadId())) {
        statement.bind("thread_id", trace.threadId());
    }
    
    // JSON as string
    Optional.ofNullable(trace.errorInfo())
        .ifPresent(errorInfo -> 
            statement.bind("error_info", JsonUtils.readTree(errorInfo).toString())
        );
}
```

### Batch Parameter Binding

```java
public Mono<Long> batchInsert(List<Trace> traces, Connection connection) {
    ST template = new ST(BATCH_INSERT);
    template.add("items", traces);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    
    // Bind parameters for each item
    for (int i = 0; i < traces.size(); i++) {
        Trace trace = traces.get(i);
        statement.bind("id" + i, trace.id());
        statement.bind("name" + i, trace.name());
        // ... bind other fields
    }
    
    // Workspace and user bound once for all
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .flatMap(result -> Mono.from(result.getRowsUpdated()))
        .map(Long::valueOf);
}
```

## Row Mapping

### Manual Row Mapping

```java
private Flux<Trace> mapToTraces(Result result) {
    return Flux.from(result.map((row, metadata) -> {
        return Trace.builder()
            .id(UUID.fromString(row.get("id", String.class)))
            .name(row.get("name", String.class))
            .workspaceId(row.get("workspace_id", String.class))
            .projectId(UUID.fromString(row.get("project_id", String.class)))
            .startTime(Optional.ofNullable(row.get("start_time", LocalDateTime.class))
                .map(ldt -> ldt.atZone(ZoneId.of("UTC")).toInstant())
                .orElse(null))
            .endTime(Optional.ofNullable(row.get("end_time", LocalDateTime.class))
                .map(ldt -> ldt.atZone(ZoneId.of("UTC")).toInstant())
                .orElse(null))
            .tags(Optional.ofNullable(row.get("tags", String[].class))
                .map(Arrays::asList)
                .map(LinkedHashSet::new)
                .orElse(new LinkedHashSet<>()))
            .build();
    }));
}
```

### Nullable Column Handling

```java
// For Nullable columns in ClickHouse
LocalDateTime endTime = row.get("end_time", LocalDateTime.class);  // Can be null
if (endTime != null) {
    builder.endTime(endTime.atZone(ZoneId.of("UTC")).toInstant());
}

// Or with Optional
Optional.ofNullable(row.get("end_time", LocalDateTime.class))
    .ifPresent(ldt -> builder.endTime(ldt.atZone(ZoneId.of("UTC")).toInstant()));
```

### Array Column Mapping

```java
// Array(String) columns
String[] tagsArray = row.get("tags", String[].class);
Set<String> tags = tagsArray != null 
    ? new LinkedHashSet<>(Arrays.asList(tagsArray))
    : new LinkedHashSet<>();
```

### JSON Column Mapping

```java
// JSON stored as String
String metadataJson = row.get("metadata", String.class);
JsonNode metadata = StringUtils.isNotBlank(metadataJson) 
    ? JsonUtils.readValue(metadataJson, JsonNode.class)
    : JsonNodeFactory.instance.objectNode();
```

## Reactive Stream Operations

### Mono<T> - Single Result

```java
// Return single entity
public Mono<Trace> findById(UUID id, Connection connection) {
    Statement statement = connection.createStatement(SELECT_BY_ID)
        .bind("id", id);
    
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .flatMapMany(this::mapToTraces)
        .singleOrEmpty();  // Convert Flux to Mono
}

// Return count
public Mono<Long> count(SearchCriteria criteria) {
    // ... build statement
    
    return Flux.from(statement.execute())
        .flatMap(result -> Mono.from(result.map((row, meta) -> 
            row.get("count", Long.class)
        )))
        .singleOrEmpty()
        .defaultIfEmpty(0L);
}

// Return void (for updates/inserts)
public Mono<Void> update(UUID id, Update update, Connection connection) {
    // ... build statement
    
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .then();  // Discard result, return Mono<Void>
}
```

### Flux<T> - Multiple Results

```java
// Return stream of entities
public Flux<Trace> search(SearchCriteria criteria, Connection connection) {
    ST template = buildSearchTemplate(criteria);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    bindSearchParams(criteria, statement);
    
    return makeFluxContextAware(bindWorkspaceIdToFlux(statement))
        .flatMap(this::mapToTraces);
}

// Collect to list
public Mono<List<Trace>> findAll() {
    return asyncTemplate.stream(connection -> {
        return traceDAO.search(criteria, connection);
    }).collectList();
}
```

### Result Processing

```java
// Execute and get rows updated
return Flux.from(statement.execute())
    .flatMap(result -> Mono.from(result.getRowsUpdated()))
    .map(Long::valueOf)
    .reduce(0L, Long::sum);  // Sum all updates

// Execute and map results
return Flux.from(statement.execute())
    .flatMap(result -> Flux.from(result.map((row, meta) -> mapRow(row))));
```

## Context Propagation

### Workspace and User Context

**Critical**: Thread-local context doesn't automatically propagate in reactive streams. Must explicitly bind context.

```java
import static com.comet.opik.domain.AsyncContextUtils.bindWorkspaceIdToMono;
import static com.comet.opik.domain.AsyncContextUtils.bindWorkspaceIdToFlux;
import static com.comet.opik.domain.AsyncContextUtils.bindUserNameAndWorkspaceContext;
import static com.comet.opik.utils.AsyncUtils.makeMonoContextAware;
import static com.comet.opik.utils.AsyncUtils.makeFluxContextAware;

// For Mono operations
return makeMonoContextAware(bindWorkspaceIdToMono(statement));

// For Flux operations
return makeFluxContextAware(bindWorkspaceIdToFlux(statement));

// For both workspace and user
return makeMonoContextAware(bindUserNameAndWorkspaceContext(statement));
```

### Context Binding Pattern

```java
// 1. Create statement
Statement statement = connection.createStatement(sql);

// 2. Bind regular parameters
statement.bind("id", id);
statement.bind("name", name);

// 3. Bind context parameters (workspace_id, user_name)
// This adds :workspace_id and :user_name bindings from RequestContext
return makeMonoContextAware(bindWorkspaceIdToMono(statement));

// SQL must include placeholders:
// WHERE workspace_id = :workspace_id AND created_by = :user_name
```

## Common Query Patterns

### Insert Pattern

```java
@Override
public Mono<UUID> insert(Trace trace, Connection connection) {
    ST template = buildInsertTemplate(trace);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    bindInsertParams(trace, statement);
    
    Segment segment = startSegment("traces", "Clickhouse", "insert");
    
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .doFinally(signalType -> endSegment(segment))
        .thenReturn(trace.id());
}
```

### Update Pattern

```java
@Override
public Mono<Void> update(UUID id, TraceUpdate update, Connection connection) {
    ST template = buildUpdateTemplate(update);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    statement.bind("id", id);
    bindUpdateParams(update, statement);
    
    return makeMonoContextAware(bindUserNameAndWorkspaceContext(statement))
        .then();
}
```

### Select Pattern

```java
@Override
public Mono<Trace> findById(UUID id, Connection connection) {
    Statement statement = connection.createStatement(SELECT_BY_ID)
        .bind("id", id);
    
    return makeFluxContextAware(bindWorkspaceIdToFlux(statement))
        .flatMap(this::mapToTraces)
        .singleOrEmpty();
}
```

### Search/List Pattern

```java
@Override
public Flux<Trace> search(int limit, SearchCriteria criteria) {
    return asyncTemplate.stream(connection -> {
        ST template = buildSearchTemplate(criteria);
        String sql = template.render();
        
        Statement statement = connection.createStatement(sql);
        statement.bind("limit", limit);
        bindSearchParams(criteria, statement);
        
        return makeFluxContextAware(bindWorkspaceIdToFlux(statement))
            .flatMap(this::mapToTraces);
    });
}
```

### Delete Pattern

```java
@Override
public Mono<Void> delete(Set<UUID> ids, UUID projectId, Connection connection) {
    ST template = new ST(DELETE_BY_ID);
    template.add("project_id", projectId);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    statement.bind("ids", ids.stream()
        .map(UUID::toString)
        .toArray(String[]::new));
    
    if (projectId != null) {
        statement.bind("project_id", projectId);
    }
    
    return makeMonoContextAware(bindWorkspaceIdToMono(statement))
        .then();
}
```

### Batch Insert Pattern

```java
@Override
public Mono<Long> batchInsert(List<Trace> traces, Connection connection) {
    if (traces.isEmpty()) {
        return Mono.just(0L);
    }
    
    ST template = new ST(BATCH_INSERT);
    template.add("items", traces);
    String sql = template.render();
    
    Statement statement = connection.createStatement(sql);
    
    // Bind all trace parameters
    for (int i = 0; i < traces.size(); i++) {
        bindBatchItemParams(traces.get(i), i, statement);
    }
    
    Segment segment = startSegment("traces", "Clickhouse", "batchInsert");
    
    return makeMonoContextAware(bindUserNameAndWorkspaceContext(statement))
        .flatMap(result -> Mono.from(result.getRowsUpdated()))
        .map(Long::valueOf)
        .doFinally(signalType -> endSegment(segment));
}
```

## Pagination Pattern

```java
public Mono<TracePage> find(int page, int size, SearchCriteria criteria) {
    return asyncTemplate.nonTransaction(READ_ONLY, connection -> {
        // Get total count
        Mono<Long> countMono = count(criteria, connection);
        
        // Get page of results
        Flux<Trace> tracesFlux = search(page, size, criteria, connection);
        
        // Combine count and results
        return Mono.zip(
            countMono,
            tracesFlux.collectList()
        ).map(tuple -> {
            long total = tuple.getT1();
            List<Trace> traces = tuple.getT2();
            return new TracePage(traces, page, size, total);
        });
    });
}
```

## Error Handling

```java
public Mono<Trace> findById(UUID id) {
    return asyncTemplate.nonTransaction(READ_ONLY, connection -> {
        return traceDAO.findById(id, connection);
    })
    .switchIfEmpty(Mono.error(new NotFoundException("Trace not found: " + id)))
    .onErrorResume(Exception.class, ex -> {
        log.error("Error finding trace: {}", id, ex);
        return Mono.error(new RuntimeException("Database error", ex));
    });
}
```

## Performance Instrumentation

```java
import static com.comet.opik.infrastructure.instrumentation.InstrumentAsyncUtils.startSegment;
import static com.comet.opik.infrastructure.instrumentation.InstrumentAsyncUtils.endSegment;

public Mono<Trace> findById(UUID id, Connection connection) {
    Segment segment = startSegment("traces", "Clickhouse", "findById");
    
    return makeFluxContextAware(bindWorkspaceIdToFlux(statement))
        .flatMap(this::mapToTraces)
        .singleOrEmpty()
        .doFinally(signalType -> endSegment(segment));  // Always close segment
}
```

## Common Anti-Patterns to Avoid

❌ **Blocking in reactive chain**
```java
// BAD: Blocking call breaks async nature
return Mono.just(jdbi.withHandle(handle -> {  // BLOCKING!
    return dao.findById(id);
}));
```

✅ **Correct**
```java
return asyncTemplate.nonTransaction(READ_ONLY, connection -> {
    return traceDAO.findById(id, connection);  // Non-blocking
});
```

❌ **Missing context propagation**
```java
// BAD: Context not bound
return Flux.from(statement.execute())
    .flatMap(this::mapToTraces);
```

✅ **Correct**
```java
return makeFluxContextAware(bindWorkspaceIdToFlux(statement))
    .flatMap(this::mapToTraces);
```

❌ **Not handling null arrays**
```java
// BAD: Will fail on null arrays
statement.bind("tags", trace.tags().toArray(String[]::new));
```

✅ **Correct**
```java
if (trace.tags() != null) {
    statement.bind("tags", trace.tags().toArray(String[]::new));
} else {
    statement.bind("tags", new String[]{});
}
```

❌ **Using .block() or .blockFirst()**
```java
// BAD: Defeats purpose of reactive
Trace trace = traceDAO.findById(id, connection).block();  // NEVER DO THIS
```

✅ **Correct**
```java
// Return Mono/Flux, let caller decide how to consume
return traceDAO.findById(id, connection);
```

## Best Practices

1. **Always use TransactionTemplateAsync** for connection management
2. **Propagate context** with `makeMonoContextAware`/`makeFluxContextAware`
3. **Use StringTemplate4** for dynamic SQL, not string concatenation
4. **Handle nullable columns** explicitly in row mapping
5. **Bind empty arrays** instead of null for Array columns
6. **Use segments** for performance instrumentation
7. **Return Mono<Void>** for operations with no result
8. **Collect streams** with `.collectList()` when needed
9. **Handle errors** with `.onErrorResume()` or `.switchIfEmpty()`
10. **Never call `.block()`** in reactive chains

## Related Rules

- [Database Overview](mdc:.cursor/rules/database-overview.mdc)
- [ClickHouse Schema Patterns](mdc:.cursor/rules/clickhouse-schema-patterns.mdc)
- [Database Query Best Practices](mdc:.cursor/rules/database-query-best-practices.mdc)
