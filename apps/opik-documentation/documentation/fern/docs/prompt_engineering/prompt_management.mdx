Opik provides a prompt library that you can use to manage your prompts. Storing
prompts in a library allows you to version them, reuse them across projects, and
manage them in a central location.

Using a prompt library does not mean you can't store your prompt in code, we
have designed the prompt library to be work seamlessly with your existing prompt
files while providing the benefits of a central prompt library.

## Managing prompts stored in code

The recommend way to create and manage prompts is using The
[`Prompt`](https://www.comet.com/docs/opik/python-sdk-reference/library/Prompt.html)
object. This will allow you to continue versioning your prompts in code while
also getting the benefit of having prompt versions managed in the Opik platform
so you can more easily keep track of your progress.

<Tabs>
    <Tab value="Prompts stored in code" title="Prompts stored in code">

        ```python
        import opik

        # Prompt text stored in a variable
        PROMPT_TEXT = "Write a summary of the following text: {{text}}"

        # Create a prompt
        prompt = opik.Prompt(
            name="prompt-summary",
            prompt=PROMPT_TEXT,
        )

        # Print the prompt text
        print(prompt.prompt)

        # Build the prompt
        print(prompt.format(text="Hello, world!"))
        ```

    </Tab>
    <Tab value="Prompts stored in a file" title="Prompts stored in a file">

        ```python {pytest_codeblocks_skip=true}
        import opik

        # Read the prompt from a file
        with open("prompt.txt", "r") as f:
            prompt_text = f.read()

        prompt = opik.Prompt(name="prompt-summary", prompt=prompt_text)

        # Print the prompt text
        print(prompt.prompt)

        # Build the prompt
        print(prompt.format(text="Hello, world!"))
        ```

    </Tab>

</Tabs>

The prompt will now be stored in the library and versioned:

<Frame>
  <img src="/img/prompt_engineering/prompt_library_versions.png" />
</Frame>

<Tip>
The [`Prompt`](https://www.comet.com/docs/opik/python-sdk-reference/library/Prompt.html)
object will create a new prompt in the library if this prompt doesn't already exist,
otherwise it will return the existing prompt.

This means you can safely run the above code multiple times without creating
duplicate prompts.

</Tip>

## Using the low level SDK

If you would rather keep prompts in the Opik platform and manually update / download
them, you can use the low-level Python SDK to manage you prompts.

### Creating prompts

You can create a new prompt in the library using both the SDK and the UI:

<Tabs>
    <Tab value="Using the Python SDK" title="Using the Python SDK">
        ```python
        import opik

        opik.configure()
        client = opik.Opik()

        # Create a new prompt
        prompt = client.create_prompt(name="prompt-summary", prompt="Write a summary of the following text: {{text}}")
        ```
    </Tab>
    <Tab value="Using the UI" title="Using the UI">
        You can create a prompt in the UI by navigating to the Prompt library and clicking `Create new prompt`. This will open a dialog where you can enter the prompt name, the prompt text, and optionally a description:

        <Frame>

<img src="/img/prompt_engineering/prompt_library.png" />
</Frame>

        You can also edit a prompt by clicking on the prompt name in the library and clicking `Edit prompt`.
    </Tab>

</Tabs>

### Downloading your prompts

Once a prompt is created in the library, you can download it in code using the [`Opik.get_prompt`](https://www.comet.com/docs/opik/python-sdk-reference/Opik.html#opik.Opik.get_prompt) method:

```python
import opik

opik.configure()
client = opik.Opik()

# Get a dataset
dataset = client.get_or_create_dataset("test_dataset")

# Get the prompt
prompt = client.get_prompt(name="prompt-summary")

# Create the prompt message
prompt.format(text="Hello, world!")
```

If you are not using the SDK, you can download a prompt by using the [REST API](/reference/rest-api/overview).

## Linking prompts to Experiments

[Experiments](/evaluation/evaluate_your_llm) allow you to evaluate the performance
of your LLM application on a set of examples. When evaluating different prompts,
it can be useful to link the evaluation to a specific prompt version. This can
be achieved by passing the `prompt` parameter when creating an Experiment:

```python
import opik
from opik.evaluation import evaluate
from opik.evaluation.metrics import Hallucination

opik.configure()
client = opik.Opik()

# Get a dataset
dataset = client.get_or_create_dataset("test_dataset")

# Create a prompt
prompt = opik.Prompt(name="My prompt", prompt="...")

# Create an evaluation task
def evaluation_task(dataset_item):
    return {"output": "llm_response"}

# Run the evaluation
evaluation = evaluate(
    experiment_name="My experiment",
    dataset=dataset,
    task=evaluation_task,
    prompt=prompt,
)
```

The experiment will now be linked to the prompt allowing you to view all experiments that use a specific prompt:

<Frame>
  <img src="/img/evaluation/linked_prompt.png" />
</Frame>
