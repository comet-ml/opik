---
title: Log Traces
---

<div
  style={{
    position: "relative",
    paddingBottom: "56.25%", // 16:9 aspect ratio
    height: 0,
    overflow: "hidden",
    maxWidth: "100%",
    marginBottom: "20px",
  }}
>
  <iframe
    src="https://www.loom.com/embed/35636dd3baee47c9b96d87e014923d11?sid=4db723bf-3ccc-4cbe-8d86-7f64d782683d"
    frameborder="0"
    webkitallowfullscreen
    mozallowfullscreen
    allowfullscreen
    style={{
      position: "absolute",
      top: 0,
      left: 0,
      width: "100%",
      height: "100%",
    }}
  />
</div>

## Getting Started with Opik Tracing

This hands-on video demonstrates how to implement [tracing](/tracing/log_traces) in Opik, the foundation of LLM observability. You'll learn how [traces](/tracing/log_traces) capture complete interactions between your application and LLMs (inputs, outputs, metadata, and [feedback scores](/tracing/annotate_traces)), and see step-by-step implementation using [OpenAI](/integrations/openai) as an example. Think of traces as the equivalent of logs in traditional software, but specifically designed for LLM applications.

## Key Highlights

- **Simple Setup**: Configure Opik with just your API key and workspace settings - optionally set project names to organize [traces](/tracing/log_traces)
- **Multiple [Integration](/integrations/overview) Methods**: Use dedicated [integrations](/integrations/openai) (like [`track_openai`](/tracing/log_traces#using-an-integration)) for automatic tracing, or the `@track` decorator for custom function tracing
- **Rich Trace Visualization**: View complete interaction flows in the Opik UI with inputs, outputs, and hierarchical [spans](/tracing/log_traces) for multi-step processes
- **Powerful Filtering & Search**: Filter [traces](/tracing/log_traces) by time ranges, tags, [feedback scores](/tracing/annotate_traces), and search by specific trace IDs for production debugging
- **Framework Support**: Dedicated [integrations](/integrations/overview) available for popular frameworks like [LangChain](/integrations/langchain), [LlamaIndex](/integrations/llama-index), and others
- **Automatic Span Creation**: Multi-step applications and RAG workflows automatically generate [spans](/tracing/log_traces) for each step, providing complete process visibility
- **Function-Level Tracing**: The [`@track`](/tracing/log_traces#decorators) decorator creates detailed trace stacks that mirror your function structure, making debugging intuitive
- **Production-Ready**: Tag system and filtering capabilities make it easy to organize and analyze [traces](/tracing/log_traces) from production environments
