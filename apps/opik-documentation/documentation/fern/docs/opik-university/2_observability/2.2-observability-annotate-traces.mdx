---
title: Annotate Traces
---

<div style={{
    position: 'relative',
    paddingBottom: '56.25%', // 16:9 aspect ratio
    height: 0,
    overflow: 'hidden',
    maxWidth: '100%',
    marginBottom: '20px'
}}>
    <iframe
        src="https://www.loom.com/embed/c61ce69e245840489dd90b25489493a8?sid=37e03eeb-e709-4182-9889-f80d113dade2"
        frameborder="0"
        webkitallowfullscreen
        mozallowfullscreen
        allowfullscreen
        style={{
            position: 'absolute',
            top: 0,
            left: 0,
            width: '100%',
            height: '100%',
        }}
    />
</div>

## Building Feedback Loops with Trace Annotations

This video demonstrates how to add human feedback and annotations to your LLM [traces](https://www.comet.com/docs/opik/tracing/log_traces), creating a powerful feedback loop for continuous improvement. You'll learn to mark [traces](https://www.comet.com/docs/opik/tracing/log_traces) as high or low quality, add specific [feedback scores](https://www.comet.com/docs/opik/tracing/annotate_traces), and build [datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets) of annotated examples for future [evaluation](https://www.comet.com/docs/opik/evaluation/overview) and fine-tuning. Annotations bridge the gap between raw trace data and actionable insights for model improvement.

## Key Highlights

- **Easy Feedback Addition**: Use the [feedback scores](https://www.comet.com/docs/opik/tracing/annotate_traces) section and pen icon to quickly add human annotations directly to [traces](https://www.comet.com/docs/opik/tracing/log_traces) in the Opik UI
- **Custom Feedback Definitions**: Create categorical or numerical feedback [metrics](https://www.comet.com/docs/opik/evaluation/metrics/overview) in Configuration â†’ Feedback Definitions to match your specific evaluation needs
- **Flexible Scoring Options**: Define custom categories (pass/fail, quality ratings) or sliding scales (0-1) based on [metrics](https://www.comet.com/docs/opik/evaluation/metrics/overview) like accuracy, relevance, or tone
- **Smart Filtering**: Filter [traces](https://www.comet.com/docs/opik/tracing/log_traces) by [feedback scores](https://www.comet.com/docs/opik/tracing/annotate_traces) to quickly identify high-performing or problematic outputs for targeted analysis
- **[Dataset](https://www.comet.com/docs/opik/evaluation/manage_datasets) Creation**: Convert annotated [traces](https://www.comet.com/docs/opik/tracing/log_traces) directly into [datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets) for training data collection and model improvement workflows
- **Built-in [Metrics](https://www.comet.com/docs/opik/evaluation/metrics/overview) Library**: Access pre-built metrics like [answer relevance](https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance), [Levenshtein distance](https://www.comet.com/docs/opik/evaluation/metrics/heuristic_metrics), and [hallucination](https://www.comet.com/docs/opik/evaluation/metrics/hallucination) detection out of the box
- **LLM as a Judge**: Use automated LLM-based [evaluation](https://www.comet.com/docs/opik/evaluation/metrics/g_eval) where a second LLM evaluates responses from your primary model
- **Pattern Identification**: Annotations help identify performance patterns, create training data, and establish feedback loops between users and developers
