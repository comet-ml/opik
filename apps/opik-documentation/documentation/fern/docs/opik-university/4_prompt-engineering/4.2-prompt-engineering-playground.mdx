---
headline: Prompt Playground | Opik Documentation
og:description: Learn to craft effective prompts for AI interactions in Opik's Prompt
  Playground. Enhance your prompt engineering skills today.
og:site_name: Opik Documentation
og:title: Explore Prompt Playground - Opik
title: Prompt Playground
---

<div style={{
    position: 'relative',
    paddingBottom: '56.25%', // 16:9 aspect ratio
    height: 0,
    overflow: 'hidden',
    maxWidth: '100%',
    marginBottom: '20px'
}}>
    <iframe
        src="https://www.loom.com/embed/d0fb61bee4db48b4a4636d99280a7253?sid=d88fee8f-e7f5-431a-917f-a2b49e4e3d9d"
        frameborder="0"
        webkitallowfullscreen
        mozallowfullscreen
        allowfullscreen
        style={{
            position: 'absolute',
            top: 0,
            left: 0,
            width: '100%',
            height: '100%',
        }}
    />
</div>

## Interactive Prompt Engineering with Opik's Playground

This video demonstrates how to use Opik's [prompting playground](https://www.comet.com/docs/opik/prompt_engineering/playground) for hands-on [prompt engineering](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) and testing. The [playground](https://www.comet.com/docs/opik/prompt_engineering/playground) provides an interactive environment where you can craft [prompts](https://www.comet.com/docs/opik/prompt_engineering/prompt_management), test variations, and run [experiments](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm) directly within the UI. You'll learn how to leverage versioned [prompts](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) from your library, conduct A/B testing, and seamlessly transition from prompt development to full [dataset evaluation](https://www.comet.com/docs/opik/evaluation/manage_datasets).

## Key Highlights

- **Parallel A/B Testing**: Run multiple [prompt](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) variations side-by-side to compare outputs and identify the most effective approaches for your use case
- **Flexible [Prompt](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) Types**: Switch between system and user [prompts](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) depending on your workflow needs, from simple queries to complex system instructions
- **Versioned [Prompt](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) Integration**: Load [prompts](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) directly from your managed [prompt library](https://www.comet.com/docs/opik/prompt_engineering/prompt_management), always accessing the latest committed version for consistent testing
- **[Dataset](https://www.comet.com/docs/opik/evaluation/manage_datasets)-Driven [Experiments](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm)**: Integrate test [datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets) directly into [playground](https://www.comet.com/docs/opik/prompt_engineering/playground) sessions to run comprehensive [evaluations](https://www.comet.com/docs/opik/evaluation/overview) right from the interface
- **Configurable Model Parameters**: Adjust creativity levels, output token limits, and other model settings to fine-tune behavior for your specific requirements
- **Template Variable Support**: Use mustache/handlebar notation (e.g., `{{question}}`) to create dynamic [prompts](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) that work with [dataset](https://www.comet.com/docs/opik/evaluation/manage_datasets) variables
- **Live Version Control**: Save [prompt](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) modifications directly from the [playground](https://www.comet.com/docs/opik/prompt_engineering/playground) with commit messages and metadata, creating new versions in your [prompt library](https://www.comet.com/docs/opik/prompt_engineering/prompt_management)
- **Instant [Experiment](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm) Creation**: Generate [experiments](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm) with visual feedback banners, then view comprehensive results including outputs from your Q&A [datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets)
- **Seamless Workflow Integration**: Bridge the gap between [prompt](https://www.comet.com/docs/opik/prompt_engineering/prompt_management) development, testing, and full [evaluation](https://www.comet.com/docs/opik/evaluation/overview) without leaving the Opik environment