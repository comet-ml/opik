These FAQs are a collection of the most common questions that we've received from our users. If you have any questions or need additional assistance,
please open an [issue on GitHub](https://github.com/comet-ml/opik/issues).

## General

### What is Opik's relationship with Comet?

Opik is developed by Comet and is available in multiple deployment options:
- As a standalone product that can be used locally or self-hosted on your own infrastructure
- As an integrated part of the Comet MLOps Platform (both in Comet-hosted and self-hosted deployments)

This means you can use Opik independently of the Comet platform, or as part of your existing Comet MLOps setup.

### What SDKs does Opik provide?

Opik currently provides official SDKs for:
- Python: Our most feature-complete SDK, supporting all Opik features
- TypeScript: Basic support for tracing features

These SDKs are actively maintained and regularly updated. For other languages, you can use our REST API directly - see our [API documentation](/docs/opik/reference/rest-api/overview) for details.

### Can I use Opik to monitor my LLM application in production?

Yes, Opik has been designed from the ground up to be used to monitor production applications. If you are self-hosting the
Opik platform, we recommend using the [Kuberneters deployment](/self-host/overview) option to ensure that Opik can scale as needed.

## Opik Cloud

### Are there are rate limits on Opik Cloud?

Yes, in order to ensure all users have a good experience we have implemented rate limits. Each user is limited to `10,000`
events per minute, an event is a trace, span, feedback score, dataset item, experiment item, etc. If you need to increase
this limit please reach out to us on [Slack](https://chat.comet.com).

## Integrations

### What integrations does Opik support?

Opik supports a wide range of popular LLM frameworks and providers. You can find detailed integration guides in our [cookbook section](/cookbook/overview#integration-examples) for:

- LLM Providers: OpenAI, Anthropic, AWS Bedrock, Google Gemini, Groq, IBM watsonx, Ollama
- Frameworks: LangChain, LlamaIndex, Haystack, DSPy, CrewAI, LangGraph
- Tools: LiteLLM, Guardrails, Ragas, aisuite
- And more!

### What if Opik doesn't support my preferred framework or tool?

If you don't see your preferred framework or tool listed in our integrations, we encourage you to:

1. Open an [issue on GitHub](https://github.com/comet-ml/opik/issues) to request the integration
2. In the meantime, you can manually log your LLM interactions using our SDK's core logging functions - see our [tracing documentation](/docs/opik/tracing/log_traces) for examples

We actively maintain and expand our integration support based on community feedback.

## Troubleshooting

### Why am I getting 403 errors?

If you're encountering 403 (Forbidden) errors, this typically indicates an authentication or authorization issue. Please double-check your configuration:

For Opik Cloud by Comet:
- `api_key` (required): Verify your API key is correct and active
- `workspace` (required): Confirm you have access to the specified workspace
- `project_name` (optional): If specified, ensure the project name is valid
- `url_override`: Should be set to `https://www.comet.com/opik/api` (this is the default)

For Self-hosted Opik:
- `url_override` (required): Verify your base URL points to your Opik instance (e.g., `http://your-instance:5173/api`)

You can find your current configuration in the Opik configuration file (`~/.opik.config`) or by checking your environment variables (`OPIK_API_KEY`, `OPIK_WORKSPACE`, `OPIK_URL_OVERRIDE`, `OPIK_PROJECT_NAME`). For more details on configuration, see our [SDK Configuration guide](/docs/opik/tracing/sdk_configuration).
