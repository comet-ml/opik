**Opik Dashboard**:

- Added the option to download traces and LLM calls as CSV files from the UI:
  <Frame>
    <img src="/img/changelog/2024-10-21/download_traces.png" />
  </Frame>
- Introduce a new quickstart guide to help you get started:
  <Frame>
    <img src="/img/changelog/2024-10-21/quickstart_guide.png" />
  </Frame>
- Updated datasets to support more flexible data schema, you can now insert items with any key value pairs and not just `input` and `expected_output`. See more in the SDK section below.
- Multiple small UX improvements (more informative empty state for projects, updated icons, feedback tab in the experiment page, etc).
- Fix issue with `\t` characters breaking the YAML code block in the traces page.

**SDK**:

- Datasets now support more flexible data schema, we now support inserting items with any key value pairs:

  ```python
  import opik

  client = opik.Opik()
  dataset = client.get_or_create_dataset(name="Demo Dataset")
  dataset.insert([
      {"user_question": "Hello, what can you do ?", "expected_output": {"assistant_answer": "I am a chatbot assistant that can answer questions and help you with your queries!"}},
      {"user_question": "What is the capital of France?", "expected_output": {"assistant_answer": "Paris"}},
  ])
  ```

- Released WatsonX, Gemini and Groq integration based on the LiteLLM integration.
- The `context` field is now optional in the [Hallucination](/tracing/integrations/overview) metric.
- LLM as a Judge metrics now support customizing the LLM provider by specifying the `model` parameter. See more in the [Customizing LLM as a Judge metrics](/evaluation/metrics/overview#customizing-llm-as-a-judge-metrics) section.
- Fixed an issue when updating feedback scores using the `update_current_span` and `update_current_trace` methods. See this Github issue for more details.
