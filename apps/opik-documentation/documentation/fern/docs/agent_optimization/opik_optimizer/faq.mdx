---
description: Find answers to common questions about Opik Agent Optimizer, including
  optimizer selection, configuration, usage, and best practices.
headline: FAQ | Opik Documentation
og:description: Enhance your prompt and agent performance using Opik's advanced optimization
  algorithms for better results.
og:site_name: Opik Documentation
og:title: Optimize Your Agents with Opik
subtitle: Common questions about the Opik Agent Optimizer
title: Optimizer Frequently Asked Questions
---

## Getting started

<AccordionGroup>
  <Accordion title="Why should I use the Opik Agent Optimizer?">
    The Agent Optimizer provides a unified interface for optimizing **your existing prompts and
    agents** with cutting edge optimization algorithms. In addition to giving you access to cutting
    edge academic optimizers like GEPA, we also provide a set of algorithms that have been developed
    in-house based on production applications.

    The optimizer will allow you to improve the performance of your agents without the need for
    manual prompt engineering. You can also use the optimizer to reduce the size of the prompts in
    your agents, reducing cost and latency while maintaining performance.
  </Accordion>
  <Accordion title="How do I get started with the Optimizer ?">
  To get started, you will need:
  1. The prompt you want to optimize
  2. A dataset of examples to optimizer on, you can start with as little as 10
  3. A metric to evaluate the performance of the prompt

  Once you have these, check out the [Quickstart Guide](/agent_optimization/overview)
  to run your first optimization.
  </Accordion>
  <Accordion title="Can you help me optimize my prompt ?">
  Yes, we would be more than happy to help you setup the Opik Optimizer for your use case ! You can
  join our [Slack community](https://chat.comet.com) and ask for help there.
  </Accordion>
</AccordionGroup>

## Optimization Algorithms

<AccordionGroup>
  <Accordion title="What are the supported optimization algorithms?">
  Opik Agent Optimizer supports a wide range of optimization algorithms including:
  - [HRPO (Hierarchical Reflective Prompt Optimizer)](/agent_optimization/algorithms/hierarchical_adaptive_optimizer)
  - [GEPA Optimization](/agent_optimization/algorithms/gepa_optimizer)
  - [Evolutionary Optimization](/agent_optimization/algorithms/evolutionary_optimizer)
  - [Few-shot Bayesian Optimization](/agent_optimization/algorithms/fewshot_bayesian_optimizer)
  - [MetaPrompt Optimization](/agent_optimization/algorithms/metaprompt_optimizer)

  If you would like us to add a new optimization algorithm, simply create an issue on our
  [GitHub repository](https://github.com/comet-ml/opik/issues) and we will be happy to add it !
  </Accordion>
  <Accordion title="How do I choose the right optimizer for my task?">
  Knowing which optimizer to use depends on your specific needs. As a rule of thumb, we recommend
  starting with [HRPO (Hierarchical Reflective Prompt Optimizer)](/agent_optimization/algorithms/hierarchical_adaptive_optimizer)
  as this has been shown to be a strong baseline for most tasks.

  You can also try to use:
  1. GEPA: This is one of the top performing academic optimizers and is a good option if you have a 
     complex task.
  2. FewShotBayesianOptimizer: If you have a task that is quite repetitive in the formatting of the prompt
     and responses then this is a good option.
  
  </Accordion>
  <Accordion title="How long should I run the optimization for?">
  While some optimizations run for shorts period of time, it is common for optimizations to take a
  couple of hours to complete. As you are starting out, we recommend setting the `max_trials`
  parameter to a reasonable number and increasing / decreasing it as you go.
  </Accordion>
  <Accordion title="How many dataset samples do I need?">
  The number of samples you need depends on your task. As a rule of thumb, we recommend starting with
  at least 10 samples. The more samples you have, the more accurate the optimization will be.
  </Accordion>
  <Accordion title="What models are supported for optimization?">
  The Opik Agent Optimizer uses [LiteLLM](https://docs.litellm.ai/) to support 100+ LLM providers including:
  - **OpenAI** (GPT-4o, GPT-4o-mini, o1, o3-mini)
  - **Anthropic** (Claude 3.5 Sonnet, Claude 3 Opus)
  - **Google Gemini** (Gemini 2.0 Flash, Gemini 1.5 Pro)
  - **Azure OpenAI**
  - **Ollama** (local models like Llama 3, Mistral)
  - **OpenRouter** (access to multiple providers)

  Models use the LiteLLM format: `provider/model-name` (e.g., `gemini/gemini-2.0-flash`).

  <Tip>
    See the [Configure LLM Providers](/agent_optimization/optimization/configure_models) guide for detailed setup instructions and examples for each provider.
  </Tip>
  </Accordion>
  <Accordion title="The performance is not improving, what should I do?">
  There are a few things you can try to improve the performance of your optimization:
  1. Review your optimization metric, ideally it should provide the model with an insightful
     `reason` for the score it gives. By improving the quality of the metric, the optimizer will be
     able to make better optimizations.
  2. Review your dataset, ideally it should be a diverse set of examples that cover the different
     scenarios you want to optimize for.
  3. Use more powerful models for both the chatPrompt model and the optimizer, as models get more
     powerful, they will be able to generate better optimizations.
  </Accordion>
</AccordionGroup>

## Common Errors

<AccordionGroup>
  <Accordion title="ValueError: Prompt must be a ChatPrompt object">
    This error occurs when you pass an incorrect type to the optimizer's `optimize_prompt()` method.

    **Solution**: Ensure you're using the `ChatPrompt` class to define your prompt:
    ```python
    from opik_optimizer import ChatPrompt

    prompt = ChatPrompt(
        messages=[
            {"role": "system", "content": "Your system prompt here"},
            {"role": "user", "content": "Your user prompt with {variable}"}
        ],
        model="gpt-4"
    )
    ```
  </Accordion>

  <Accordion title="ValueError: Dataset must be a Dataset object">
    This error occurs when the dataset passed to the optimizer is not a proper `Dataset` object.

    **Solution**: Use the `Dataset` class to create your dataset:
    ```python
    import opik

    client = opik.Opik()
    dataset = client.get_or_create_dataset(name='your-dataset-name')
    dataset.insert([
        {"input": "example 1", "output": "expected 1"},
        {"input": "example 2", "output": "expected 2"}
    ])
    ```
  </Accordion>

  <Accordion title="ValueError: Metric must be a function">
    This error occurs when the metric parameter is not callable or doesn't have the correct signature.

    **Solution**: Ensure your metric is a function that takes `dataset_item` and `llm_output` as arguments and returns a `ScoreResult`:
    ```python
    from opik.evaluation.metrics import score_result

    def my_metric(dataset_item, llm_output):
        # Your scoring logic here
        score = calculate_score(dataset_item, llm_output)
        return ScoreResult(
          name="my-metric",
            value=score,
            reason="Explanation for the score"
        )
    ```
  </Accordion>

  <Accordion title="ValueError: Missing required key in prompt">
    This error occurs when your prompt template contains placeholders (e.g., `{variable}`) that don't match your dataset fields.

    **Solution**: Ensure all placeholders in your prompt match the keys in your dataset:
    ```python
    # Prompt with {question} placeholder
    prompt = ChatPrompt(
        user="Answer: {question}",
        model="gpt-4"
    )

    # Dataset must have 'question' field
    dataset = Dataset.from_list([
        {"question": "What is AI?", "output": "..."}
    ])
    ```
  </Accordion>

  <Accordion title="ImportError: gepa package is required for GepaOptimizer">
    This error occurs when trying to use the `GepaOptimizer` without the required `gepa` package installed.

    **Solution**: Install the gepa package:
    ```bash
    pip install gepa
    ```
  </Accordion>

  <Accordion title="Exception: Make sure you have provider API key set">
    This error typically occurs when the LLM provider API key is not configured in your environment.

    **Solution**: Set the appropriate environment variable for your LLM provider:
    ```bash
    # For OpenAI
    export OPENAI_API_KEY="your-api-key"

    # For Anthropic
    export ANTHROPIC_API_KEY="your-api-key"

    # For other providers, check the LiteLLM documentation
    ```
  </Accordion>
</AccordionGroup>

## Open challenges & advanced topics

<AccordionGroup>
  <Accordion title="Why do some optimized prompts look like gibberish?">
    Research has shown "evil twin" prompts and unusual delimiters can perform well despite being hard to interpret. Optimizers explore the search space indiscriminately, so high-performing instructions aren't always human-readable. When interpretability matters, prefer algorithms like HRPO that include reasoning traces or enforce structure via custom metrics.
  </Accordion>
  <Accordion title="How expensive are optimizers in terms of API calls?">
    Cost varies widely. Reflection-heavy optimizers (e.g., HRPO, GEPA) may call LLMs multiple times per trial, while MetaPrompt/Few-Shot Bayesian are lighter weight. Start with small `n_samples` and `max_trials`, monitor API usage, and review the [Benchmarks](/agent_optimization/algorithms/benchmarks) page for sample-efficiency notes.
  </Accordion>
  <Accordion title="Do optimized prompts generalize across tasks?">
    Optimizers tune prompts for the dataset you provide. Prompts may overfit if the dataset lacks coverage. Use diverse datasets, consider chaining optimizers (e.g., Evolutionary → Few-Shot Bayesian) to encourage generalization, and re-evaluate on unseen samples before shipping.
  </Accordion>
  <Accordion title="How can I avoid overfitting during optimization?">
    To prevent overfitting, use the `validation_dataset` parameter when calling `optimize_prompt()`. This separates your data into training (for generating prompt improvements) and validation (for evaluating candidate prompts). The optimizer will use the training dataset to understand failure modes and generate improvements, then rank candidates using the validation dataset. This mirrors standard ML practices and helps ensure your optimized prompt generalizes to unseen data.

    ```python
    result = optimizer.optimize_prompt(
        prompt=my_prompt,
        dataset=training_dataset,  # Used for analysis and improvements
        validation_dataset=validation_dataset,  # Used for ranking candidates
        metric=my_metric,
        max_trials=5,
    )
    ```

    If you don't provide a validation dataset, the optimizer will use the same dataset for both training and validation, which may lead to overfitting on that specific dataset. For best results, split your data 70/30 or 80/20 between training and validation sets.
  </Accordion>
  <Accordion title="Can I optimize for more than one objective (accuracy, cost, safety, etc.)?">
    Yes—compose metrics using `MultiMetricObjective` or custom heuristics so optimizers weigh multiple goals. For complex trade-offs, capture human preferences in the metric reasons, or explore Pareto-aware optimizers like GEPA that surface trade-offs between accuracy and cost.
  </Accordion>
  <Accordion title="What about multimodal or agent workflows?">
    Opik supports optimizing prompts that handle images/videos, as well as agents built with LangGraph, Google ADK, or MCP toolchains. Use the [Optimize agents](/agent_optimization/optimization/optimize_agents/overview) and [Optimize multimodal](/agent_optimization/optimization/optimize_multimodal) guides for modality-specific advice.
  </Accordion>
  <Accordion title="How reliable are optimizer metrics?">
    LLM-based metrics can be noisy. Always include deterministic checks when possible, and ensure your `ScoreResult.reason` is informative so reflective optimizers can identify true failure modes. See [Define metrics](/agent_optimization/optimization/define_metrics) and [Custom metrics](/agent_optimization/advanced/custom_metrics) for best practices.
  </Accordion>
  <Accordion title="Are there safety or ethical considerations?">
    Yes. When optimizing prompts that handle sensitive content, bake alignment constraints into your dataset/metrics (e.g., moderation scores) and review outputs manually before deployment. Multi-objective setups help enforce safety alongside accuracy.
  </Accordion>
</AccordionGroup>

## Next Steps

- Explore [API Reference](/agent_optimization/api-reference) for detailed technical documentation.
- Review the individual Optimizer pages under [Optimization Algorithms](/agent_optimization/overview#optimization-algorithms).
- Check out the [Quickstart Guide](/agent_optimization/optimizer-cookbooks/optimizer_introduction_cookbook).
