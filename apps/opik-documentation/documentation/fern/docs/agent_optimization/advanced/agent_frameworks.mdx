---
title: "Agent Framework Integrations"
subtitle: "Optimize LangGraph, Google ADK, DSPy, and other agents with Opik"
description: "A step-by-step guide for wiring your agent and where to find code samples."
---

Opik can optimize agents just as easily as static prompts. The only thing you have to provide is a
small wrapper that tells the optimizer how to run your agent.

## Quick recipe

1. **Start from a prompt** – Define a `ChatPrompt` with the messages your agent expects. Opik will
   substitute dataset values for placeholders like `{question}` during evaluation.
2. **Wrap your agent** – Subclass `OptimizableAgent`, store any framework-specific setup in
   `init_agent`, and implement `invoke(self, messages, seed=None)` to run the agent and return a
   final string. That method is your entry point for LangGraph, Google ADK, DSPy, etc.
3. **Pick an optimizer** – Call `optimizer.optimize_prompt(prompt=..., dataset=..., metric=...)`.
   Opik will call `invoke` for every row, track counters, and handle retries or tool calls.

That’s all—no custom evaluation loop required.

## What the optimizer does for you

- `BaseOptimizer.evaluate_prompt` converts your `ChatPrompt` into an `OptimizableAgent`. If you
  supply a custom class, it still runs through the same hook, so every optimizer (Parameter, GEPA,
  Hierarchical Reflective, MetaPrompt, etc.) speaks the same interface.
- The generated or custom agent is re-instantiated for every dataset item, so there’s no leftover
  state between evaluations.
- Counters, project metadata, and LiteLLM tool tracking are handled automatically; you only return
  the agent’s final answer.

## What `invoke` should do

`invoke(self, messages, seed=None) -> str` receives a list of chat-style dictionaries. All dataset
placeholders are already resolved. Your implementation should:

1. Convert those messages into whatever input your framework expects (execute the graph, run ADK,
   call DSPy, etc.).
2. Return the agent’s final textual reply. Opik records it, runs your metric, and moves to the next
   example.

If you need reproducibility, use the optional `seed` parameter to control randomness inside your
agent.

## Where to find examples

We keep concrete integrations in the repository so you can copy them:

- **LangGraph** – `sdks/opik_optimizer/scripts/llm_frameworks/langgraph/langgraph_agent.py`
- **Google ADK** – `sdks/opik_optimizer/scripts/llm_frameworks/adk/adk_agent.py`
- **DSPy (MIPROv2)** – `sdks/opik_optimizer/scripts/archive/dspy_mipro_hotpot_example.py`

Each script shows how to initialize the framework, implement `invoke`, and then hand the class to an
optimizer.

## Tips when building your own

- Keep `invoke` idempotent and avoid global state; Opik creates a new agent instance for each run.
- Use `ChatPrompt` placeholders for dataset fields so the optimizer can auto-fill them.
- Start by copying the example that’s closest to your stack and adjust the framework-specific code.

With that pattern, you can optimize virtually any agentic workflow while still benefiting from
Opik’s tracing, metrics, and prompt evolution algorithms.
