---
description: Start here to integrate Opik with the OpenRouter SDK for robust LLM observability.
headline: OpenRouter SDK | Opik Documentation
og:description: Track calls made via the official OpenRouter SDK with Opik.
og:site_name: Opik Documentation
og:title: Integrate OpenRouter SDK with Opik Easily
title: Observability for OpenRouter SDK with Opik
---

This guide explains how to integrate Opik with the official OpenRouter SDK.

Use this path when your code already uses a native OpenRouter client object.

<Tip>
If your traffic is routed through OpenRouter Gateway, follow the [OpenRouter Gateway](/docs/opik/integrations/openrouter-gateway/) guide.
</Tip>

If you use OpenRouter as an OpenAI-compatible endpoint without the official SDK:

- [OpenRouter Gateway](/docs/opik/integrations/openrouter-gateway/) for transport-level tracing
- [OpenAI-compatible integration docs](/docs/opik/integrations/openai-typescript/) / [OpenAI Python docs](/docs/opik/integrations/openai/) for wrapper-level fallback

## Option 1: Official OpenRouter SDK (recommended)

Use this path when your app uses the official OpenRouter SDK and you want typed spans with explicit OpenRouter source attribution.

<Tip>
OpenRouter routing metadata in spans is best-effort inferred from request/response model and provider fields where available. There is currently no guaranteed explicit `routing_provider`/`routing_model` field in the OpenRouter SDK integrations, so downstream route labels should be treated as inference rather than absolute ground truth.
</Tip>

<Tabs>
<Tab value="Python" title="Python">

:::note
Intent: choose this tab when your application already initializes a native OpenRouter Python client.
:::

```bash
pip install opik
```

### Required fields for OpenRouter payload

- `model` (required) - e.g., `openai/gpt-4`
- `messages` (required) - list of role/content messages

### Optional fields

- `stream`, `temperature`, `max_tokens`, `top_p`, `tools`, `response_format`, `tool_choice`
- `provider` (optional) - OpenRouter routing request object, e.g. `{ order: ["deepinfra/turbo"], allow_fallbacks: false }`

OpenRouter routing metadata is captured as `openrouter_routing` in span metadata.

```python
from opik.integrations.openrouter import track_openrouter

# Replace with your initialized OpenRouter SDK client instance.
openrouter_client = get_openrouter_client(api_key="YOUR_OPENROUTER_API_KEY")
tracked_client = track_openrouter(openrouter_client)

response = tracked_client.chat.send(
    model="openai/gpt-4",
    messages=[{"role": "user", "content": "Hello, world!"}],
)
```

### Minimal valid payload

```python
response = tracked_client.chat.send(
    model="openai/gpt-4",
    messages=[{"role": "user", "content": "Hello, world!"}],
)
```

:::note
When using `track_openrouter`, Opik records the source as `openrouter`.
:::

</Tab>
<Tab value="TypeScript" title="TypeScript">

:::note
Intent: choose this tab when your application already initializes an `@openrouter/sdk` `OpenRouter` client.
:::

```bash
npm install opik-openrouter opik @openrouter/sdk
```

### Required fields for OpenRouter payload

- `model` (required) - e.g., `openai/gpt-4`
- `messages` (required) - list of role/content messages

### Optional fields

- `stream`, `temperature`, `max_tokens`, `top_p`, `tools`, `response_format`, `tool_choice`
- `provider` (optional) - OpenRouter routing request object, e.g. `{ order: ["anthropic/claude-3-5-sonnet"], allow_fallbacks: false }`

OpenRouter routing metadata is captured as `openrouter_routing` in span metadata.

```ts
import { OpenRouter } from "@openrouter/sdk";
import { trackOpenRouter } from "opik-openrouter";

const openrouterClient = new OpenRouter({
  apiKey: process.env.OPENROUTER_API_KEY,
});

const trackedOpenRouter = trackOpenRouter(openrouterClient);

const response = await trackedOpenRouter.chat.send({
  model: "openai/gpt-4",
  messages: [{ role: "user", content: "Hello, world!" }],
});
```

### Minimal valid payload

```typescript
const response = await trackedOpenRouter.chat.send({
  model: "openai/gpt-4",
  messages: [{ role: "user", content: "Hello, world!" }],
});
```

</Tab>
</Tabs>

## Option 2: OpenAI-compatible path via OpenRouter

Use this path when you do not use the official OpenRouter SDK directly:

- Python: `track_openai` for OpenAI-style calls (OpenRouter base URL)
- TypeScript: `trackOpenAI` for OpenAI-style calls (OpenRouter base URL)

Then follow [OpenAI-compatible integration docs](/docs/opik/integrations/openai-typescript/) / [OpenAI Python docs](/docs/opik/integrations/openai/) for wrapper details.

## Canonical references

Use the examples in this page for both languages.

- `track_openrouter` (Python)
- `trackOpenRouter` (TypeScript)

OpenRouter-specific response metadata can also surface in trace `metadata` as:

- `openrouter_provider`
- `openrouter_routing`
- `openrouter_provider_name`
- `openrouter_provider_id`
- `openrouter_model_provider`

## Supported OpenRouter SDK methods

OpenRouter SDK integration tracks:

- `chat.send`
- `chat.send_async` (if available)

For complete API details from OpenRouter, see the [OpenRouter API documentation](https://openrouter.ai/docs).
