---
title: Alerts
description: Configure automated webhook notifications to stay informed about events in your Opik workspace, from trace errors to feedback scores and prompt changes.
---

Alerts allow you to configure automated webhook notifications for important events in your Opik workspace. When specific events occur â€” such as trace errors, new feedback scores, or prompt changes â€” Opik sends HTTP POST requests to your configured endpoint with detailed event data.

<Frame>
  <img src="/img/production/alerts_configuration.png" alt="Alerts configuration in Opik" />
</Frame>

## Creating an alert

### Prerequisites

- Access to the Opik Configuration page
- A webhook endpoint that can receive HTTP POST requests
- (Optional) An HTTPS endpoint with valid SSL certificate for production use

### Step-by-step guide

<Frame>
  <img src="/img/production/create_alert_form.png" alt="Create alert form" />
</Frame>

1. **Navigate to Alerts**
   - Go to Configuration â†’ Alerts tab
   - Click "Create new alert" button

2. **Configure basic settings**
   - **Name**: Give your alert a descriptive name (e.g., "Production Errors Slack")
   - **Enable alert**: Toggle on to activate the alert immediately

3. **Configure webhook settings**
   - **Endpoint URL**: Enter your webhook URL (must start with `http://` or `https://`)
   - Example: `https://hooks.slack.com/services/`

4. **Advanced webhook settings** (optional)
   - **Secret token**: Add a secret token to verify webhook authenticity
   - **Custom headers**: Add HTTP headers for authentication or routing
     - Example: `X-Custom-Auth: Bearer your-token-here`

5. **Add triggers**
   - Click "Add trigger" to select event types
   - Choose one or more event types from the list
   - Configure project scope for observability events (optional)

6. **Test your configuration**
   - Click "Test connection" to send a sample webhook
   - Verify your endpoint receives the test payload
   - Check the response status in the Opik UI

7. **Create the alert**
   - Click "Create alert" to save your configuration
   - The alert will start monitoring events immediately

## Integration examples

### Slack integration

Send alerts to a Slack channel using Slack's Incoming Webhooks:

1. [Create a Slack app and enable Incoming Webhooks](https://docs.slack.dev/messaging/sending-messages-using-incoming-webhooks/)
2. Create a webhook URL (e.g., `https://hooks.slack.com/services/T00000000/B00000000/XXXX`)
3. In Opik, create an alert with your Slack webhook URL
4. Format the payload (Slack will display JSON by default)

For better formatting, create a middleware service that transforms Opik's payload into Slack's Block Kit format:

```python
import requests

def transform_to_slack(opik_payload):
    event_type = opik_payload.get('eventType')
    alert_name = opik_payload['payload']['alertName']
    event_count = opik_payload['payload']['eventCount']
    
    return {
        "blocks": [
            {
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": f"ðŸš¨ {alert_name}"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"*{event_count}* new `{event_type}` events"
                }
            },
            {
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": f"View in Opik: https://www.comet.com/opik"
                }
            }
        ]
    }

@app.route('/opik-to-slack', methods=['POST'])
def opik_to_slack():
    opik_data = request.json
    slack_payload = transform_to_slack(opik_data)
    
    # Forward to Slack
    requests.post(
        SLACK_WEBHOOK_URL,
        json=slack_payload
    )
    
    return {'status': 'success'}, 200
```

### PagerDuty integration

Send critical alerts to PagerDuty for on-call incident management:

```python
import requests

PAGERDUTY_ROUTING_KEY = "your-routing-key"
PAGERDUTY_URL = "https://events.pagerduty.com/v2/enqueue"

@app.route('/opik-to-pagerduty', methods=['POST'])
def opik_to_pagerduty():
    data = request.json
    event_type = data.get('eventType')
    
    # Only send critical errors to PagerDuty
    if event_type != 'trace:errors':
        return {'status': 'ignored'}, 200
    
    payload = data['payload']
    errors = payload.get('metadata', [])
    
    # Create PagerDuty event
    pagerduty_payload = {
        "routing_key": PAGERDUTY_ROUTING_KEY,
        "event_action": "trigger",
        "payload": {
            "summary": f"{payload['alertName']}: {len(errors)} errors",
            "severity": "error",
            "source": "opik",
            "custom_details": {
                "event_count": payload['eventCount'],
                "errors": errors[:5]  # First 5 errors
            }
        }
    }
    
    response = requests.post(PAGERDUTY_URL, json=pagerduty_payload)
    return {'status': 'success'}, 200
```

### Using no-code automation platforms

No-code automation tools like [n8n](https://n8n.io), [Make.com](https://www.make.com), and [IFTTT](https://ifttt.com) provide an easy way to connect Opik alerts to other servicesâ€”without writing or deploying code. These platforms can receive webhooks from Opik, apply filters or conditions, and trigger actions such as sending Slack messages, logging data in Google Sheets, or creating incidents in PagerDuty.

<Frame>
  <img src="/img/production/no_code_automation_flow.png" alt="No-code automation flow example" />
</Frame>

**To use them:**

1. **Create a new workflow or scenario** and add a **Webhook trigger** node/module
2. **Copy the webhook URL** generated by the platform and paste it into your Opik alert configuration
3. **Secure the connection** by validating the Authorization header or including a secret token parameter
4. **Add filters or routing logic** to handle different eventType values from Opik (for example, trace:errors or trace:feedback_score)
5. **Chain the desired actions**, such as notifications, database updates, or analytics tracking

These tools also provide built-in monitoring, retries, and visual flow editors, making them suitable for both technical and non-technical users who want to automate Opik alert handling securely and efficiently.

### Custom dashboard integration

Build a custom monitoring dashboard that receives alerts:

```python
from fastapi import FastAPI, Request
from datetime import datetime

app = FastAPI()

# In-memory storage (use a database in production)
alert_history = []

@app.post("/webhook")
async def receive_webhook(request: Request):
    data = await request.json()
    
    # Store alert
    alert_history.append({
        'timestamp': datetime.utcnow(),
        'event_type': data.get('eventType'),
        'alert_name': data['payload']['alertName'],
        'event_count': data['payload']['eventCount'],
        'data': data
    })
    
    # Keep only last 1000 alerts
    if len(alert_history) > 1000:
        alert_history.pop(0)
    
    return {"status": "success"}

@app.get("/dashboard")
async def get_dashboard():
    # Return aggregated statistics
    return {
        'total_alerts': len(alert_history),
        'by_type': group_by_type(alert_history),
        'recent_alerts': alert_history[-10:]
    }
```

## Supported event types

Opik supports seven types of alert events:

### Observability events

**New error in trace**
- **Event type**: `trace:errors`
- **Triggered when**: A trace is logged with error information
- **Project scope**: Can be configured to specific projects
- **Payload**: Array of trace objects with error details
- **Use case**: Monitor production errors, debug issues in real-time

**New score added to trace**
- **Event type**: `trace:feedback_score`
- **Triggered when**: A feedback score is added to a trace
- **Project scope**: Can be configured to specific projects
- **Payload**: Array of feedback score objects
- **Use case**: Track model performance, monitor user satisfaction

**New score added to thread**
- **Event type**: `trace_thread:feedback_score`
- **Triggered when**: A feedback score is added to a conversation thread
- **Project scope**: Can be configured to specific projects
- **Payload**: Array of thread feedback score objects
- **Use case**: Monitor conversation quality, track multi-turn interactions

**Guardrails triggered**
- **Event type**: `trace:guardrails_triggered`
- **Triggered when**: A guardrail check fails for a trace
- **Project scope**: Can be configured to specific projects
- **Payload**: Array of guardrail result objects
- **Use case**: Security monitoring, compliance tracking, PII detection

### Prompt engineering events

**New prompt added**
- **Event type**: `prompt:created`
- **Triggered when**: A new prompt is created in the prompt library
- **Project scope**: Workspace-wide
- **Payload**: Prompt object with metadata
- **Use case**: Track prompt library changes, audit prompt creation

**New prompt version created**
- **Event type**: `prompt:committed`
- **Triggered when**: A new version (commit) is added to a prompt
- **Project scope**: Workspace-wide
- **Payload**: Prompt version object with template and metadata
- **Use case**: Monitor prompt iterations, track version history

**Prompt deleted**
- **Event type**: `prompt:deleted`
- **Triggered when**: A prompt is removed from the prompt library
- **Project scope**: Workspace-wide
- **Payload**: Array of deleted prompt objects
- **Use case**: Audit prompt deletions, maintain prompt governance

### Want us to support more event types?

If you need additional event types for your use case, please [create an issue on GitHub](https://github.com/comet-ml/opik/issues/new?title=Alert%20Event%20Request%3A%20%3Cevent-name%3E&labels=enhancement) and let us know what you'd like to monitor.

## Webhook payload structure

All webhook events follow a consistent payload structure:

```json
{
  "id": "webhook-event-id",
  "eventType": "trace:errors",
  "alertId": "alert-uuid",
  "alertName": "Production Errors Alert",
  "workspaceId": "workspace-uuid",
  "createdAt": "2025-01-15T10:30:00Z",
  "payload": {
    "alertId": "alert-uuid",
    "alertName": "Production Errors Alert",
    "eventType": "trace:errors",
    "eventIds": ["event-id-1", "event-id-2"],
    "userNames": ["user@example.com"],
    "eventCount": 2,
    "aggregationType": "consolidated",
    "message": "Alert 'Production Errors Alert': 2 trace:errors events aggregated",
    "metadata": [
      {
        "id": "trace-uuid",
        "name": "handle_query",
        "project_id": "project-uuid",
        "project_name": "Demo Project",
        "start_time": "2025-01-15T10:29:45Z",
        "end_time": "2025-01-15T10:29:50Z",
        "input": {
          "query": "User question"
        },
        "output": {
          "response": "LLM response"
        },
        "error_info": {
          "exception_type": "ValidationException",
          "message": "Validation failed",
          "traceback": "Full traceback..."
        },
        "metadata": {
          "customer_id": "customer_123"
        },
        "tags": ["production"]
      }
    ]
  }
}
```

### Payload fields

| Field | Type | Description |
|-------|------|-------------|
| `id` | string | Unique webhook event identifier |
| `eventType` | string | Type of event (e.g., `trace:errors`) |
| `alertId` | string (UUID) | Alert configuration identifier |
| `alertName` | string | Name of the alert |
| `workspaceId` | string | Workspace identifier |
| `createdAt` | string (ISO 8601) | Timestamp when webhook was created |
| `payload.eventIds` | array | List of aggregated event IDs |
| `payload.userNames` | array | Users associated with the events |
| `payload.eventCount` | number | Number of aggregated events |
| `payload.aggregationType` | string | Always "consolidated" |
| `payload.metadata` | array | Event-specific data (varies by event type) |

## Event-specific payloads

### Trace errors payload

```json
{
  "metadata": [
    {
      "id": "trace-uuid",
      "name": "trace-name",
      "project_id": "project-uuid",
      "project_name": "Project Name",
      "start_time": "2025-01-15T10:00:00Z",
      "end_time": "2025-01-15T10:00:05Z",
      "input": { "query": "..." },
      "output": { "response": "..." },
      "error_info": {
        "exception_type": "ExceptionName",
        "message": "Error message",
        "traceback": "Full traceback"
      },
      "metadata": { "custom": "data" },
      "tags": ["tag1", "tag2"]
    }
  ]
}
```

### Feedback score payload

```json
{
  "metadata": [
    {
      "id": "score-uuid",
      "name": "score-name",
      "value": 0.85,
      "reason": "Explanation of the score",
      "category_name": "quality",
      "source": "sdk",
      "author": "user@example.com"
    }
  ]
}
```

### Thread feedback score payload

```json
{
  "metadata": [
    {
      "thread_id": "thread-uuid",
      "name": "score-name",
      "value": 0.90,
      "reason": "Explanation of the score",
      "category_name": "satisfaction",
      "source": "sdk",
      "author": "user@example.com"
    }
  ]
}
```

### Prompt created payload

```json
{
  "metadata": {
    "id": "prompt-uuid",
    "name": "Prompt Name",
    "description": "Prompt description",
    "tags": ["system", "assistant"],
    "created_at": "2025-01-15T10:00:00Z",
    "created_by": "user@example.com",
    "last_updated_at": "2025-01-15T10:00:00Z",
    "last_updated_by": "user@example.com"
  }
}
```

### Prompt version created payload

```json
{
  "metadata": {
    "id": "version-uuid",
    "prompt_id": "prompt-uuid",
    "commit": "abc12345",
    "template": "You are a helpful assistant. {{question}}",
    "type": "mustache",
    "metadata": {
      "version": "1.0",
      "model": "gpt-4"
    },
    "created_at": "2025-01-15T10:00:00Z",
    "created_by": "user@example.com"
  }
}
```

### Prompt deleted payload

```json
{
  "metadata": [
    {
      "id": "prompt-uuid",
      "name": "Prompt Name",
      "description": "Prompt description",
      "tags": ["deprecated"],
      "created_at": "2025-01-10T10:00:00Z",
      "created_by": "user@example.com",
      "last_updated_at": "2025-01-15T10:00:00Z",
      "last_updated_by": "user@example.com",
      "latest_version": {
        "id": "version-uuid",
        "commit": "abc12345",
        "template": "Template content",
        "type": "mustache",
        "created_at": "2025-01-15T10:00:00Z",
        "created_by": "user@example.com"
      }
    }
  ]
}
```

### Guardrails triggered payload

```json
{
  "metadata": [
    {
      "id": "guardrail-check-uuid",
      "entity_id": "trace-uuid",
      "project_id": "project-uuid",
      "project_name": "Project Name",
      "name": "PII",
      "result": "failed",
      "details": {
        "detected_entities": ["EMAIL", "PHONE_NUMBER"],
        "message": "PII detected in response: email and phone number"
      }
    }
  ]
}
```

## Securing your webhooks

### Using secret tokens

Add a secret token to your webhook configuration to verify that incoming requests are from Opik:

1. Generate a secure random token (e.g., using `openssl rand -hex 32`)
2. Add it to your alert's "Secret token" field
3. Opik will send it in the `Authorization` header: `Authorization: Bearer your-secret-token`
4. Validate the token in your webhook handler before processing the request

### Example validation (Python/Flask)

```python
from flask import Flask, request, abort
import hmac

app = Flask(__name__)
SECRET_TOKEN = "your-secret-token-here"

@app.route('/webhook', methods=['POST'])
def handle_webhook():
    # Verify the secret token
    auth_header = request.headers.get('Authorization', '')
    if not auth_header.startswith('Bearer '):
        abort(401, 'Missing or invalid Authorization header')
    
    token = auth_header.split(' ', 1)[1]
    if not hmac.compare_digest(token, SECRET_TOKEN):
        abort(401, 'Invalid secret token')
    
    # Process the webhook
    data = request.json
    event_type = data.get('eventType')
    
    # Handle different event types
    if event_type == 'trace:errors':
        handle_trace_errors(data)
    elif event_type == 'trace:feedback_score':
        handle_feedback_score(data)
    
    return {'status': 'success'}, 200
```

### Using custom headers

You can add custom headers for additional authentication or routing:

```python
# In your webhook handler
api_key = request.headers.get('X-API-Key')
environment = request.headers.get('X-Environment')

if api_key != EXPECTED_API_KEY:
    abort(401, 'Invalid API key')

# Route to different handlers based on environment
if environment == 'production':
    handle_production_webhook(data)
else:
    handle_staging_webhook(data)
```

## Troubleshooting

### Webhooks not being delivered

**Check endpoint accessibility:**
- Ensure your endpoint is publicly accessible (if using cloud)
- Verify firewall rules allow incoming connections
- Test your endpoint with curl: `curl -X POST -H "Content-Type: application/json" -d '{"test": "data"}' https://your-endpoint.com/webhook`

**Check webhook configuration:**
- Verify the URL starts with `http://` or `https://`
- Check that the endpoint returns 2xx status codes
- Review custom headers for syntax errors

**Check alert status:**
- Ensure the alert is enabled
- Verify at least one trigger is configured
- Check that project scope matches your events (for observability events)

### Webhook timeouts

Opik expects webhooks to respond within the configured timeout (typically 30 seconds). If your endpoint takes longer:

**Optimize your handler:**
- Return a 200 response immediately
- Process the webhook asynchronously in the background
- Use a queue system (e.g., Celery, RabbitMQ) for long-running tasks

**Example async processing:**
```python
from flask import Flask
from threading import Thread

app = Flask(__name__)

def process_webhook_async(data):
    # Long-running processing
    send_to_slack(data)
    update_dashboard(data)
    log_to_database(data)

@app.route('/webhook', methods=['POST'])
def handle_webhook():
    data = request.json
    
    # Start background processing
    thread = Thread(target=process_webhook_async, args=(data,))
    thread.start()
    
    # Return immediately
    return {'status': 'accepted'}, 200
```

### Duplicate webhooks

If you receive duplicate webhooks:

**Check retry configuration:**
- Opik retries failed webhooks with exponential backoff
- Ensure your endpoint returns 2xx status codes on success
- Implement idempotency using the webhook `id` field

**Example idempotent handler:**
```python
processed_webhook_ids = set()

@app.route('/webhook', methods=['POST'])
def handle_webhook():
    data = request.json
    webhook_id = data.get('id')
    
    # Skip if already processed
    if webhook_id in processed_webhook_ids:
        return {'status': 'already_processed'}, 200
    
    # Process webhook
    process_alert(data)
    
    # Mark as processed
    processed_webhook_ids.add(webhook_id)
    
    return {'status': 'success'}, 200
```

### Events not triggering alerts

**Check event type matching:**
- Verify the alert has a trigger for this event type
- For observability events, check project scope configuration
- Review project IDs in trigger configuration

**Check workspace context:**
- Ensure events are logged to the correct workspace
- Verify the alert is in the same workspace as your events

**Check alert evaluation:**
- View backend logs for alert evaluation messages
- Confirm events are being published to the event bus
- Check Redis for alert buckets (self-hosted deployments)

### SSL certificate errors

If you see SSL certificate errors in logs:

**For development/testing:**
- Use self-signed certificates with proper configuration
- Or use HTTP endpoints (not recommended for production)

**For production:**
- Use valid SSL certificates from trusted CAs
- Ensure certificate chain is complete
- Check certificate expiry dates
- Use services like Let's Encrypt for free SSL

## Architecture and internals

Understanding Opik's alert architecture can help with troubleshooting and optimization.

### How alerts work

The Opik Alerts system monitors your workspace for specific events and sends consolidated webhook notifications to your configured endpoints. Here's the flow:

1. **Event occurs**: An event happens in your workspace (e.g., a trace error, new feedback score)
2. **Alert evaluation**: The system checks if any enabled alerts match this event type
3. **Event aggregation**: Multiple events are aggregated over a short time window (debouncing)
4. **Webhook delivery**: A consolidated HTTP POST request is sent to your webhook URL
5. **Retry handling**: Failed requests are automatically retried with exponential backoff

#### Event debouncing

To prevent overwhelming your webhook endpoint, Opik aggregates multiple events of the same type within a short time window (typically 30-60 seconds) and sends them as a single consolidated webhook. This is particularly useful for high-frequency events like feedback scores.

### Event flow

```
1. Event occurs (e.g., trace error logged)
   â†“
2. Service publishes AlertEvent to EventBus
   â†“
3. AlertEventListener receives event
   â†“
4. AlertEventEvaluationService evaluates against configured alerts
   â†“
5. Matching events added to AlertBucketService (Redis)
   â†“
6. AlertJob (runs every 5 seconds) processes ready buckets
   â†“
7. WebhookPublisher publishes to Redis stream
   â†“
8. WebhookSubscriber consumes from stream
   â†“
9. WebhookHttpClient sends HTTP POST request
   â†“
10. Retries on failure with exponential backoff
```

### Debouncing mechanism

Opik uses Redis-based buckets to aggregate events:

- **Bucket key format**: `alert_bucket:{alertId}:{eventType}`
- **Window size**: Configurable (default 30-60 seconds)
- **Index**: Redis Sorted Set for efficient bucket retrieval
- **TTL**: Buckets expire automatically after processing

This prevents overwhelming your webhook endpoint with individual events and reduces costs for high-frequency events.

### Retry strategy

Failed webhooks are automatically retried:

- **Max retries**: Configurable (default 3)
- **Initial delay**: 1 second
- **Max delay**: 60 seconds
- **Backoff**: Exponential with jitter
- **Retryable errors**: 5xx status codes, network errors
- **Non-retryable errors**: 4xx status codes (except 429)

## Best practices

### Alert design

**Create focused alerts:**
- Use separate alerts for different purposes (e.g., one for errors, one for feedback)
- Configure project scope to avoid noise from test projects
- Use descriptive names that explain the alert's purpose

**Optimize for your workflow:**
- Send critical errors to PagerDuty or on-call systems
- Route feedback scores to analytics platforms
- Send prompt changes to audit logs or Slack channels

**Test thoroughly:**
- Use the "Test connection" feature before enabling alerts
- Monitor webhook delivery in your endpoint logs
- Start with a small project scope and expand gradually

### Webhook endpoint design

**Handle failures gracefully:**
- Return 2xx status codes immediately
- Process webhooks asynchronously
- Implement retry logic in your handler
- Use dead letter queues for permanent failures

**Implement security:**
- Always validate secret tokens
- Use HTTPS endpoints with valid certificates
- Implement rate limiting to prevent abuse
- Log all webhook attempts for auditing

**Monitor performance:**
- Track webhook processing time
- Alert on handler failures
- Monitor queue lengths for async processing
- Set up dead letter queue monitoring

### Scaling considerations

**For high-volume workspaces:**
- Use event debouncing (built-in)
- Implement batch processing in your handler
- Use message queues for async processing
- Consider using serverless functions (AWS Lambda, Cloud Functions)

**For multiple projects:**
- Create project-specific alerts with scope configuration
- Use custom headers to route to different handlers
- Implement filtering in your webhook handler
- Consider separate endpoints for different event types

## Next steps

- Configure your first alert for production error monitoring
- Set up Slack integration for team notifications
- Explore [Online Evaluation Rules](/production/rules) for automated model monitoring
- Learn about [Guardrails](/production/guardrails) for proactive risk detection
- Review [Production Monitoring](/production/production_monitoring) best practices

