---
headline: Scaling Opik | Opik Documentation
og:description: Learn best practices and configurations for running Opik in production,
  ensuring resilience and scalability for mission-critical workloads.
og:site_name: Opik Documentation
og:title: Scaling Opik for High-Volume Deployments
subtitle: Comprehensive guide for scaling Opik in production environments
title: Scaling Opik
---

# Scaling Opik

Opik is built to power mission-critical workloads at scale. Whether you're running a small proof of concept or a high-volume enterprise deployment, Opik adapts seamlessly to your needs. Its stateless architecture and powerful ClickHouse backed storage make it highly resilient, horizontally scalable, and future-proof for your data growth.

This guide outlines recommended configurations and best practices for running Opik in production.

## Proven at Scale

Opik is engineered to handle demanding, production-grade workloads. The following example demonstrates the robustness of a typical deployment:

| Metric | Value |
|--------|-------|
| Select queries per second | ~80 |
| Insert queries per second | ~20 |
| Rows inserted per minute | Up to 75K |
| Traces (count) | 40 million |
| Traces (size) | 400 GB |
| Spans (count) | 250M  |
| Spans (size) | 3.1 TB |
| Total data on disk | 5 TB |
| Weekly data ingestion | 100 GB |

A deployment of this scale is fully supported using:

**Opik Services** - 
  These Opik Services run on r7i.2xlarge instances with 2 replicas:
  - Opik Backend
  - Opik Frontend
  
  The Opik Python Backend service runs on c7i.2xlarge instances with 3 replicas:

**ClickHouse** - running on m7i.8xlarge instances with 2 replicas.

This configuration provides both performance and reliability while leaving room for seamless expansion.

## Built for Growth

Opik is designed with flexibility at its core. As your data grows and query volumes increase, Opik grows with you.

- **Horizontal scaling** - add more replicas of services to instantly handle more traffic
- **Vertical scaling** - increase CPU, memory, or storage to handle denser workloads  
- **Seamless elasticity** - scale out during peak usage and scale back during quieter periods

For larger workloads, ClickHouse can be scaled to support enterprise-level deployments. A common configuration includes:

- 62 CPU cores
- 256 GB RAM
- 25 TB disk space

ClickHouse's read path can also scale horizontally by increasing replicas, ensuring Opik continues to deliver high performance as usage grows.

## Resilient Services Cluster

Opik services are stateless and fault-tolerant, ensuring high availability across environments. Recommended resources:

| Environment | CPU (vCPU) | RAM (GB) |
|-------------|------------|----------|
| Development | 4 | 8 |
| Production | 13 | 32 |

### Instance Guidance

| Deployment | Instance | vCPUs | Memory (GiB) |
|------------|----------|-------|--------------|
| Dev (small) | c7i.large | 2 | 4 |
| Dev | c7i.xlarge | 4 | 8 |
| Prod (small) | c7i.2xlarge | 8 | 16 |
| Prod | c7i.4xlarge | 16 | 32 |

### Backend Service (Scales to Demand)

| Metric | Dev | Prod Small | Prod Large |
|--------|-----|------------|------------|
| Replicas | 2 | 5 | 7 |
| CPU cores | 1 | 2 | 2 |
| Memory (GiB) | 2 | 9 | 12 |

### Frontend Service (Always Responsive)

| Metric | Dev | Prod Small | Prod Large |
|--------|-----|------------|------------|
| Replicas | 2 | 3 | 5 |
| CPU (millicores) | 5 | 50 | 50 |
| Memory (MiB) | 16 | 32 | 64 |

## ClickHouse: High-Performance Storage

At the heart of Opik's scalability is ClickHouse, a proven, high-performance analytical database designed for large-scale workloads. Opik leverages ClickHouse for storing traces and spans, ensuring fast queries, robust ingestion, and uncompromising reliability.

### Instance Types

Memory-optimized instances are recommended, with a minimum 4:1 memory-to-CPU ratio:

| Deployment | Instance |
|------------|----------|
| Small | m7i.2xlarge |
| Medium | m7i.4xlarge |
| Large | m7i.8xlarge |

### Replication Strategy

- **Development**: 1 replica
- **Production**: 2 replicas

Always scale vertically before adding more replicas for efficiency.

### CPU & Memory Guidance

Target 10–20% CPU utilization, with safe spikes up to 40–50%.

Maintain at least a 4:1 memory-to-CPU ratio (extend to 8:1 for very large environments).

| Deployment | CPU cores | Memory (GiB) |
|------------|-----------|--------------|
| Minimum | 2 | 8 |
| Development | 4 | 16 |
| Production (small) | 6 | 24 |
| Production | 32 | 128 |

### Disk Recommendations

To ensure reliable performance under heavy load:

| Volume | Value |
|--------|-------|
| Family | SSD |
| Type | gp3 |
| Size | 8–16 TiB (workload dependent) |
| IOPS | 3000 |
| Throughput | 250 MiB/s |

Opik's ClickHouse layer is resilient even under sustained, large-scale ingestion, ensuring queries stay fast.

## Managing System Tables

System tables (e.g., `system.opentelemetry_span_log`) can grow quickly. To keep storage lean:

- Configure TTL settings in ClickHouse, or
- Perform periodic manual pruning

## Why Opik Scales with Confidence

- **Enterprise-ready** — built to support multi-terabyte data volumes
- **Elastic & flexible** — easily adjust resources to match workload demands
- **Robust & reliable** — designed for high availability and long-term stability
- **Future-proof** — proven to support growing usage without redesign

With Opik, you can start small and scale confidently, knowing your observability platform won't hold you back.

## References

- [ClickHouse sizing & hardware recommendations](https://clickhouse.com/docs/guides/sizing-and-hardware-recommendations)