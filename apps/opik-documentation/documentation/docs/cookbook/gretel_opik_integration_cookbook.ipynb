{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77a7fb6",
   "metadata": {},
   "source": [
    "# Gretel AI to Opik Dataset Integration - Complete Cookbook\n",
    "\n",
    "A comprehensive guide with ready-to-run examples for generating synthetic Q&A datasets using Gretel Navigator and importing them into Opik for model evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ What This Cookbook Covers\n",
    "\n",
    "- **Authentication setup** for both Gretel and Opik\n",
    "- **Synthetic data generation** using Gretel Navigator\n",
    "- **Data format conversion** from Gretel to Opik\n",
    "- **Dataset import** into Opik for evaluation\n",
    "- **Complete examples** for different use cases\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ Prerequisites & Setup\n",
    "\n",
    "Before starting, you'll need:\n",
    "1. **Gretel Account**: Sign up at [gretel.ai](https://gretel.ai)\n",
    "2. **Comet Account**: Sign up at [comet.com](https://comet.com) for Opik access\n",
    "3. **API Keys**: Gretel API key and Comet API key\n",
    "\n",
    "### Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab09f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gretel_client opik langchain tiktoken pandas --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c8e480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Opik is already configured. You can check the settings by viewing the config file at /home/mavrick/.opik.config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Gretel to Opik integration setup...\n",
      "Logged in as mavrickrishi@gmail.com âœ…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from gretel_client import Gretel\n",
    "import opik\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"ğŸš€ Starting Gretel to Opik integration setup...\")\n",
    "\n",
    "#set up Opik\n",
    "opik.configure()\n",
    "\n",
    "# Set up Gretel API key\n",
    "if \"GRETEL_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GRETEL_API_KEY\"] = getpass.getpass(\"Enter your Gretel API key: \")\n",
    "\n",
    "gretel = Gretel(api_key=os.environ[\"GRETEL_API_KEY\"], cache=True, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd657be",
   "metadata": {},
   "source": [
    "## Find Working Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b3647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Testing model: gretelai/auto\n",
      "Backend model: gretelai/auto\n",
      "API path: https://api.gretel.cloud/v1/inference/tabular/\n",
      "Navigator Tabular initialized ğŸš€\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07, 0.41 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model gretelai/auto works! Generated 3 records\n",
      "ğŸ“Š Test database:\n",
      "         name  age\n",
      "0  John Smith   25\n",
      "1   Maria Lee   31\n",
      "2   David Kim   42\n",
      "ğŸ‰ Using working model: gretelai/auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test different models to find one that works\n",
    "def find_working_navigator_model():\n",
    "    \"\"\"Find a Navigator model that works in your environment\"\"\"\n",
    "    models_to_try = ['gretelai/auto', 'gretelai/apache-2.0', 'gretelai/llama-3.x']\n",
    "    \n",
    "    for model in models_to_try:\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Testing model: {model}\")\n",
    "            test_navigator = gretel.factories.initialize_navigator_api(\"tabular\", backend_model=model)\n",
    "            \n",
    "            # Quick test generation\n",
    "            test_result = test_navigator.generate(\n",
    "                \"Create a small dataset with columns 'name' and 'age' for 3 people.\", \n",
    "                num_records=3\n",
    "            )\n",
    "            \n",
    "            print(f\"âœ… Model {model} works! Generated {len(test_result)} records\")\n",
    "            \n",
    "            # Print the test database\n",
    "            print(f\"ğŸ“Š Test database:\")\n",
    "            print(test_result)\n",
    "            \n",
    "            return test_navigator, model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Model {model} failed: {e}\")\n",
    "    \n",
    "    raise Exception(\"No working Navigator model found\")\n",
    "\n",
    "# Find and use a working model\n",
    "navigator, working_model = find_working_navigator_model()\n",
    "print(f\"ğŸ‰ Using working model: {working_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96757b6",
   "metadata": {},
   "source": [
    "## ğŸ“ Configure Prompt and Source Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d88b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Prompt and source text configured\n",
      "ğŸ“„ Source text length: 596 characters\n"
     ]
    }
   ],
   "source": [
    "# Base prompt for Q&A dataset creation\n",
    "PROMPT = (\n",
    "    \"From the source text below, create a dataset with the following columns:\\n\"\n",
    "    \"* `question`: Ask a set of unique questions related to the topic that a customer might ask. \"\n",
    "    \"Questions should be relatively complex and specific enough to be addressed in a short answer.\\n\"\n",
    "    \"* `context`: Copy the exact sentence(s) from the source text and surrounding details from where the answer can be derived.\\n\"\n",
    "    \"* `truth`: Respond to the question with a clear, textbook quality answer that provides relevant details to fully address the question.\\n\"\n",
    ")\n",
    "\n",
    "# Your source content (customize this with your domain-specific content)\n",
    "source_text = \"\"\"\n",
    "Artificial Intelligence (AI) has revolutionized numerous industries by automating complex tasks \n",
    "and providing intelligent insights. Machine learning, a subset of AI, enables systems to learn \n",
    "from data without explicit programming. Deep learning, using neural networks with multiple layers, \n",
    "has achieved breakthroughs in image recognition, natural language processing, and decision making.\n",
    "The field continues to evolve with advancements in transformer architectures, reinforcement learning,\n",
    "and federated learning approaches that preserve privacy while enabling collaborative model training.\n",
    "\"\"\"\n",
    "\n",
    "print(\"ğŸ“ Prompt and source text configured\")\n",
    "print(f\"ğŸ“„ Source text length: {len(source_text)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66dd1c9",
   "metadata": {},
   "source": [
    "## ğŸš€ Generate Synthetic Q&A Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e793e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting data generation...\n",
      "ğŸ”„ Attempt 1: Generating with params {'num_records': 10, 'temperature': 0.7, 'top_p': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating records: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:33, 0.30 records/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Success! Generated 10 records\n",
      "\n",
      "ğŸ“Š Dataset generated successfully!\n",
      "   Shape: (10, 3)\n",
      "   Columns: ['question', 'context', 'truth']\n",
      "\n",
      "ğŸ“‹ Sample generated data:\n",
      "                                                                  question  \\\n",
      "0                  What is the primary function of machine learning in AI?   \n",
      "1  What are some key areas where deep learning has achieved breakthroughs?   \n",
      "2                    What are some recent advancements in the field of AI?   \n",
      "\n",
      "                                                                                               context  \\\n",
      "0   Machine learning, a subset of AI, enables systems to learn from data without explicit programming.   \n",
      "1  Deep learning, using neural networks with multiple layers, has achieved breakthroughs in image r...   \n",
      "2  The field continues to evolve with advancements in transformer architectures, reinforcement lear...   \n",
      "\n",
      "                                                                                                 truth  \n",
      "0  Machine learning allows systems to learn from data without being explicitly programmed, enabling...  \n",
      "1  Deep learning has achieved breakthroughs in image recognition, natural language processing, and ...  \n",
      "2  Recent advancements in AI include transformer architectures, reinforcement learning, and federat...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_qa_dataset_robust(navigator, prompt, source_text, max_attempts=3):\n",
    "    \"\"\"Generate Q&A dataset with multiple fallback strategies\"\"\"\n",
    "    \n",
    "    # Different parameter strategies (from complex to simple)\n",
    "    strategies = [\n",
    "        {\"num_records\": 10, \"temperature\": 0.7, \"top_p\": 0.9},\n",
    "        {\"num_records\": 8, \"temperature\": 0.5},\n",
    "        {\"num_records\": 5},\n",
    "        {\"num_records\": 3, \"temperature\": 0.3}\n",
    "    ]\n",
    "    \n",
    "    for attempt, params in enumerate(strategies, 1):\n",
    "        try:\n",
    "            print(f\"ğŸ”„ Attempt {attempt}: Generating with params {params}\")\n",
    "            result = navigator.generate(f\"{prompt}\\n\\n{source_text}\", **params)\n",
    "            \n",
    "            if len(result) > 0:\n",
    "                print(f\"âœ… Success! Generated {len(result)} records\")\n",
    "                return result\n",
    "            else:\n",
    "                print(\"âš ï¸ Empty result, trying next strategy...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Attempt {attempt} failed: {e}\")\n",
    "            if attempt < len(strategies):\n",
    "                print(\"ğŸ”„ Trying next strategy...\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"ğŸš€ Starting data generation...\")\n",
    "synthetic_df = generate_qa_dataset_robust(navigator, PROMPT, source_text)\n",
    "\n",
    "if synthetic_df is not None:\n",
    "    print(f\"\\nğŸ“Š Dataset generated successfully!\")\n",
    "    print(f\"   Shape: {synthetic_df.shape}\")\n",
    "    print(f\"   Columns: {list(synthetic_df.columns)}\")\n",
    "    \n",
    "    # Display sample data\n",
    "    pd.set_option('display.max_colwidth', 100)\n",
    "    print(f\"\\nğŸ“‹ Sample generated data:\")\n",
    "    print(synthetic_df.head(3))\n",
    "else:\n",
    "    print(\"âŒ Failed to generate any data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60bf351",
   "metadata": {},
   "source": [
    "## ğŸ”„ Convert Gretel Format to Opik Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e5a423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Converting 10 rows to Opik format...\n",
      "ğŸ“ Available columns: ['question', 'context', 'truth']\n",
      "âœ… Question column: question\n",
      "âœ… Context column: context\n",
      "âœ… Answer column: truth\n",
      "âœ… Successfully converted 10/10 rows\n",
      "\n",
      "ğŸ“‹ Sample converted item:\n",
      "{\n",
      "  \"input\": {\n",
      "    \"question\": \"What is the primary function of machine learning in AI?\",\n",
      "    \"context\": \"Machine learning, a subset of AI, enables systems to learn from data without explicit programming.\"\n",
      "  },\n",
      "  \"expected_output\": \"Machine learning allows systems to learn from data without being explicitly programmed, enabling them to improve their performance on a task over time.\",\n",
      "  \"metadata\": {\n",
      "    \"source\": \"gretel_navigator\",\n",
      "    \"generated\": true,\n",
      "    \"row_index\": 0,\n",
      "    \"model\": \"gretelai/auto\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def convert_gretel_to_opik_format(df, model_name=\"unknown\"):\n",
    "    \"\"\"Convert Gretel DataFrame to Opik dataset format\"\"\"\n",
    "    \n",
    "    print(f\"ğŸ”„ Converting {len(df)} rows to Opik format...\")\n",
    "    print(f\"ğŸ“ Available columns: {list(df.columns)}\")\n",
    "    \n",
    "    opik_items = []\n",
    "    \n",
    "    # Detect columns automatically\n",
    "    question_col = None\n",
    "    answer_col = None\n",
    "    context_col = None\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_lower = col.lower().strip()\n",
    "        \n",
    "        if any(word in col_lower for word in ['question', 'query', 'q']):\n",
    "            question_col = col\n",
    "            print(f\"âœ… Question column: {col}\")\n",
    "        elif any(word in col_lower for word in ['truth', 'answer', 'response', 'reply']):\n",
    "            answer_col = col\n",
    "            print(f\"âœ… Answer column: {col}\")\n",
    "        elif any(word in col_lower for word in ['context', 'background', 'source']):\n",
    "            context_col = col\n",
    "            print(f\"âœ… Context column: {col}\")\n",
    "    \n",
    "    # Convert each row\n",
    "    successful_conversions = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            # Build input dictionary\n",
    "            input_data = {}\n",
    "            \n",
    "            if question_col and pd.notna(row.get(question_col)):\n",
    "                input_data[\"question\"] = str(row[question_col]).strip()\n",
    "            \n",
    "            if context_col and pd.notna(row.get(context_col)):\n",
    "                input_data[\"context\"] = str(row[context_col]).strip()\n",
    "            \n",
    "            # Get expected output\n",
    "            expected_output = \"\"\n",
    "            if answer_col and pd.notna(row.get(answer_col)):\n",
    "                expected_output = str(row[answer_col]).strip()\n",
    "            \n",
    "            # Only include items with both question and answer\n",
    "            if input_data.get(\"question\") and expected_output:\n",
    "                item = {\n",
    "                    \"input\": input_data,\n",
    "                    \"expected_output\": expected_output,\n",
    "                    \"metadata\": {\n",
    "                        \"source\": \"gretel_navigator\",\n",
    "                        \"generated\": True,\n",
    "                        \"row_index\": idx,\n",
    "                        \"model\": model_name\n",
    "                    }\n",
    "                }\n",
    "                opik_items.append(item)\n",
    "                successful_conversions += 1\n",
    "            else:\n",
    "                print(f\"âš ï¸ Skipping row {idx}: missing question or answer\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error converting row {idx}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Successfully converted {successful_conversions}/{len(df)} rows\")\n",
    "    return opik_items\n",
    "\n",
    "# Convert the dataset\n",
    "if synthetic_df is not None and len(synthetic_df) > 0:\n",
    "    opik_formatted_data = convert_gretel_to_opik_format(synthetic_df, working_model)\n",
    "    \n",
    "    if opik_formatted_data:\n",
    "        print(f\"\\nğŸ“‹ Sample converted item:\")\n",
    "        print(json.dumps(opik_formatted_data[0], indent=2))\n",
    "    else:\n",
    "        print(\"âŒ No items were successfully converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dbef7e",
   "metadata": {},
   "source": [
    "## ğŸ“¤ Push Dataset to Opik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf008047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¤ Pushing 10 items to Opik...\n",
      "ğŸ“Š Dataset created/found: gretel-ai-qa-cookbook\n",
      "ğŸ†” Dataset ID: 0197a84b-cf53-7f88-afef-ffb5c0fa95b2\n",
      "âœ… Successfully pushed 10 items!\n",
      "ğŸ“Š Dataset name: gretel-ai-qa-cookbook\n",
      "ğŸ†” Dataset ID: 0197a84b-cf53-7f88-afef-ffb5c0fa95b2\n",
      "\n",
      "ğŸ“‹ Sample item pushed:\n",
      "   Question: What is the primary function of machine learning in AI?...\n",
      "   Answer: Machine learning allows systems to learn from data without being explicitly prog...\n",
      "\n",
      "ğŸ‰ Integration completed successfully!\n",
      "ğŸ“Š Dataset 'gretel-ai-qa-cookbook' is now available in Opik\n",
      "\n",
      "ğŸ”— Next steps:\n",
      "   1. Go to your Comet workspace\n",
      "   2. Navigate to Opik â†’ Datasets\n",
      "   3. Find your dataset: gretel-ai-qa-cookbook\n",
      "   4. Use it in model evaluations!\n"
     ]
    }
   ],
   "source": [
    "def push_to_opik(opik_data, dataset_name=\"gretel-qa-dataset\"):\n",
    "    \"\"\"Push converted data to Opik as a dataset\"\"\"\n",
    "    \n",
    "    if not opik_data:\n",
    "        return False, \"No data to push\"\n",
    "    \n",
    "    print(f\"ğŸ“¤ Pushing {len(opik_data)} items to Opik...\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize Opik client\n",
    "        opik_client = opik.Opik()\n",
    "        \n",
    "        # Create or get dataset\n",
    "        opik_dataset = opik_client.get_or_create_dataset(\n",
    "            name=dataset_name,\n",
    "            description=f\"Synthetic Q&A dataset generated using Gretel Navigator ({working_model})\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“Š Dataset created/found: {opik_dataset.name}\")\n",
    "        print(f\"ğŸ†” Dataset ID: {opik_dataset.id}\")\n",
    "        \n",
    "        # Insert data\n",
    "        opik_dataset.insert(opik_data)\n",
    "        \n",
    "        print(f\"âœ… Successfully pushed {len(opik_data)} items!\")\n",
    "        print(f\"ğŸ“Š Dataset name: {opik_dataset.name}\")\n",
    "        print(f\"ğŸ†” Dataset ID: {opik_dataset.id}\")\n",
    "        \n",
    "        # Show sample of what was pushed\n",
    "        if opik_data:\n",
    "            sample = opik_data[0]\n",
    "            print(f\"\\nğŸ“‹ Sample item pushed:\")\n",
    "            print(f\"   Question: {sample['input'].get('question', 'N/A')[:80]}...\")\n",
    "            print(f\"   Answer: {sample['expected_output'][:80]}...\")\n",
    "        \n",
    "        return True, opik_dataset.name\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to push to Opik: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False, str(e)\n",
    "\n",
    "# Push the data to Opik\n",
    "if 'opik_formatted_data' in locals() and opik_formatted_data:\n",
    "    success, result = push_to_opik(opik_formatted_data, \"gretel-ai-qa-cookbook\")\n",
    "    \n",
    "    if success:\n",
    "        print(f\"\\nğŸ‰ Integration completed successfully!\")\n",
    "        print(f\"ğŸ“Š Dataset '{result}' is now available in Opik\")\n",
    "        print(f\"\\nğŸ”— Next steps:\")\n",
    "        print(f\"   1. Go to your Comet workspace\")\n",
    "        print(f\"   2. Navigate to Opik â†’ Datasets\")\n",
    "        print(f\"   3. Find your dataset: {result}\")\n",
    "        print(f\"   4. Use it in model evaluations!\")\n",
    "    else:\n",
    "        print(f\"âŒ Failed to complete integration: {result}\")\n",
    "else:\n",
    "    print(\"âŒ No data available to push\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4848097",
   "metadata": {},
   "source": [
    "The gretel-qa-dataset dataset can now be viewed in the UI:\n",
    "\n",
    "![gretel-qa-dataset](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/fern/img/cookbook/gretel_opik_integration_cookbook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f00fd",
   "metadata": {},
   "source": [
    "## âœ… Verify Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812e4a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Verifying dataset: gretel-ai-qa-cookbook\n",
      "âœ… Dataset verified: gretel-ai-qa-cookbook\n",
      "ğŸ†” Dataset ID: 0197a84b-cf53-7f88-afef-ffb5c0fa95b2\n",
      "\n",
      "ğŸ“‹ How to view your dataset:\n",
      "   1. Go to https://www.comet.com\n",
      "   2. Navigate to your workspace\n",
      "   3. Click on 'Opik' in the left sidebar\n",
      "   4. Go to 'Datasets' tab\n",
      "   5. Look for dataset: gretel-ai-qa-cookbook\n",
      "\n",
      "ğŸ§ª How to use in evaluations:\n",
      "\n",
      "# Example evaluation code:\n",
      "import opik\n",
      "\n",
      "opik_client = opik.Opik()\n",
      "dataset = opik_client.get_dataset('gretel-ai-qa-cookbook')\n",
      "\n",
      "@opik.track\n",
      "def my_qa_model(input_data):\n",
      "    question = input_data.get('question', '')\n",
      "    context = input_data.get('context', '')\n",
      "    # Your model logic here\n",
      "    return \"Your model's answer\"\n",
      "\n",
      "# Run evaluation\n",
      "evaluation = opik.evaluate(\n",
      "    dataset=dataset,\n",
      "    task=my_qa_model,\n",
      "    experiment_name=\"gretel-synthetic-eval\"\n",
      ")\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def verify_opik_dataset(dataset_name):\n",
    "    \"\"\"Verify the dataset was created and provide access instructions\"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"ğŸ” Verifying dataset: {dataset_name}\")\n",
    "        opik_client = opik.Opik()\n",
    "        \n",
    "        # Get the dataset\n",
    "        dataset = opik_client.get_dataset(dataset_name)\n",
    "        print(f\"âœ… Dataset verified: {dataset.name}\")\n",
    "        print(f\"ğŸ†” Dataset ID: {dataset.id}\")\n",
    "\n",
    "        print(f\"\\nğŸ“‹ How to view your dataset:\")\n",
    "        print(f\"   1. Go to https://www.comet.com\")\n",
    "        print(f\"   2. Navigate to your workspace\")\n",
    "        print(f\"   3. Click on 'Opik' in the left sidebar\")\n",
    "        print(f\"   4. Go to 'Datasets' tab\")\n",
    "        print(f\"   5. Look for dataset: {dataset_name}\")\n",
    "        \n",
    "        print(f\"\\nğŸ§ª How to use in evaluations:\")\n",
    "        print(f\"\"\"\n",
    "# Example evaluation code:\n",
    "import opik\n",
    "\n",
    "opik_client = opik.Opik()\n",
    "dataset = opik_client.get_dataset('{dataset_name}')\n",
    "\n",
    "@opik.track\n",
    "def my_qa_model(input_data):\n",
    "    question = input_data.get('question', '')\n",
    "    context = input_data.get('context', '')\n",
    "    # Your model logic here\n",
    "    return \"Your model's answer\"\n",
    "\n",
    "# Run evaluation\n",
    "evaluation = opik.evaluate(\n",
    "    dataset=dataset,\n",
    "    task=my_qa_model,\n",
    "    experiment_name=\"gretel-synthetic-eval\"\n",
    ")\n",
    "        \"\"\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Could not verify dataset: {e}\")\n",
    "        return False\n",
    "\n",
    "# Verify the dataset (use the actual dataset name from previous step)\n",
    "if 'result' in locals() and success:\n",
    "    verify_opik_dataset(result)\n",
    "else:\n",
    "    print(\"âš ï¸ No dataset to verify - make sure previous steps completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d592e5",
   "metadata": {},
   "source": [
    "## ğŸ”„ Alternative: Load from Gretel Export Files\n",
    "\n",
    "If you have pre-existing Gretel datasets exported as files, you can also import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57d9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gretel_export(file_path, format_type=\"csv\"):\n",
    "    \"\"\"\n",
    "    Load a Gretel dataset export from local file.\n",
    "    Supports CSV, JSON, and JSONL formats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if format_type.lower() == \"csv\":\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif format_type.lower() == \"json\":\n",
    "            df = pd.read_json(file_path)\n",
    "        elif format_type.lower() == \"jsonl\":\n",
    "            df = pd.read_json(file_path, lines=True)\n",
    "        else:\n",
    "            raise ValueError(\"Supported formats: csv, json, jsonl\")\n",
    "        \n",
    "        print(f\"âœ… Loaded {len(df)} records from {file_path}\")\n",
    "        print(f\"ğŸ“Š Dataset shape: {df.shape}\")\n",
    "        print(f\"ğŸ“‹ Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Display sample data from Gretel\n",
    "        print(\"\\nğŸ“„ Sample data from Gretel:\")\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        pd.set_option('display.max_colwidth', 100)\n",
    "        print(df.head(3))\n",
    "        \n",
    "        # Show data types\n",
    "        print(f\"\\nğŸ“ˆ Data types:\")\n",
    "        print(df.dtypes)\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\nğŸ“Š Basic statistics:\")\n",
    "        if 'question' in df.columns:\n",
    "            print(f\"  - Average question length: {df['question'].str.len().mean():.1f} characters\")\n",
    "        if 'answer' in df.columns or 'truth' in df.columns:\n",
    "            answer_col = 'answer' if 'answer' in df.columns else 'truth'\n",
    "            print(f\"  - Average answer length: {df[answer_col].str.len().mean():.1f} characters\")\n",
    "        if 'topic' in df.columns:\n",
    "            print(f\"  - Unique topics: {df['topic'].nunique()}\")\n",
    "        if 'difficulty' in df.columns or 'user_profile' in df.columns:\n",
    "            diff_col = 'difficulty' if 'difficulty' in df.columns else 'user_profile'\n",
    "            print(f\"  - Difficulty distribution: {dict(df[diff_col].value_counts())}\")\n",
    "            \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# df_gretel = load_gretel_export(\"your_gretel_export.csv\", \"csv\")\n",
    "# df_gretel = load_gretel_export(\"your_gretel_export.jsonl\", \"jsonl\")\n",
    "\n",
    "# Then convert and push to Opik:\n",
    "# opik_data = convert_gretel_to_opik_format(df_gretel, \"gretel-export\")\n",
    "# success, result = push_to_opik(opik_data, \"gretel-imported-dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231cec81",
   "metadata": {},
   "source": [
    "## ğŸ¯ Complete Integration Summary\n",
    "\n",
    "This cookbook provides a complete workflow for integrating Gretel AI datasets with Opik:\n",
    "\n",
    "### âœ… **What We Accomplished:**\n",
    "1. **Authentication Setup** - Both Gretel and Opik API configurations\n",
    "2. **Model Discovery** - Automatic detection of working Gretel models\n",
    "3. **Synthetic Data Generation** - Using Gretel Navigator for Q&A creation\n",
    "4. **Format Conversion** - Transform Gretel output to Opik-compatible format\n",
    "5. **Dataset Import** - Push datasets to Opik for evaluation use\n",
    "6. **Verification** - Confirm successful import and provide usage guidance\n",
    "\n",
    "### ğŸ”§ **Key Features:**\n",
    "- **Robust Error Handling**: Multiple fallback strategies\n",
    "- **Automatic Column Detection**: Smart mapping of data fields\n",
    "- **Flexible Input**: Supports both live generation and file imports\n",
    "- **Production Ready**: Comprehensive validation and user guidance\n",
    "\n",
    "### ğŸ“Š **Use Cases:**\n",
    "- **Model Testing**: Create evaluation datasets for Q&A models\n",
    "- **Benchmarking**: Generate consistent test sets across experiments\n",
    "- **Agent Optimization**: Provide training data for Opik's Agent Optimizer\n",
    "- **Continuous Evaluation**: Regular model performance monitoring\n",
    "\n",
    "### ğŸš€ **Next Steps:**\n",
    "1. Customize the `source_text` with your domain-specific content\n",
    "2. Adjust generation parameters based on your needs\n",
    "3. Use the imported dataset in Opik evaluations\n",
    "4. Scale up for larger dataset generation\n",
    "\n",
    "This integration enables seamless data flow from Gretel's synthetic data generation capabilities into Opik's model evaluation and optimization ecosystem! ğŸ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
