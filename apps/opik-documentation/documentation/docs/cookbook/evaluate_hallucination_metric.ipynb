{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Opik's Hallucination Metric\n",
    "\n",
    "For this guide we will be evaluating the Hallucination metric included in the LLM Evaluation SDK which will showcase both how to use the `evaluation` functionality in the platform as well as the quality of the Hallucination metric included in the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an account on Comet.com\n",
    "\n",
    "[Comet](https://www.comet.com/site/?from=llm&utm_source=opik&utm_medium=colab&utm_content=eval_hall&utm_campaign=opik) provides a hosted version of the Opik platform, [simply create an account](https://www.comet.com/signup?from=llm&utm_source=opik&utm_medium=colab&utm_content=eval_hall&utm_campaign=opik) and grab you API Key.\n",
    "\n",
    "> You can also run the Opik platform locally, see the [installation guide](https://www.comet.com/docs/opik/self-host/overview/?from=llm&utm_source=opik&utm_medium=colab&utm_content=eval_hall&utm_campaign=opik) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opik in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (1.0.3)\n",
      "Requirement already satisfied: pyarrow in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (17.0.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-18.0.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (2024.9.0)\n",
      "Collecting fsspec\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface_hub in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (0.24.7)\n",
      "Collecting huggingface_hub\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (8.1.7)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (0.27.2)\n",
      "Requirement already satisfied: levenshtein~=0.25.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (0.25.1)\n",
      "Requirement already satisfied: litellm in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (1.49.1)\n",
      "Requirement already satisfied: openai<2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (1.52.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (2.2.2)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (2.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (2.8.2)\n",
      "Requirement already satisfied: pytest in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (8.3.2)\n",
      "Requirement already satisfied: rich in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (13.7.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (4.66.5)\n",
      "Requirement already satisfied: questionary in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (2.0.1)\n",
      "Requirement already satisfied: uuid7<1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from opik) (0.1.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from huggingface_hub) (3.15.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1.0.0->opik) (4.4.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1.0.0->opik) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1.0.0->opik) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1.0.0->opik) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpx<1.0.0->opik) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->opik) (0.14.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from levenshtein~=0.25.1->opik) (3.9.6)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai<2.0.0->opik) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from openai<2.0.0->opik) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pandas<3.0.0,>=2.0.0->opik) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pandas<3.0.0,>=2.0.0->opik) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pandas<3.0.0,>=2.0.0->opik) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pandas<3.0.0,>=2.0.0->opik) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->opik) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.0.0->opik) (2.20.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.0.0->opik) (1.0.1)\n",
      "Requirement already satisfied: aiohttp in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (3.10.3)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (8.2.0)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (3.1.4)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (4.23.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (0.7.0)\n",
      "Requirement already satisfied: tokenizers in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from litellm->opik) (0.19.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: iniconfig in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pytest->opik) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from pytest->opik) (1.5.0)\n",
      "Requirement already satisfied: prompt_toolkit<=3.0.36,>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from questionary->opik) (3.0.36)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from rich->opik) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from rich->opik) (2.18.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm->opik) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm->opik) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm->opik) (0.20.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->opik) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from prompt_toolkit<=3.0.36,>=2.0->questionary->opik) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.0.0->opik) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm->opik) (2024.7.24)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from aiohttp->litellm->opik) (2.3.5)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from aiohttp->litellm->opik) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/py312_llm_eval/lib/python3.12/site-packages (from aiohttp->litellm->opik) (1.9.4)\n",
      "Downloading pyarrow-18.0.0-cp312-cp312-macosx_12_0_arm64.whl (29.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Downloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Installing collected packages: pyarrow, fsspec, huggingface_hub\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 17.0.0\n",
      "    Uninstalling pyarrow-17.0.0:\n",
      "      Successfully uninstalled pyarrow-17.0.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.24.7\n",
      "    Uninstalling huggingface-hub-0.24.7:\n",
      "      Successfully uninstalled huggingface-hub-0.24.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.9.0.post1 requires fsspec==2024.9.0, but you have fsspec 2024.10.0 which is incompatible.\n",
      "predibase 2024.9.3 requires urllib3==1.26.12, but you have urllib3 2.2.3 which is incompatible.\n",
      "datasets 2.21.0 requires fsspec[http]<=2024.6.1,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed fsspec-2024.10.0 huggingface_hub-0.26.2 pyarrow-18.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opik pyarrow fsspec huggingface_hub --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPIK: Opik is already configured. You can check the settings by viewing the config file at /Users/jacquesverre/.opik.config\n"
     ]
    }
   ],
   "source": [
    "import opik\n",
    "\n",
    "opik.configure(use_local=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our environment\n",
    "\n",
    "First, we will install configure the OpenAI API key and create a new Opik dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [HaluBench dataset](https://huggingface.co/datasets/PatronusAI/HaluBench?library=pandas) which according to this [paper](https://arxiv.org/pdf/2407.08488) GPT-4o detects 87.9% of hallucinations. The first step will be to create a dataset in the platform so we can keep track of the results of the evaluation.\n",
    "\n",
    "Since the insert methods in the SDK deduplicates items, we can insert 50 items and if the items already exist, Opik will automatically remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "import opik\n",
    "import pandas as pd\n",
    "\n",
    "client = opik.Opik()\n",
    "\n",
    "# Create dataset\n",
    "dataset = client.get_or_create_dataset(\n",
    "    name=\"HaluBench\", description=\"HaluBench dataset\"\n",
    ")\n",
    "\n",
    "# Insert items into dataset\n",
    "df = pd.read_parquet(\n",
    "    \"hf://datasets/PatronusAI/HaluBench/data/test-00000-of-00001.parquet\"\n",
    ")\n",
    "df = df.sample(n=50, random_state=42)\n",
    "\n",
    "dataset_records = [\n",
    "    {\n",
    "        \"input\": x[\"question\"],\n",
    "        \"context\": [x[\"passage\"]],\n",
    "        \"output\": x[\"answer\"],\n",
    "        \"expected_output\": x[\"label\"],\n",
    "    } for x in df.to_dict(orient=\"records\")\n",
    "]\n",
    "\n",
    "dataset.insert(dataset_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the hallucination metric\n",
    "\n",
    "In order to evaluate the performance of the Opik hallucination metric, we will define:\n",
    "\n",
    "- Evaluation task: Our evaluation task will use the data in the Dataset to return a hallucination score computed using the Opik hallucination metric.\n",
    "- Scoring metric: We will use the `Equals` metric to check if the hallucination score computed matches the expected output.\n",
    "\n",
    "By defining the evaluation task in this way, we will be able to understand how well Opik's hallucination metric is able to detect hallucinations in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 100/100 [00:22<00:00,  4.49it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ HaluBench (100 samples) ─────────────────╮\n",
       "│                                           │\n",
       "│ <span style=\"font-weight: bold\">Total time:       </span> 00:00:22               │\n",
       "│ <span style=\"font-weight: bold\">Number of samples:</span> 100                    │\n",
       "│                                           │\n",
       "│ <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Correct hallucination score: 0.8100 (avg)</span> │\n",
       "│                                           │\n",
       "╰───────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ HaluBench (100 samples) ─────────────────╮\n",
       "│                                           │\n",
       "│ \u001b[1mTotal time:       \u001b[0m 00:00:22               │\n",
       "│ \u001b[1mNumber of samples:\u001b[0m 100                    │\n",
       "│                                           │\n",
       "│ \u001b[1;32mCorrect hallucination score: 0.8100 (avg)\u001b[0m │\n",
       "│                                           │\n",
       "╰───────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Uploading results to Opik <span style=\"color: #808000; text-decoration-color: #808000\">...</span> \n",
       "</pre>\n"
      ],
      "text/plain": [
       "Uploading results to Opik \u001b[33m...\u001b[0m \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">View the results <a href=\"https://www.comet.com/opik/jacques-comet/experiments/0192ba7d-67d1-70da-b19e-00f1c7b03339/compare?experiments=%5B%22067215da-e88a-788e-8000-f400b5344778%22%5D\" target=\"_blank\">in your Opik dashboard</a>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "View the results \u001b]8;id=510002;https://www.comet.com/opik/jacques-comet/experiments/0192ba7d-67d1-70da-b19e-00f1c7b03339/compare?experiments=%5B%22067215da-e88a-788e-8000-f400b5344778%22%5D\u001b\\in your Opik dashboard\u001b]8;;\u001b\\.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from opik.evaluation.metrics import Hallucination, Equals\n",
    "from opik.evaluation import evaluate\n",
    "from opik import Opik\n",
    "from opik.evaluation.metrics.llm_judges.hallucination.template import generate_query\n",
    "from typing import Dict\n",
    "\n",
    "# Define the evaluation task\n",
    "def evaluation_task(x: Dict):\n",
    "    metric = Hallucination()\n",
    "    try:\n",
    "        metric_score = metric.score(\n",
    "            input=x[\"input\"], context=x[\"context\"], output=x[\"output\"]\n",
    "        )\n",
    "        hallucination_score = metric_score.value\n",
    "        hallucination_reason = metric_score.reason\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        hallucination_score = None\n",
    "        hallucination_reason = str(e)\n",
    "\n",
    "    return {\n",
    "        \"output\": \"FAIL\" if hallucination_score == 1 else \"PASS\",\n",
    "        \"hallucination_reason\": hallucination_reason,\n",
    "        \"reference\": x[\"expected_output\"],\n",
    "    }\n",
    "\n",
    "\n",
    "# Get the dataset\n",
    "client = Opik()\n",
    "dataset = client.get_dataset(name=\"HaluBench\")\n",
    "\n",
    "# Define the scoring metric\n",
    "check_hallucinated_metric = Equals(name=\"Correct hallucination score\")\n",
    "\n",
    "# Add the prompt template as an experiment configuration\n",
    "experiment_config = {\n",
    "    \"prompt_template\": generate_query(\n",
    "        input=\"{input}\", context=\"{context}\", output=\"{output}\", few_shot_examples=[]\n",
    "    )\n",
    "}\n",
    "\n",
    "res = evaluate(\n",
    "    dataset=dataset,\n",
    "    task=evaluation_task,\n",
    "    scoring_metrics=[check_hallucinated_metric],\n",
    "    experiment_config=experiment_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the hallucination metric is able to detect ~80% of the hallucinations contained in the dataset and we can see the specific items where hallucinations were not detected.\n",
    "\n",
    "![Hallucination Evaluation](https://raw.githubusercontent.com/comet-ml/opik/main/apps/opik-documentation/documentation/static/img/cookbook/hallucination_metric_cookbook.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
