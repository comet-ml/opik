---
description: ClickHouse SQL query guidelines for opik-backend
globs: apps/opik-backend/**/*
alwaysApply: false
---
# ClickHouse SQL Query Guidelines

Comprehensive guidelines for writing and maintaining ClickHouse SQL queries embedded as Java String literals in the Opik backend.

## Core Principles

### **Schema-First Development**

- **Never invent schema**: Always verify table names, column names, and types from migration files
- **Check migrations first**: Review `src/main/resources/liquibase/db-app-analytics/migrations/` before writing queries
- **Find similar queries**: Search for existing queries that access the same tables before implementing new ones
- **Reuse patterns**: Match established query patterns for consistency and correctness

### **Query Development Workflow**

1. **Find similar query**: Search for existing queries accessing the same tables
2. **Verify schema**: Check migration files for table structure and column types
3. **Implement change**: Write query following established patterns
4. **Update mapping**: Ensure Java row mappers match query output aliases
5. **Test query**: Verify query works with actual data

## Schema Verification

### **Migration File Locations**

- **ClickHouse migrations**: `src/main/resources/liquibase/db-app-analytics/migrations/`
- **Migration naming**: `000001_description.sql`, `000002_description.sql`, etc.
- **Schema source of truth**: Migration files define all tables, columns, and types

### **Common ClickHouse Tables**

```sql
-- Core analytics tables (from 000001_init_script.sql)
traces (
    id              FixedString(36),
    workspace_id    String,
    project_id      FixedString(36),
    name            String,
    start_time      DateTime64(9, 'UTC'),
    end_time        Nullable(DateTime64(9, 'UTC')),
    input           String,
    output          String,
    metadata        String,
    tags            Array(String),
    created_at      DateTime64(9, 'UTC'),
    last_updated_at DateTime64(9, 'UTC'),
    created_by      String,
    last_updated_by String,
    thread_id       String,
    error_info      String,
    visibility_mode Enum8('unknown' = 0, 'default' = 1, 'hidden' = 2) DEFAULT 'default'
) ENGINE = ReplacingMergeTree(last_updated_at)
  ORDER BY (workspace_id, project_id, id);

spans (
    id              FixedString(36),
    workspace_id    String,
    project_id      FixedString(36),
    trace_id        FixedString(36),
    parent_span_id  String,
    name            String,
    type            Enum8('unknown' = 0, 'general' = 1, 'tool' = 2, 'llm' = 3),
    start_time      DateTime64(9, 'UTC'),
    end_time        Nullable(DateTime64(9, 'UTC')),
    input           String,
    output          String,
    metadata        String,
    tags            Array(String),
    usage           Map(String, Int32),
    total_estimated_cost Decimal(38, 12),  -- Changed from Decimal128(12) in migration 000017
    created_at      DateTime64(9, 'UTC'),
    last_updated_at DateTime64(9, 'UTC'),
    created_by      String,
    last_updated_by String,
    model           String,
    error_info      String
) ENGINE = ReplacingMergeTree(last_updated_at)
  ORDER BY (workspace_id, project_id, trace_id, parent_span_id, id);

feedback_scores (
    entity_id       FixedString(36),
    entity_type     ENUM('unknown' = 0, 'span' = 1, 'trace' = 2, 'thread' = 3),
    project_id      FixedString(36),
    workspace_id    String,
    name            String,
    category_name   String,
    value           Decimal64(9),
    reason          String,
    source          Enum8('sdk', 'ui'),
    created_at      DateTime64(9, 'UTC'),
    last_updated_at DateTime64(9, 'UTC'),
    created_by      String,
    last_updated_by String
) ENGINE = ReplacingMergeTree(last_updated_at)
  ORDER BY (workspace_id, project_id, entity_type, entity_id, name);

experiments (
    workspace_id    String,
    dataset_id      FixedString(36),
    id              FixedString(36),
    name            String,
    metadata        String,
    tags            Array(String),  -- Added in migration 000051
    created_at      DateTime64(9, 'UTC'),
    last_updated_at DateTime64(9, 'UTC'),
    created_by      String,
    last_updated_by String,
    prompt_version_id Nullable(FixedString(36)),  -- Made nullable in migration 000017
    prompt_id       Nullable(FixedString(36)),    -- Made nullable in migration 000017
    prompt_versions Map(FixedString(36), Array(FixedString(36))),  -- Updated in migration 000017
    type            ENUM('regular' = 0, 'trial' = 1, 'mini-batch' = 2),  -- Updated in migration 000021
    optimization_id String,  -- Changed from FixedString(36) in migration 000021
    status          ENUM('running' = 0, 'completed' = 1, 'cancelled' = 2),
    experiment_scores String,  -- Added in migration 000049
    dataset_version_id String  -- Added in migration 000050
) ENGINE = ReplacingMergeTree(last_updated_at)
  ORDER BY (workspace_id, dataset_id, id);
```

### **Before Writing Queries**

```java
// ✅ Good: Check migrations first
// 1. Review src/main/resources/liquibase/db-app-analytics/migrations/000001_init_script.sql
// 2. Check for schema changes in later migrations (e.g., 000002_change_decimal_precision.sql)
// 3. Verify column types match (Decimal64(9), DateTime64(9, 'UTC'), etc.)

// ❌ Bad: Assume schema without verification
// Don't write queries based on assumptions about table structure
```

## ReplacingMergeTree Deduplication

All ClickHouse analytics tables use `ReplacingMergeTree` engine, which requires explicit deduplication to get the latest version of each row.

### **Three Deduplication Patterns**

```java
// Pattern 1: FINAL (simplest, but potentially slower for large tables)
private static final String QUERY = """
    SELECT *
    FROM traces FINAL
    WHERE workspace_id = :workspace_id
    AND project_id = :project_id
    ;
    """;

// Pattern 2: ORDER BY + LIMIT 1 BY (more explicit, better performance)
private static final String QUERY = """
    SELECT *
    FROM traces
    WHERE workspace_id = :workspace_id
    AND project_id = :project_id
    ORDER BY (workspace_id, project_id, id) DESC, last_updated_at DESC
    LIMIT 1 BY id
    ;
    """;

// Pattern 3: CTE with deduplication (best for complex queries with multiple table references)
private static final String QUERY = """
    WITH feedback_scores_final AS (
        SELECT *
        FROM feedback_scores
        WHERE entity_type = 'trace'
        AND workspace_id = :workspace_id
        ORDER BY (workspace_id, project_id, entity_id, name) DESC, last_updated_at DESC
        LIMIT 1 BY entity_id, name
    )
    SELECT * FROM feedback_scores_final
    ;
    """;

// ❌ Bad: Missing deduplication - will return duplicate rows
private static final String QUERY = """
    SELECT *
    FROM traces
    WHERE workspace_id = :workspace_id
    ;
    """;
```

### **When to Use Each Pattern**

- **FINAL**: Simplest syntax, use for small tables or when performance is not critical
- **ORDER BY + LIMIT 1 BY**: Better performance than FINAL, use when you need explicit ordering control
- **CTE with deduplication**: Use when the deduplicated result is referenced multiple times in the same query (avoids redundant deduplication)

## String Template Engine Patterns

### **Conditional SQL with <if>**

```java
// ✅ Good: Use StringTemplate conditionals for optional filters
private static final String QUERY = """
    SELECT *
    FROM traces FINAL
    WHERE workspace_id = :workspace_id
    <if(project_id)> AND project_id = :project_id <endif>
    <if(uuid_from_time)> AND id >= :uuid_from_time <endif>
    <if(uuid_to_time)> AND id \\<= :uuid_to_time <endif>
    <if(filters)> AND <filters> <endif>
    ;
    """;

// Note: Escape < in comparisons: \\<
```

### **Template Rendering and Binding**

```java
// ✅ Good: Render template, then bind parameters
var template = getSTWithLogComment(QUERY, "queryName", workspaceId, projectId)
        .add("project_id", true)  // Add flags for conditionals
        .add("uuid_from_time", true);

var statement = connection.createStatement(template.render())
        .bind("workspace_id", workspaceId)
        .bind("project_id", projectId)
        .bind("uuid_from_time", uuidFromTime.toString());

// Bind optional parameters conditionally
if (request.uuidToTime() != null) {
    statement.bind("uuid_to_time", request.uuidToTime().toString());
}
```

## Parameter Binding Conventions

### **Parameter Naming**

```java
// ✅ Good: Use snake_case for ClickHouse parameters
.bind("workspace_id", workspaceId)
.bind("project_id", projectId)
.bind("uuid_from_time", uuidFromTime)
.bind("uuid_to_time", uuidToTime)

// ❌ Bad: Don't use camelCase for ClickHouse parameters
.bind("workspaceId", workspaceId)
.bind("projectId", projectId)
```

### **Parameter Types**

```java
// ✅ Good: Bind correct types
statement.bind("workspace_id", workspaceId);          // String
statement.bind("project_id", projectId.toString());   // String (FixedString(36))
statement.bind("limit", limit);                       // int
statement.bind("offset", offset);                     // int
statement.bind("tags", tags.toArray(new String[0]));  // Array

// ✅ Good: Convert UUIDs to strings
statement.bind("uuid_from_time", uuid.toString());

// ❌ Bad: Don't bind null directly, use conditional binding
if (value != null) {
    statement.bind("param", value);
}
```

## ClickHouse-Specific Functions

### **Quantiles for Percentiles**

```java
// ✅ Good: Use quantiles (plural) for multiple percentiles
"""
SELECT
    arrayMap(
        v -> toDecimal64(
            greatest(
                least(if(isFinite(v), v, 0), 999999999.999999999),
                -999999999.999999999
            ),
            9
        ),
        quantiles(0.5, 0.9, 0.99)(duration)
    ) AS duration
FROM traces_filtered
GROUP BY bucket
;
"""

// ❌ Bad: Don't use quantile (singular) for multiple values
quantile(0.5)(duration), quantile(0.9)(duration), quantile(0.99)(duration)
```

### **Handling NaN and Infinity**

```java
// ✅ Good: Always clamp numeric values to prevent NaN/Inf
toDecimal64(
    greatest(
        least(if(isFinite(v), v, 0), 999999999.999999999),
        -999999999.999999999
    ),
    9
)

// Pattern: isFinite check → clamp to max → clamp to min → convert to Decimal
```

### **Decimal Precision**

```java
// ✅ Good: Use correct Decimal types from schema
Decimal64(9)    // For feedback scores (from 000002_change_decimal_precision.sql)
Decimal(38, 12) // For total_estimated_cost (from 000017_change_tables_to_replicated.sql)

// ✅ Good: Convert aggregations to Decimal
toDecimal64(avg(value), 9)
toDecimal128(sum(total_estimated_cost), 12)  // Use Decimal128 for aggregations

// ❌ Bad: Don't use incorrect precision
toDecimal64(total_estimated_cost, 9)  // Should be Decimal(38, 12)
```

### **Array and Map Operations**

```java
// ✅ Good: ARRAY JOIN for expanding arrays
"""
SELECT span_time, name, value
FROM spans_filtered s
ARRAY JOIN mapKeys(usage) AS name, mapValues(usage) AS value
WHERE value > 0
;
"""

// ✅ Good: Map aggregation functions
sumMap(usage)           // Sum maps by key
avgMap(usage)           // Average maps by key
mapFromArrays(keys, values)  // Create map from arrays

// ✅ Good: Array functions
arrayConcat([prompt_id], mapKeys(prompt_versions))
groupArray(value)
arrayMap(x -> x * 2, values)
```

### **Date/Time Functions**

```java
// ✅ Good: Use ClickHouse date functions
UUIDv7ToDateTime(toUUID(id))  // Convert UUIDv7 to DateTime
toStartOfInterval(time, toIntervalDay(1))  // Bucket by day
dateDiff('microsecond', start_time, end_time)  // Time difference
parseDateTime64BestEffort(:timestamp, 9)  // Parse timestamp

// ✅ Good: Time interval constants
toIntervalWeek(1)
toIntervalDay(1)
toIntervalHour(1)
```

### **Duration Calculation Pattern**

```java
// ✅ Good: Standard duration calculation with null checks
"""
if(end_time IS NOT NULL AND start_time IS NOT NULL
    AND notEquals(start_time, toDateTime64('1970-01-01 00:00:00.000', 9)),
    (dateDiff('microsecond', start_time, end_time) / 1000.0),
    NULL) AS duration
"""

// Pattern: Check both times exist → Check start_time is not epoch → Calculate diff in microseconds → Convert to milliseconds
```

## Common Query Patterns

### **WITH Clause (CTEs)**

```java
// ✅ Good: Use CTEs for complex queries
private static final String QUERY = """
    WITH feedback_scores_combined_raw AS (
        SELECT workspace_id, project_id, entity_id, name, value
        FROM feedback_scores FINAL
        WHERE entity_type = 'trace'
        AND workspace_id = :workspace_id
        UNION ALL
        SELECT workspace_id, project_id, entity_id, name, value
        FROM authored_feedback_scores FINAL
        WHERE entity_type = 'trace'
        AND workspace_id = :workspace_id
    ), feedback_scores_with_ranking AS (
        SELECT *,
            ROW_NUMBER() OVER (
                PARTITION BY workspace_id, project_id, entity_id, name, author
                ORDER BY last_updated_at DESC
            ) as rn
        FROM feedback_scores_combined_raw
    ), feedback_scores_final AS (
        SELECT *
        FROM feedback_scores_with_ranking
        WHERE rn = 1
    )
    SELECT * FROM feedback_scores_final
    ;
    """;
```

### **Aggregation Patterns**

```java
// ✅ Good: Conditional aggregation
if(count() = 1, any(value), toDecimal64(avg(value), 9)) AS value

// ✅ Good: Filtering aggregations
countIf(error_info, error_info != '')
avgIf(total_estimated_cost, total_estimated_cost > 0)
sumIf(total_estimated_cost, total_estimated_cost > 0)

// ✅ Good: Group by with HAVING
GROUP BY entity_id
HAVING <feedback_scores_filters>
```

### **WITH FILL for Time Series**

```java
// ✅ Good: Fill gaps in time series data
"""
SELECT <bucket> AS bucket, count(*) as count
FROM traces_filtered
GROUP BY bucket
ORDER BY bucket
<if(with_fill)>WITH FILL
    FROM <fill_from>
    TO toDateTime(UUIDv7ToDateTime(toUUID(:uuid_to_time)))
    STEP <step><endif>
;
"""
```

## Query Output and Java Mapping

### **Column Aliases**

```java
// ✅ Good: Use clear aliases that match Java field names
"""
SELECT
    t.id as id,
    t.name as name,
    t.workspace_id as workspace_id,
    fs.feedback_scores as feedback_scores,
    ed.duration_values AS duration
FROM traces t
;
"""

// Java mapping:
row.get("id", String.class)
row.get("name", String.class)
row.get("workspace_id", String.class)
row.get("feedback_scores", Map.class)
row.get("duration", List.class)
```

### **Complex Type Mapping**

```java
// ✅ Good: Map complex ClickHouse types to Java
// Map(String, Decimal64) → Map<String, BigDecimal>
row.get("feedback_scores", Map.class)

// Array(Decimal64) → List<BigDecimal>
row.get("duration", List.class)

// Tuple → Custom mapping
Optional.ofNullable(row.get("duration", List.class))
    .map(durations -> Stream.of(
        Entry.builder().name("p50").value(getP(durations, 0)).build(),
        Entry.builder().name("p90").value(getP(durations, 1)).build(),
        Entry.builder().name("p99").value(getP(durations, 2)).build()
    ))
```

## Performance Considerations

### **Query Optimization**

```java
// ✅ Good: Filter early in CTEs
WITH traces_scope AS (
    SELECT id
    FROM traces
    WHERE workspace_id = :workspace_id
    AND project_id = :project_id
    <if(uuid_from_time)> AND id >= :uuid_from_time <endif>
    ORDER BY (workspace_id, project_id, id) DESC, last_updated_at DESC
    LIMIT 1 BY id
)
SELECT * FROM traces_scope;

// ✅ Good: Use IN subqueries for filtering
WHERE entity_id IN (SELECT trace_id FROM experiment_items_final)

// ❌ Bad: Don't fetch all data then filter in Java
SELECT * FROM traces;  // Then filter in Java
```

### **LIMIT 1 BY Performance**

```java
// ✅ Good: Use LIMIT 1 BY for better performance than FINAL
FROM traces
WHERE workspace_id = :workspace_id
ORDER BY (workspace_id, project_id, id) DESC, last_updated_at DESC
LIMIT 1 BY id

// Note: This is often faster than FINAL for large tables
```

## Error Prevention

### **Common Mistakes**

```java
// ❌ Bad: Incorrect comparison operator escaping
WHERE id <= :uuid_to_time  // Will break in StringTemplate

// ✅ Good: Escape comparison operators
WHERE id \\<= :uuid_to_time

// ❌ Bad: Using wrong Decimal precision
toDecimal64(total_estimated_cost, 9)

// ✅ Good: Match schema precision (Decimal(38, 12) from migration 000017)
toDecimal128(total_estimated_cost, 12)

// ❌ Bad: Not handling NaN/Inf
quantiles(0.5, 0.9, 0.99)(duration)

// ✅ Good: Clamp values
arrayMap(v -> toDecimal64(greatest(least(if(isFinite(v), v, 0), 999999999.999999999), -999999999.999999999), 9), quantiles(0.5, 0.9, 0.99)(duration))

// ❌ Bad: Missing FINAL or deduplication
SELECT * FROM feedback_scores WHERE workspace_id = :workspace_id

// ✅ Good: Use FINAL or LIMIT 1 BY
SELECT * FROM feedback_scores FINAL WHERE workspace_id = :workspace_id
```

## Query Logging

### **Log Comments**

```java
// ✅ Good: Always add log comments for query tracking
"""
SELECT * FROM traces
WHERE workspace_id = :workspace_id
SETTINGS log_comment = '<log_comment>'
;
"""

// Template setup:
var template = getSTWithLogComment(QUERY, "queryName", workspaceId, projectId);
```

## Best Practices Summary

### **Do's:**

- ✅ Always verify schema from migration files
- ✅ Search for similar queries before implementing
- ✅ Use FINAL or LIMIT 1 BY for ReplacingMergeTree tables
- ✅ Escape comparison operators in StringTemplate (\\<, \\>)
- ✅ Use snake_case for parameter names
- ✅ Clamp numeric values to prevent NaN/Inf
- ✅ Use correct Decimal precision (Decimal64(9), Decimal(38, 12))
- ✅ Add log comments to all queries
- ✅ Use CTEs for complex queries
- ✅ Match column aliases to Java field names

### **Don'ts:**

- ❌ Don't invent schema without checking migrations
- ❌ Don't forget FINAL or deduplication patterns
- ❌ Don't use camelCase for ClickHouse parameters
- ❌ Don't ignore NaN/Inf handling for numeric aggregations
- ❌ Don't use wrong Decimal precision
- ❌ Don't forget to escape < and > in StringTemplate
- ❌ Don't bind null directly (use conditional binding)
- ❌ Don't fetch all data and filter in Java

## Key References

- **Migration files**: `src/main/resources/liquibase/db-app-analytics/migrations/`
- **Example DAOs**: `ProjectMetricsDAO.java`, `TraceDAO.java`, `ExperimentDAO.java`
- **ClickHouse docs**: [ClickHouse Documentation](https://clickhouse.com/docs)
- **R2DBC ClickHouse**: [R2DBC ClickHouse Driver](https://github.com/ClickHouse/clickhouse-java)
