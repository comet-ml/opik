---
# https://www.dropwizard.io/en/stable/manual/configuration.html#logging
logging:
  #  Default: INFO
  #  Description: Logback logging level
  level: ${GENERAL_LOG_LEVEL:-INFO}
  #  Default: com.comet: INFO
  #  Description: Individual logger configuration
  loggers:
    com.comet: ${OPIK_LOG_LEVEL:-INFO}

# Description: state database configuration
# https://www.dropwizard.io/en/stable/manual/configuration.html#database
database:
  #  Default: jdbc:mysql://localhost:3306/opik?createDatabaseIfNotExist=true&rewriteBatchedStatements=true
  #  Description: The URL of the server
  url: ${STATE_DB_PROTOCOL:-jdbc:mysql://}${STATE_DB_URL:-localhost:3306/opik?createDatabaseIfNotExist=true&rewriteBatchedStatements=true}
  #  Default: opik
  #  Description: The username used to connect to the server
  user: ${STATE_DB_USER:-opik}
  #  Default: opik
  #  Description: The password used to connect to the server
  password: ${STATE_DB_PASS:-opik}
  #  Default: com.mysql.cj.jdbc.Driver
  #  Description: The fully qualified class name of the JDBC driver class.
  #   Only required if there were no JDBC drivers registered in META-INF/services/java.sql.Driver.
  driverClass: ${STATE_DB_DRIVER_CLASS:-com.mysql.cj.jdbc.Driver}
  #  Default: Empty
  #  Description: Any additional JDBC driver parameters
  properties:
    wrapperPlugins: ${STATE_DB_PLUGINS:-''}

# Description: analytics database configuration for migrations connection
databaseAnalyticsMigrations:
  #  Default: jdbc:clickhouse://localhost:8123/opik
  #  Description: The URL of the server
  url: ${ANALYTICS_DB_MIGRATIONS_URL:-jdbc:clickhouse://localhost:8123/opik}
  #  Default: opik
  #  Description: The username used to connect to the server
  user: ${ANALYTICS_DB_MIGRATIONS_USER:-opik}
  #  Default: opik
  #  Description: The password used to connect to the server
  password: ${ANALYTICS_DB_MIGRATIONS_PASS:-opik}
  #  Default: ru.yandex.clickhouse.ClickHouseDriver
  #  Description: The fully qualified class name of the JDBC driver class.
  #   Community support only. Requires an old driver for migrations to work
  driverClass: ru.yandex.clickhouse.ClickHouseDriver

# Description: analytics database configuration for service connection
databaseAnalytics:
  #  Default: http
  #  Description: The protocol used to connect to the server
  protocol: ${ANALYTICS_DB_PROTOCOL:-HTTP}
  #  Default: localhost
  #  Description: The host used to connect to the server
  host: ${ANALYTICS_DB_HOST:-localhost}
  #  Default: 8123
  #  Description: The port used to connect to the server
  port: ${ANALYTICS_DB_PORT:-8123}
  #  Default: opik
  #  Description: The username used to connect to the server
  username: ${ANALYTICS_DB_USERNAME:-opik}
  #  Default: opik
  #  Description: The password used to connect to the server
  password: ${ANALYTICS_DB_PASS:-opik}
  #  Default: opik
  #  Description: The database name
  databaseName: ${ANALYTICS_DB_DATABASE_NAME:-opik}
  #  Default:
  #   - health_check_interval=2000
  #   - compress=1
  #   - auto_discovery=true
  #   - failover=3
  #   - custom_http_params=max_query_size=100000000
  #  Description: query parameters that will be added to the connection string
  queryParameters: ${ANALYTICS_DB_QUERY_PARAMETERS:-health_check_interval=2000&compress=1&auto_discovery=true&failover=3&custom_http_params=max_query_size=100000000}

# https://www.dropwizard.io/en/stable/manual/configuration.html#health
health:
  # Default: ["/health-check"]
  # Description: URLs to expose the app’s health check on.
  healthCheckUrlPaths: [ "/health-check" ]
  # Options around a particular health check which is registered in an Application
  # https://www.dropwizard.io/en/stable/manual/configuration.html#man-configuration-health-checks
  healthChecks:
    - name: deadlocks
      critical: true
      type: alive
    - name: db
      critical: true
      type: ready
    - name: redis
      critical: true
      type: ready
    - name: clickhouse
      critical: true
      type: ready
    - name: mysql
      critical: true
      type: ready

# Configuration for distributed locking using redis
distributedLock:
  # Default: 500
  # Description: Lease time in milliseconds
  lockTimeoutMS: ${DISTRIBUTED_LOCK_TIME_OUT:-500}
  # Default: 5
  # Description: This value has to be considerably higher than the lockTimeoutMS value, as it has to guarantee that the
  # last thread to join the queue to acquire the lock will have enough time to execute the action. Then, the lock will
  # be deleted from redis after the specified period of time.
  # This is needed as redisson by default doesn't delete the lock from redis after the lease time expires, it just
  # releases the lock. The expiration time will be reset every time the lock is acquired.
  ttlInSeconds: ${DISTRIBUTED_LOCK_TTL_IN_SEC:-5}

# Redis configuration
redis:
  # Default: redis://:opik@localhost:6379/0
  # Description: single node redis's URL
  singleNodeUrl: ${REDIS_URL:-redis://:opik@localhost:6379/0}

openTelemetry:
  # Default: 3h
  # Description: how long it takes to expire non-used keys
  ttl: ${OTEL_TTL_INTERVAL:-3h}

# Authentication configuration. This is not enabled by default for open source installations.
authentication:
  # Default: false
  # Description: Whether or not to enable authentication
  enabled: ${AUTH_ENABLED:-false}
  # Default: 5
  # Description: API key resolution cache TTL (seconds). Setting this value to 0 means no caching.
  apiKeyResolutionCacheTTLInSec: ${AUTH_API_KEY_RESOLUTION_CACHE_TTL_IN_SEC:-5}
  # Default: http://react-svc:8080
  # Description: Configures base url for React service, used for user management and authentication
  reactService:
    url: ${REACT_SERVICE_URL:-http://react-svc:8080}

# https://www.dropwizard.io/en/stable/manual/configuration.html#servers
server:
  # Default: false
  # Description: Whether to enable virtual threads for Jetty’s thread pool.
  enableVirtualThreads: ${ENABLE_VIRTUAL_THREADS:-false}
  # https://www.dropwizard.io/en/stable/manual/configuration.html#gzip
  gzip:
    # Default: true
    # Description: If true, all requests with gzip in the Accept-Encoding header will have their response entities
    # compressed and requests with gzip in the Content-Encoding header will have their request entities decompressed.
    enabled: true

# Configuration for batch operations
batchOperations:
  datasets:
    # Default: 5000
    # Description: The maximal number of ids to be used for IN clause. Find requests with a larger number of ids will
    # involve the use of temp tables for querying
    maxExperimentInClauseSize: ${BATCH_OPERATIONS_MAX_EXPERIMENT_IN_CLAUSE_SIZE:-5000}

# Configuration for rate limit. This is not enabled by default for open source installations.
# If enabled, rate limit is applied to creation and update of various entities including traces, spans, projects,
# prompts, feedback definitions, experiments, datasets and dataset items
rateLimit:
  # Default: false
  # Description: Whether or not rate limit is enabled
  enabled: ${RATE_LIMIT_ENABLED:-false}
  # This uses as a fallback rate limit configuration in case an entity specific configuration doesn't exist
  generalLimit:
    # Default: 10000
    # Description: how many events are allowed in the specified time bucket
    limit: ${RATE_LIMIT_GENERAL_EVENTS_LIMIT:-10000}
    # Default: 60
    # Description: Time bucket size in seconds
    durationInSeconds: ${RATE_LIMIT_GENERAL_EVENTS_DURATION_IN_SEC:-60}
    # Description: Header name to use for rate limiting
    headerName: User
    # Description: User facing bucket name
    userFacingBucketName: general_events
    # Description: Rate limit error message
    errorMessage: "You have exceeded the general rate limit for this user. Please try again later."

  workspaceLimit:
    # Default: 5000
    # Description: how many events per workspace are allowed in the specified time bucket
    limit: ${RATE_LIMIT_WORKSPACE_EVENTS_LIMIT:-5000}
    # Default: 60
    # Description: Time bucket size in seconds
    durationInSeconds: ${RATE_LIMIT_WORKSPACE_EVENTS_DURATION_IN_SEC:-60}
    # Description: Header name to use for rate limiting
    headerName: Workspace
    # Description: User facing bucket name
    userFacingBucketName: workspace_events
    # Description: Rate limit error message
    errorMessage: "You have exceeded the rate limit for this user in this workspace. Please try again later."

  customLimits:
    getSpanById:
      # Default: 250
      # Description: how many events are allowed in the specified time bucket
      limit: ${RATE_LIMIT_GET_SPANS_BY_ID_EVENTS_PER_WORKSPACE_LIMIT:-250}
      # Default: 60
      # Description: Time bucket size in seconds
      durationInSeconds: ${RATE_LIMIT_WORKSPACE_EVENTS_DURATION_IN_SEC:-60}
      # Description: Header name to use for rate limiting
      headerName: Get-Span-Id
      # Description: User facing bucket name
      userFacingBucketName: get_span_by_id
      # Description: Rate limit error message
      errorMessage: "You have exceeded the rate limit for this operation Please try again later."

# Configuration for usage limit. This is not enabled by default for open source installations.
# In order to support that, the remote authentication server must contain a `quotas` object in its authentication
# response.
usageLimit:
  # Description: The error to be displayed when submitting entities to a workspace where the usage limit is exceeded
  errorMessage: ${USAGE_LIMIT_ERROR_MESSAGE:-You have exceeded the usage limit for this operation.}

# Configuration for anonymous usage reporting
usageReport:
  # Default: true
  # Description: Whether or not to send anonymous usage reports
  enabled: ${OPIK_USAGE_REPORT_ENABLED:-true}
  # Default: https://stats.comet.com/notify/event/
  # Description: URL to send the anonymous usage reports to
  url: ${OPIK_USAGE_REPORT_URL:-https://stats.comet.com/notify/event/}

# Configuration for application metadata
metadata:
  # Default: latest
  # Description: The application version
  version: ${OPIK_VERSION:-latest}

# CORS related configuration
cors:
  # Default: false
  # Description: Whether or not to allow cross site scripting
  enabled: ${CORS:-false}

# Encryption related configuration
encryption:
  # Default: GiTHubiLoVeYouAA
  # Description: Encryption key to use when storing sensitive information
  key: ${OPIK_ENCRYPTION_KEY:-'GiTHubiLoVeYouAA'}

# Configuration for Online Scoring
onlineScoring:
  # Default: 500 ms
  # Description: How often Online Scoring will check Redis for new messages (in milliseconds)
  poolingInterval: ${REDIS_SCORING_CONSUMER_POOL_INTERVAL:-500ms}
  # Default: online_scoring
  # Description: A consumer group name so multiple instances can share the stream load
  consumerGroupName: ${REDIS_SCORING_CONSUMER_GROUP_NAME:-'online_scoring'}
  # Default: 5
  # Description: Maximum number of messages returned within a Redis Stream get
  consumerBatchSize: ${REDIS_SCORING_CONSUMER_BATCH_SIZE:-5}
  ## scorer: options from AutomationRuleEvaluatorType
  ## streamName: the name of the stream in redis
  ## codec: 'json' when there are non-java consumers, 'java' for java consumers only
  streams:
    - scorer: llm_as_judge
      streamName: stream_scoring_llm_as_judge
      codec: java
    - scorer: user_defined_metric_python
      streamName: stream_scoring_user_defined_metric_python
      codec: java

# LLM providers client configuration
llmProviderClient:
  # Default: 3
  # Description: Max amount of attempts to reach the LLM provider before giving up
  maxAttempts: ${LLM_PROVIDER_CLIENT_MAX_ATTEMPTS:-3}
  # Default: 500
  # Description: Number of milliseconds to wait between retry attempts
  delayMillis: ${LLM_PROVIDER_CLIENT_DELAY_MILLIS:-500}
  # Default: 0.2
  # Description: Max amount of jitter to add to the delay. The value is a percentage in the range [0-1]
  jitterScale: ${LLM_PROVIDER_CLIENT_JITTER_SCALE:-0.2}
  # Default: 1.5
  # Description: Backoff exponent to be used in retry attempts
  backoffExp: ${LLM_PROVIDER_CLIENT_BACKOFF_EXP:-1.5}
  # Default: 60s
  # Description: Call timeout for LLM providers
  callTimeout: ${LLM_PROVIDER_CLIENT_CALL_TIMEOUT:-60s}
  # Default: 60s
  # Description: Connect timeout for LLM providers
  connectTimeout: ${LLM_PROVIDER_CLIENT_CONNECT_TIMEOUT:-60s}
  # Default: 60s
  # Description: Read timeout for LLM providers
  readTimeout: ${LLM_PROVIDER_CLIENT_READ_TIMEOUT:-60s}
  # Default: 60s
  # Description: Write timeout for LLM providers
  writeTimeout: ${LLM_PROVIDER_CLIENT_WRITE_TIMEOUT:-60s}
  # Default: false
  # Description: Whether or not to log requests
  logRequests: ${LLM_PROVIDER_CLIENT_LOG_REQUESTS:-false}
  # Default: false
  # Description: Whether or not to log responses
  logResponses: ${LLM_PROVIDER_CLIENT_LOG_RESPONSES:-false}
  # Configuration for OpenAI client
  openAiClient:
    # Default:
    # Description: OpenAI API URL
    url: ${LLM_PROVIDER_OPENAI_URL:-}
  # Configuration for Anthropic client
  anthropicClient:
    # Default: https://api.anthropic.com/v1/
    # Description: Anthropic API URL
    url: ${LLM_PROVIDER_ANTHROPIC_URL:-https://api.anthropic.com/v1/}
    # Default: 2023-06-01
    # Description: Anthropic API version https://docs.anthropic.com/en/api/versioning
    version: ${LLM_PROVIDER_ANTHROPIC_VERSION:-'2023-06-01'}
  # Default: https://openrouter.ai/api/v1
  # Description: OpenRouter API URL
  openRouterUrl: ${LLM_PROVIDER_OPENROUTER_URL:-https://openrouter.ai/api/v1}

  vertexAIClient:
    # Default: https://www.googleapis.com/auth/cloud-platform
    # Description: Vertex AI SCOPE API URL
    scope: ${LLM_PROVIDER_VERTEXAI_SCOPE:-https://www.googleapis.com/auth/cloud-platform}

# Configuration for cache manager
cacheManager:
    # Default: true
    # Description: Whether or not cache manager is enabled
    enabled: ${CACHE_MANAGER_ENABLED:-true}
    # Default: PT1S
    # Description: Time to live for cache entries in using the formats accepted are based on the ISO-8601: https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-
    defaultDuration: ${CACHE_MANAGER_DEFAULT_DURATION:-PT1S}
    caches:
      # Default: {}
      # Description: Dynamically created caches with their respective time to live in seconds
      automationRules: ${CACHE_MANAGER_AUTOMATION_RULES_DURATION:-PT1S}
      workspace_metadata: ${CACHE_MANAGER_WORKSPACE_METADATA_DURATION:-PT1H}

# Configuration for clickhouse log appender
clickHouseLogAppender:
  # Default: 1000
  # Description: Number of log messages to be batched before sending to ClickHouse
  batchSize: ${CLICKHOUSE_LOG_APPENDER_BATCH_SIZE:-1000}

  # Default: PT0.500S or 500ms
  # Description: Time interval after which the log messages are sent to ClickHouse if the batch size is not reached
  flushIntervalDuration: ${CLICKHOUSE_LOG_APPENDER_FLUSH_INTERVAL_DURATION:-PT0.500S}

workspaceSettings:
  # Default: 50
  # Description: Maximum size of a workspace in GB to allow dynamic sorting. This value is calculated via estimated size based on spans table
    maxSizeToAllowSorting: ${WORKSPACE_SETTINGS_MAX_SIZE_IN_GB_TO_ALLOW_SORTING:-50}

# Configuration AWS S3
s3Config:
  s3Region: ${S3_REGION:-'us-east-1'}
  # Description: AWS S3 bucket for Opik
  s3BucketName: ${S3_BUCKET:-'public'}
  # Description: AWS S3 presign url timeout
  preSignUrlTimeoutSec: ${S3_PRESIGN_URL_TIMEOUT:-3600}
  # Description: Url for local MinIO or Aws
  s3Url: ${S3_URL:-http://minio:9000}
  # Description: Whether installation uses MinIO or AWS S3
  isMinIO: ${IS_MINIO:-true}

# Python evaluator configuration
pythonEvaluator:
  # Default: http://localhost:8000
  # Description: URL of the Python evaluator service, generally the opik-python-backend service
  url: ${PYTHON_EVALUATOR_URL:-http://localhost:8000}

serviceToggles:
  # Default: true
  # Description: Whether or not Python evaluator is enabled
  pythonEvaluatorEnabled: ${TOGGLE_PYTHON_EVALUATOR_ENABLED:-"true"}
  # Default: false
  # Description: Whether or not Guardrails feature is enabled
  guardrailsEnabled: ${TOGGLE_GUARDRAILS_ENABLED:-"false"}

