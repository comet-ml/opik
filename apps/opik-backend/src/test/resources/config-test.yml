---
# https://www.dropwizard.io/en/stable/manual/configuration.html#logging
logging:
  #  Default: INFO
  #  Description: Logback logging level
  level: INFO
  #  Default: com.comet: DEBUG
  #  Description: Individual logger configuration
  loggers:
    com.comet: DEBUG
    com.comet.opik.infrastructure.llm: INFO

# Description: state database configuration
# https://www.dropwizard.io/en/stable/manual/configuration.html#database
database:
  #  Default: jdbc:mysql://localhost:3306/opik?createDatabaseIfNotExist=true&rewriteBatchedStatements=true
  #  Description: The URL of the server
  url: jdbc:mysql://localhost:3306/opik?createDatabaseIfNotExist=true&rewriteBatchedStatements=true
  #  Default: opik
  #  Description: The username used to connect to the server
  user: opik
  #  Default: opik
  #  Description: The password used to connect to the server
  password: opik
  #  Default: com.mysql.cj.jdbc.Driver
  #  Description: The fully qualified class name of the JDBC driver class. Only required if there were no JDBC drivers registered in META-INF/services/java.sql.Driver.
  driverClass: com.mysql.cj.jdbc.Driver

# Description: analytics database configuration for migrations connection
databaseAnalyticsMigrations:
  #  Default: jdbc:clickhouse://localhost:8123/opik
  #  Description: The URL of the server
  url: jdbc:clickhouse://localhost:8123/opik
  #  Default: opik
  #  Description: The username used to connect to the server
  user: opik
  #  Default: opik
  #  Description: The password used to connect to the server
  password: opik
  #  Default: ru.yandex.clickhouse.ClickHouseDriver
  #  Description: The fully qualified class name of the JDBC driver class.
  #   Community support only. Requires an old driver for migrations to work
  driverClass: ru.yandex.clickhouse.ClickHouseDriver

# Description: analytics database configuration for service connection
databaseAnalytics:
  #  Default: http
  #  Description: The protocol used to connect to the server
  protocol: HTTP
  #  Default: localhost
  #  Description: The host used to connect to the server
  host: localhost
  #  Default: 8123
  #  Description: The port used to connect to the server
  port: 8123
  #  Default: opik
  #  Description: The username used to connect to the server
  username: opik
  #  Default: opik
  #  Description: The password used to connect to the server
  password: opik
  #  Default: opik
  #  Description: The database name
  databaseName: opik
  #  Default:
  #   - health_check_interval=2000
  #   - compress=1
  #   - auto_discovery=true
  #   - failover=3
  #   - custom_http_params=max_query_size=100000000
  #  Description: query parameters that will be added to the connection string
  queryParameters: health_check_interval=2000&compress=1&auto_discovery=true&failover=3&custom_http_params=max_query_size=100000000,async_insert_busy_timeout_max_ms=60,async_insert_busy_timeout_min_ms=50,async_insert=1,wait_for_async_insert=1,async_insert_use_adaptive_busy_timeout=1,async_insert_deduplicate=1

# https://www.dropwizard.io/en/stable/manual/configuration.html#health
health:
  # Default: ["/health-check"]
  # Description: URLs to expose the appâ€™s health check on.
  healthCheckUrlPaths: [ "/health-check" ]
  # Options around a particular health check which is registered in an Application
  # https://www.dropwizard.io/en/stable/manual/configuration.html#man-configuration-health-checks
  healthChecks:
    - name: deadlocks
      critical: true
      type: alive
    - name: db
      critical: true
      type: ready
    - name: redis
      critical: true
      type: ready
    - name: clickhouse
      critical: true
      type: ready
    - name: mysql
      critical: true
      type: ready

# Configuration for distributed locking using redis
distributedLock:
  # Default: 500
  # Description: Lease time in milliseconds
  lockTimeoutMS: 500
  # Default: 1
  # Description: This value has to be considerably higher than the lockTimeoutMS value, as it has to guarantee that the
  # last thread to join the queue to acquire the lock will have enough time to execute the action. Then, the lock will
  # be deleted from redis after the specified period of time.
  # This is needed as redisson by default doesn't delete the lock from redis after the lease time expires, it just
  # releases the lock. The expiration time will be reset every time the lock is acquired.
  ttlInSeconds: 1

# Redis configuration
redis:
  # Default: redis://:opik@localhost:6379/0
  # Description: single node redis's URL
  singleNodeUrl: redis://:opik@localhost:6379/0

openTelemetry:
  # Default: 3h
  # Description: how long it takes to expire non-used keys
  ttl: 3h

# Authentication configuration. This is not enabled by default for open source installations.
authentication:
  # Default: false
  # Description: Whether or not to enable authentication
  enabled: false
  # Default: 0
  # Description: API key resolution cache TTL (seconds). Setting this value to 0 means no caching.
  apiKeyResolutionCacheTTLInSec: 0
  # Default:
  # Description: Configures base url for React service, used for user management and authentication
  reactService:
    url: ''

# https://www.dropwizard.io/en/stable/manual/configuration.html#servers
server:
  # Default: false
  # Description: Whether to enable virtual threads for Jetty's thread pool.
  enableVirtualThreads: false
  # https://www.dropwizard.io/en/stable/manual/configuration.html#gzip
  gzip:
    # Default: true
    # Description: If true, all requests with gzip in the Accept-Encoding header will have their response entities
    # compressed and requests with gzip in the Content-Encoding header will have their request entities decompressed.
    enabled: true
  # HTTP connector configuration for handling large request headers
  # Default: 16KB (16000 bytes) - matches ALB/Nginx request line limit
  # Description: Maximum size of request headers to prevent 431 errors from long URLs with many filters
  applicationConnectors:
    - type: http
      # Default: 8080
      # Description: The port on which the application HTTP connector listens
      port: 8080
      maxRequestHeaderSize: 16KB
      # Default: 1m
      # Description: The maximum idle time for a connection, after which it will be closed.
      idleTimeout: 1m
  adminConnectors:
    - type: http
      # Default: 8081
      # Description: The port on which the admin HTTP connector listens
      port: 8081

# Jackson JSON processing configuration
# Controls limits for JSON deserialization to prevent memory exhaustion
jacksonConfig:
  # Default: 104857600 (100MB)
  # Description: Maximum size for individual string values during JSON deserialization. 
  #   A JSON with 3 fields up to this size will work, but a single larger string will fail.
  #   This configuration is used by both HTTP layer and internal JSON processing for consistency,
  #   preventing memory exhaustion from extremely large base64-encoded attachments before they can be stripped
  maxStringLength: 262144000 

# Configuration for batch operations
batchOperations:
  datasets:
    # Default: 100
    # Description: The maximal number of ids to be used for IN clause. Find requests with a larger number of ids will
    # involve the use of temp tables for querying
    maxExperimentInClauseSize: 100
    # Default: 1000
    # Description: The batch size for processing CSV files. Dataset items are saved to the database in batches of this size.
    csvBatchSize: 1000

# Configuration for rate limit. This is not enabled by default for open source installations.
# If enabled, rate limit is applied to creation and update of various entities including traces, spans, projects,
# prompts, feedback definitions, experiments, datasets and dataset items
rateLimit:
  # Default: false
  # Description: Whether or not rate limit is enabled
  enabled: false

# Configuration for usage limit. This is not enabled by default for open source installations.
# In order to support that, the remote authentication server must contain a `quotas` object in its authentication
# response.
usageLimit:
  # Description: The error to be displayed when submitting entities to a workspace where the usage limit is exceeded
  errorMessage: "You have exceeded the usage limit for this operation."

# Configuration for anonymous usage reporting
usageReport:
  # Default: false
  # Description: Whether or not to send anonymous usage reports
  enabled: false

# Configuration for application metadata
metadata:
  # Default: latest
  # Description: The application version
  version: latest

# CORS related configuration
cors:
  # Default: false
  # Description: Whether or not to allow cross site scripting
  enabled: false

# Encryption related configuration
encryption:
  # Default: GiTHubiLoVeYouAA
  # Description: Encryption key to use when storing sensitive information
  key: 'GiTHubiLoVeYouAA'

# Configuration for Online Scoring
onlineScoring:
  # Default: 500 ms
  # Description: How often Online Scoring will check Redis for new messages (in milliseconds)
  # This is the global default value, can be overridden per stream
  poolingInterval: 500ms
  # Default: 5s
  # Description: Timeout for blocking read operations on Redis streams (long polling duration)
  # This is the global default value, can be overridden per stream
  longPollingDuration: 5s
  # Default: online_scoring
  # Description: A consumer group name so multiple instances can share the stream load
  consumerGroupName: 'online_scoring'
  # Default: 10
  # Description: Maximum number of messages returned within a Redis Stream get
  # This is the global default value, can be overridden per stream
  consumerBatchSize: 10
  # Default: 10
  # Description: Claim pending messages every N polling intervals (global default)
  claimIntervalRatio: 10
  # Default: 10m
  # Description: Time before message considered orphaned and eligible for claiming (global default)
  pendingMessageDuration: 10m
  # Default: 3
  # Description: Maximum number of retry attempts for failed messages (1-10, global default)
  maxRetries: 3
  ## scorer: options from AutomationRuleEvaluatorType
  ## streamName: the name of the stream in redis
  ## codec: 'json' when there are non-java consumers, 'java' for java consumers only
  ## poolingInterval: (optional, but highly recommended) per stream pooling interval, overrides global value
  ## longPollingDuration: (optional, but highly recommended) per stream long polling duration, overrides global value
  ## consumerBatchSize: (optional, but highly recommended) per stream batch size, overrides global value
  ## claimIntervalRatio: (optional) per stream claim interval ratio, overrides global value
  ## pendingMessageDuration: (optional) per stream pending message duration, overrides global value
  ## maxRetries: (optional) per stream max retries, overrides global value
  streams:
    - scorer: llm_as_judge
      streamName: stream_scoring_llm_as_judge
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default
    - scorer: user_defined_metric_python
      streamName: stream_scoring_user_defined_metric_python
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default
    - scorer: trace_thread_llm_as_judge
      streamName: stream_scoring_trace_thread_llm_as_judge
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default
    - scorer: trace_thread_user_defined_metric_python
      streamName: stream_scoring_trace_thread_user_defined_metric_python
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default
    - scorer: span_llm_as_judge
      streamName: stream_scoring_span_llm_as_judge
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default
    - scorer: span_user_defined_metric_python
      streamName: stream_scoring_span_user_defined_metric_python
      codec: java
      # Optional per stream configuration (falls back to global if not specified)
      poolingInterval: # Empty - will use global default
      longPollingDuration: # Empty - will use global default
      consumerBatchSize: # Empty - will use global default
      claimIntervalRatio: # Empty - will use global default
      pendingMessageDuration: # Empty - will use global default
      maxRetries: # Empty - will use global default

datasetExport:
  enabled: true
  streamName: 'dataset-export-test'
  consumerGroupName: 'dataset_export_consumers_test'
  consumerBatchSize: 10
  poolingInterval: 1s
  longPollingDuration: 500ms
  maxRetries: 3
  claimIntervalRatio: 10
  pendingMessageDuration: 5m
  defaultTtl: 24h
  minPartSize: 5242880  # 5MB - S3 minimum
  maxPartSize: 10485760  # 10MB
  itemBatchSize: 100
  cleanupTimeout: 5m
  cleanupLockWaitTime: 1s
  cleanupBatchSize: 100

# LLM providers client configuration
llmProviderClient:
  # Default: 60s
  # Description: Call timeout for LLM providers
  callTimeout: 60s
  # Default: false
  # Description: Whether or not to log requests
  logRequests: false
  # Default: false
  # Description: Whether or not to log responses
  logResponses: false
  openAiClient:
    # See demo endpoint Langchain4j documentation: https://docs.langchain4j.dev/get-started
    # Not https but only used for testing purposes. It's fine as long as not sensitive data is sent.
    url: http://langchain4j.dev/demo/openai/v1
  # Configuration for Anthropic client
  anthropicClient:
    # Default: https://api.anthropic.com/v1/
    # Description: Anthropic API base URL
    url: https://api.anthropic.com/v1/
    # Default: 2023-06-01
    # Description: Anthropic API version https://docs.anthropic.com/en/api/versioning
    version: '2023-06-01'
  # Default: https://openrouter.ai/api/v1
  # Description: OpenRouter API URL
  openRouterUrl: https://openrouter.ai/api/v1

# Configuration for cache manager
cacheManager:
  # Default: false
  # Description: Whether or not cache manager is enabled
  enabled: false
  # Default: PT1S
  # Description: Time to live for cache entries in using the formats accepted are based on the ISO-8601: https://docs.oracle.com/javase/8/docs/api/java/time/Duration.html#parse-java.lang.CharSequence-
  defaultDuration: PT1S
  caches:
    # Default: {}
    # Description: Dynamically created caches with their respective time to live in seconds
    testCache: PT1S

# Configuration for clickhouse log appender
clickHouseLogAppender:
  # Default: 1000
  # Description: Number of log messages to be batched before sending to ClickHouse
  batchSize: 1000

  # Default: PT0.500S or 500ms
  # Description: Time interval after which the log messages are sent to ClickHouse if the batch size is not reached
  flushIntervalDuration: PT0.500S

workspaceSettings:
  # Default: 50
  # Description: Maximum size of a workspace in GB to allow dynamic sorting.
  # Set to -1 to disable the limit (allow sorting for all workspace sizes).
  # This value is calculated via estimated size based on spans table.
  maxSizeToAllowSorting: -1
  # Default: 100
  # Description: Maximum size of a project in GB to allow dynamic sorting.
  # Set to -1 to disable the limit (allow sorting for all project sizes).
  # This value is calculated via estimated size based on spans table.
  maxProjectSizeToAllowSorting: -1

# Configuration AWS S3
s3Config:
  s3Region: 'us-east-1'
  # Description: AWS S3 bucket for Opik
  s3BucketName: 'test-bucket'
  # Description: AWS S3 presign url timeout
  preSignUrlTimeoutSec: 60
  # Description: Url for local MinIO or Aws
  s3Url: http://localhost:9000
  # Description: Whether installation uses MinIO or AWS S3
  isMinIO: true

# Attachments configuration
attachmentsConfig:
  # Description: Minimum size (bytes) for base64 strings to be considered attachments
  # For tests, use 5KB (same as local dev default)
  stripMinSize: 5000

# Python evaluator configuration
pythonEvaluator:
  # Default: http://localhost:8000
  # Description: URL of the Python evaluator service, generally the opik-python-backend service
  url: ${PYTHON_EVALUATOR_URL:-http://localhost:8000}

serviceToggles:
  # Default: false for testing. It should be enabled for test scenarios when it's relevant.
  # Description: Whether or not Python evaluator is enabled
  pythonEvaluatorEnabled: "false"
  # Default: false
  # Description: Whether or not Guardrails feature is enabled
  guardrailsEnabled: "false"
  # Default: false
  # Description: Whether or not to enable the trace thread Python evaluator
  traceThreadPythonEvaluatorEnabled: "false"
  # Default: true
  # Description: Whether or not to enable the span LLM as Judge evaluator
  spanLlmAsJudgeEnabled: "false"
  # Default: false
  # Description: Whether or not to enable the span user-defined metric Python evaluator
  spanUserDefinedMetricPythonEnabled: "false"
  # Default: false
  # Description: Whether or not OpikAI feature is enabled
  opikAIEnabled: "false"
  # Default: false
  # Description: Whether or not Alert feature is enabled
  alertsEnabled: "false"
  # Default: false
  # Description: Whether or not CSV upload feature is enabled for dataset items
  csvUploadEnabled: "false"
  # Default: true
  # Description: Whether or not export/download functionality is enabled
  exportEnabled: "true"
  # Default: false for testing (legacy mode)
  # Description: Whether or not dataset versioning feature is enabled
  datasetVersioningEnabled: "false"
  # Default: false
  # Description: Whether or not Optimization Studio feature is enabled
  optimizationStudioEnabled: "false"
  # Default: true
  # Description: Whether or not OpenAI provider is enabled
  openaiProviderEnabled: "true"
  # Default: true
  # Description: Whether or not Anthropic provider is enabled
  anthropicProviderEnabled: "true"
  # Default: true
  # Description: Whether or not Gemini provider is enabled
  geminiProviderEnabled: "true"
  # Default: true
  # Description: Whether or not OpenRouter provider is enabled
  openrouterProviderEnabled: "true"
  # Default: true
  # Description: Whether or not Vertex AI provider is enabled
  vertexaiProviderEnabled: "true"
  # Default: true
  # Description: Whether or not Bedrock provider is enabled
  bedrockProviderEnabled: "true"
  # Default: true
  # Description: Whether or not Custom LLM provider is enabled
  customllmProviderEnabled: "true"
  # Default: false
  # Description: Whether or not Collaborators tab feature is enabled
  collaboratorsTabEnabled: "false"

# Trace Thread configuration
traceThreadConfig:
  # Default: false for testing. Should be enabled for specific test scenarios when needed.
  # Description: Whether the trace thread closing job is enabled
  enabled: false
  # Default: 1s
  # Description: Inactive thread timeout. If a thread is inactive for this amount of time, it will be marked as inactive
  timeoutToMarkThreadAsInactive: 1s
  # Default: trace_thread_closing
  # Description: A consumer group name so multiple instances can share the stream load
  consumerGroupName: 'trace_thread_closing'
  # Default: 100
  # Description: Maximum number of messages returned within a Redis Stream get
  consumerBatchSize: 100
  # Default: 500ms
  # Description: How often the trace thread consumer will check Redis for new messages (in milliseconds)
  poolingInterval: 500ms
  # Default: 5s
  # Description: Timeout for blocking read operations on Redis streams (long polling duration)
  longPollingDuration: 5s
  # Default: trace_thread_closing_stream
  # Description: The name of the Redis Stream used for trace thread closing
  streamName: 'trace_thread_closing_stream'
  # Default: 1s
  # Description: The interval at which the close trace thread job will run to inactive threads
  closeTraceThreadJobInterval: 1500ms
  # Default: 4s
  # Description: The time to wait for the close trace threads job to finish before releasing the lock
  closeTraceThreadJobLockTime: 3s
  # Default: 300ms
  # Description: The time to wait for the close trace threads job to acquire the lock before giving up
  closeTraceThreadJobLockWaitTime: 300ms
  # Default: 2000
  # Description: The maximum number of item to process in a single close trace thread run
  closeTraceThreadMaxItemPerRun: 2000
  # Default: 10
  # Description: Claim pending messages every N polling intervals
  claimIntervalRatio: 10
  # Default: 10m
  # Description: Time before message considered orphaned and eligible for claiming
  pendingMessageDuration: 10m
  # Default: 3
  # Description: Maximum number of retry attempts for failed messages (1-10)
  maxRetries: 3

# Job timeout configuration
jobTimeout:
  # Default: 30s
  # Description: Timeout for the daily usage report job execution
  dailyUsageReportJobTimeout: 30
  # Default: 30s
  # Description: Timeout for the trace threads closing job execution
  traceThreadsClosingJobTimeout: 30

# Response formatting configuration
responseFormatting:
  # Default: 10001
  # Description: Maximum size of input/output/metadata fields in responses (FE limit + 1)
  truncationSize: 10001

# Queue configuration for Python RQ workers
queues:
  # Default: true
  # Description: Whether queue functionality is enabled
  enabled: true
  # Default: 14 days
  # Description: Default TTL for jobs in queues (how long job data is kept in Redis)
  defaultJobTtl: 14 days
  # Per-queue specific configurations
  queues:
    # Optimizer cloud queue configuration
    opik:optimizer-cloud:
      # Job TTL for optimizer jobs
      jobTTl: 1 day

# Webhook configuration
webhook:
  # Default: false
  # Description: Whether or not webhook functionality is enabled
  enabled: true
  # Default: webhook-events
  # Description: Redis stream name for webhook events
  streamName: webhook-events
  # Default: webhook-consumers
  # Description: Consumer group name for webhook event processing
  consumerGroupName: webhook-consumers
  # Default: 10
  # Description: Maximum number of messages to consume in a single batch (1-100)
  consumerBatchSize: 10
  # Default: 1s
  # Description: How often webhook consumer will check Redis for new messages
  poolingInterval: 1s
  # Default: 5s
  # Description: Timeout for blocking read operations on Redis streams (long polling duration)
  # Note: In tests, set this <= poolingInterval to avoid backpressure drops
  longPollingDuration: 500ms
  # Default: 3
  # Description: Maximum number of retry attempts for failed webhooks (1-10)
  maxRetries: 3
  # Default: 100ms
  # Description: Initial delay between retry attempts
  initialRetryDelay: 100ms
  # Default: 5s
  # Description: Maximum delay between retry attempts
  maxRetryDelay: 5s
  # Default: 1s
  # Description: HTTP request timeout for webhook calls
  requestTimeout: 1s
  # Default: 1s
  # Description: HTTP connection timeout for webhook calls
  connectionTimeout: 1s
  # Default: 10
  # Description: Claim pending messages every N polling intervals
  claimIntervalRatio: 10
  # Default: 10m
  # Description: Time before message considered orphaned and eligible for claiming
  pendingMessageDuration: 10m
  debouncing:
    # Default: {}
    # Description: Period for events aggregation before sending to webhook endpoint
    windowSize: 1s
  metrics:
    # Default: 1s
    # Description: Initial delay before the first metrics alert job execution
    initialDelay: 1s
    # Default: 2s
    # Description: Fixed delay between metrics alert job executions (waits this duration after completion)
    fixedDelay: 2s
