---
description: Test naming conventions and performance guidelines for Opik Optimizer SDK
globs: sdks/opik_optimizer/tests/**/*
alwaysApply: false
---
# Opik Optimizer Test Best Practices

The test suite is pytest-based and aims to keep optimizers deterministic, fast, and affordable.

## Determinism and Isolation

- Seed randomness where behaviour depends on stochastic operators (`random.seed`, `numpy.random.seed`). Many optimizers accept a `seed` parameter - set it explicitly in tests. Our default value for seed is "42".
- Reset global state (LiteLLM cache, logging configuration, environment variables) with fixtures or `monkeypatch` as seen in `tests/unit/test_logging_config.py`.
- Avoid touching the real LiteLLM cache directory in unit tests; point cache-dependent code to a temporary directory when practical.

## Fast Feedback

- Configure optimizers with tiny populations, low iteration counts, and reduced thread pools. Unit tests should replace LiteLLM calls with fakes or patches so they run offline.
- Prefer dataset stubs from `tests/unit` or `opik_optimizer.datasets.tiny_test()` for smoke coverage.
- Use parametrisation to cover edge cases without introducing nested loops.

## Assertions

- Assert both positive paths (best score improves, result shape) and failure handling (invalid config, evaluation failure fallback).
- When verifying prompts or histories, rely on helper models (for example, `OptimizationResult`) and compare essential fields rather than entire nested structures.
- Use `caplog` to assert log-level behaviour in logging-sensitive code.

## External Services

- End-to-end tests may require provider credentials (for example, `OPENAI_API_KEY`). Guard them with explicit failure messages so contributors understand the prerequisite before running the suite.
- When adding a new e2e test, document any required environment variables in the test docstring.

## Test Organization

Tests are organized per-optimizer in subdirectories with shared logic in root-level files:

```text
tests/unit/optimizers/
├── test_base_optimizer.py       # Shared BaseOptimizer tests
├── test_prompt_factory.py       # prompt_overrides feature tests
├── evolutionary/                # EvolutionaryOptimizer tests
├── few_shot/                    # FewShotBayesianOptimizer tests
├── gepa_optimizer/              # GEPAOptimizer tests
├── hierarchical/                # HierarchicalReflectiveOptimizer tests
├── meta_prompt/                 # MetaPromptOptimizer tests
└── parameter/                   # ParameterOptimizer tests
```

### When to Update Tests

- **Adding a new optimizer**: Create `tests/unit/optimizers/<name>/test_<name>.py` with standard test classes
- **Changing validation logic**: Update `TestValidateOptimizationInputs` in `test_base_optimizer.py`
- **Changing result format**: Update `TestSkipAndResultHelpers` or optimizer-specific result tests
- **Changing dataset selection**: Update `TestSelectEvaluationDataset` in `test_base_optimizer.py`
- **Changing prompt normalization**: Update `TestNormalizePromptInput` in `test_base_optimizer.py`

### Standard Test Classes Per Optimizer

Each optimizer should have these test classes in its main test file:

```python
class TestOptimizerInit:
    """Initialization with default and custom parameters."""

class TestOptimizerOptimizePrompt:
    """optimize_prompt behavior: prompt normalization, result format."""

class TestOptimizerEarlyStop:
    """Early-stop when baseline meets threshold."""
```

### Key Fixtures (from conftest.py)

- `mock_llm_call`: Mock synchronous LLM calls with configurable responses
- `mock_opik_client`: Mock Opik client for optimization tracking
- `mock_dataset`: Factory for mock datasets with configurable items
- `simple_chat_prompt`: Basic ChatPrompt fixture
- `multimodal_chat_prompt`: ChatPrompt with image content parts
- `chat_prompt_with_tools`: ChatPrompt with tool definitions
- `mock_task_evaluator`: Mock task evaluator with configurable scores
- `mock_full_optimization_flow`: Comprehensive mock for full optimization testing
- `optimizer_test_params`: Standard minimal test parameters

### Documentation

See `tests/unit/optimizers/OPTIMIZER_TEST_COVERAGE.md` for the full coverage matrix and detailed documentation.
