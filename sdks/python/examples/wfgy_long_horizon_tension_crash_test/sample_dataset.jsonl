{"input": "Q001 · Prime waves and spectral tension\n\nYou are given a long-horizon reasoning system that tries to detect whether a given prime-generating protocol behaves like a stable wave or a chaotic drift.\n\nDescribe a concrete test protocol that could be logged and replayed inside an evaluation dataset. The protocol must:\n- be fully described in natural language,\n- specify which numerical traces are recorded at each step,\n- explain how a single tension score would be computed from the trace.\n\nDo not claim to solve the underlying open problem. Focus on what can be measured and replayed.", "metadata": {"question_id": "Q001", "domain": "math_spectral", "pack_version": "wfgy_3_0_sample"}, "tags": ["wfgy", "long_horizon", "crash_test"]}
{"input": "Q010 · Long-horizon RAG collapse\n\nConsider a RAG pipeline that answers questions about a large technical PDF corpus. Over a long session (20+ turns) the model starts to drift and hallucinate citations.\n\nDesign a crash test case that would expose this drift inside Opik:\n- describe the user story,\n- describe the sequence of turns,\n- specify what should be logged as trace metadata at each turn,\n- define at least one metric that can be computed without a ground-truth full answer (for example, citation self-consistency or format checks).", "metadata": {"question_id": "Q010", "domain": "rag_long_horizon", "pack_version": "wfgy_3_0_sample"}, "tags": ["wfgy", "rag", "long_horizon", "crash_test"]}
{"input": "Q023 · Agent loop and recovery\n\nAn autonomous agent periodically gets stuck in a loop where it repeats the same plan with tiny variations.\n\nPropose a test case for Opik that:\n- defines an initial goal and environment description,\n- describes how the agent is expected to behave over 30+ steps,\n- specifies which signals (tags, metrics, or counters) would let you detect a loop early,\n- includes at least one measurable recovery criterion that can be checked from the trace alone.", "metadata": {"question_id": "Q023", "domain": "agents", "pack_version": "wfgy_3_0_sample"}, "tags": ["wfgy", "agents", "loops", "crash_test"]}
{"input": "Q057 · Policy drift under slow prompt edits\n\nA content-moderation assistant starts with a strict policy, but over many iterations the prompt is gradually edited by different teams. After a few months, the behavior is noticeably inconsistent.\n\nDescribe a dataset item that encodes this as a long-horizon test:\n- define the initial policy snapshot,\n- list a sequence of prompt edits (summarized in natural language),\n- specify how a single run should sample from these edits,\n- propose at least one metric that measures policy drift using only the model outputs and the logged edit IDs.", "metadata": {"question_id": "Q057", "domain": "safety_policy", "pack_version": "wfgy_3_0_sample"}, "tags": ["wfgy", "policy", "long_horizon", "drift"]}
{"input": "Q089 · Multi-step numerical planning under noisy feedback\n\nA planning agent needs to schedule maintenance for 1,000 machines over a year, with noisy feedback on failures and repairs.\n\nFormulate a test case for long-horizon planning that:\n- describes the initial state and constraints,\n- specifies what is logged at each planning step (state summary, chosen actions, feedback),\n- defines one or two aggregate scores that can be computed from the logged trace (for example, cost overrun, missed deadlines, or instability of the plan).", "metadata": {"question_id": "Q089", "domain": "planning_numerical", "pack_version": "wfgy_3_0_sample"}, "tags": ["wfgy", "planning", "numerical", "crash_test"]}
