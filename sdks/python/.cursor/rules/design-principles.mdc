---
description: SOLID principles and architectural design guidelines for the Python SDK
globs: sdks/python/src/opik/**/*
alwaysApply: false
---
# Python SDK Design Principles Guidelines

Comprehensive guidelines for applying SOLID principles and architectural design patterns in the Opik Python SDK.

## SOLID and Architecture

### Single Responsibility Principle

- **Follow SOLID principles**
- **Organize modules by functionality, avoid generic utility modules**
- **Use meaningful module and class names** that reflect their purpose, no shortcuts
- **Keep modules, classes and functions focused** on single responsibilities

```python
# ✅ Good: Single responsibility - focused only on thread management
class ThreadsClient:
    """Client for managing and interacting with conversational threads."""
    def __init__(self, client: "opik.Opik"):
        self._opik_client = client

    def search_threads(self, project_name: Optional[str] = None) -> List[TraceThread]:
        """Single responsibility - only handles thread search operations."""
        pass

# ✅ Good: Single responsibility - focused only on message processing
class OpikMessageProcessor(BaseMessageProcessor):
    """Processes messages with single responsibility - message handling."""
    def __init__(self, rest_client: rest_api_client.OpikApi):
        self._rest_client = rest_client

    def process(self, message: BaseMessage) -> None:
        """Single responsibility - only processes messages."""
        pass
```

### Open/Closed Principle

- **Design for extension without modification**
- **Use factory patterns for creating specialized objects**
- **Implement provider-specific behavior through abstraction**

```python
# ✅ Good: Open for extension via factory pattern (from opik_usage_factory.py)
_PROVIDER_TO_OPIK_USAGE_BUILDERS: Dict[
    Union[str, LLMProvider],
    List[Callable[[Dict[str, Any]], opik_usage.OpikUsage]],
] = {
    LLMProvider.OPENAI: [
        opik_usage.OpikUsage.from_openai_completions_dict,
        opik_usage.OpikUsage.from_openai_responses_dict,
    ],
    LLMProvider.ANTHROPIC: [opik_usage.OpikUsage.from_anthropic_dict],
    LLMProvider.BEDROCK: [opik_usage.OpikUsage.from_bedrock_dict],
}

def build_opik_usage(
    provider: Union[str, LLMProvider],
    usage: Dict[str, Any],
) -> opik_usage.OpikUsage:
    """Factory function open for extension - new providers can be added."""
    build_functions = _PROVIDER_TO_OPIK_USAGE_BUILDERS[provider]

    for build_function in build_functions:
        try:
            return build_function(usage)
        except Exception:
            continue

    raise ValueError(f"Failed to build OpikUsage for provider {provider}")
```

### Dependency Inversion Principle

- **Use builder functions for creating complex objects**
- **Follow dependency injection principles**
- **Inject dependencies rather than creating them directly**

```python
# ✅ Good: Dependency injection pattern (from streamer.py)
class Streamer:
    def __init__(
        self,
        queue: message_queue.MessageQueue[messages.BaseMessage],
        queue_consumers: List[queue_consumer.QueueConsumer],
        batch_manager: Optional[batch_manager.BatchManager],
        file_upload_manager: base_upload_manager.BaseFileUploadManager,
    ) -> None:
        """Dependencies are injected rather than created internally."""
        self._message_queue = queue
        self._queue_consumers = queue_consumers
        self._batch_manager = batch_manager
        self._file_upload_manager = file_upload_manager

        # Start injected components
        self._start_queue_consumers()
        if self._batch_manager is not None:
            self._batch_manager.start()

# ✅ Good: Factory function that builds dependencies (from streamer_constructors.py)
def construct_online_streamer(
    rest_client: rest_api_client.OpikApi,
    httpx_client: httpx.Client,
    use_batching: bool,
    file_upload_worker_count: int,
    n_consumers: int,
    max_queue_size: int,
) -> streamer.Streamer:
    """Factory function that creates and injects dependencies."""
    message_processor = message_processors.OpikMessageProcessor(rest_client=rest_client)
    file_uploader = upload_manager.FileUploadManager(
        rest_client=rest_client,
        httpx_client=httpx_client,
        worker_count=file_upload_worker_count,
    )

    return construct_streamer(
        message_processor=message_processor,
        file_upload_manager=file_uploader,
        n_consumers=n_consumers,
        use_batching=use_batching,
        max_queue_size=max_queue_size,
    )
```

### Interface Segregation

- **Create focused, specialized interfaces**
- **Avoid large, monolithic interfaces**
- **Group related functionality appropriately**

```python
# ✅ Good: Focused interfaces for different concerns
class ThreadsClient:
    """Focused only on thread operations."""
    def search_threads(self, project_name: Optional[str] = None) -> List[TraceThread]:
        pass
    def log_feedback_scores_to_thread(self, thread_id: str, scores: List[FeedbackScoreDict]):
        pass

# ✅ Good: Specialized client interfaces from OpikApi
class OpikApi:
    def __init__(self, ...):
        # Each client handles a specific domain
        self.datasets = DatasetsClient(client_wrapper=self._client_wrapper)
        self.experiments = ExperimentsClient(client_wrapper=self._client_wrapper)
        self.feedback_definitions = FeedbackDefinitionsClient(client_wrapper=self._client_wrapper)
        self.guardrails = GuardrailsClient(client_wrapper=self._client_wrapper)
```

## Builder and Factory Patterns

### Builder Functions for Complex Objects

```python
# ✅ Good: Builder function pattern (from streamer_constructors.py)
def construct_online_streamer(
    rest_client: rest_api_client.OpikApi,
    httpx_client: httpx.Client,
    use_batching: bool,
    file_upload_worker_count: int,
    n_consumers: int,
    max_queue_size: int,
) -> streamer.Streamer:
    """Builder function that constructs complex objects with dependencies."""
    # Build message processor
    message_processor = message_processors.OpikMessageProcessor(rest_client=rest_client)

    # Build file upload manager
    file_uploader = upload_manager.FileUploadManager(
        rest_client=rest_client,
        httpx_client=httpx_client,
        worker_count=file_upload_worker_count,
    )

    # Use another builder function to construct the final object
    return construct_streamer(
        message_processor=message_processor,
        file_upload_manager=file_uploader,
        n_consumers=n_consumers,
        use_batching=use_batching,
        max_queue_size=max_queue_size,
    )
```

### Factory Pattern for Extensible Creation

```python
# ✅ Good: Factory pattern for provider-specific objects
class OpikUsage(pydantic.BaseModel):
    @classmethod
    def from_openai_completions_dict(cls, usage: Dict[str, Any]) -> "OpikUsage":
        """Factory method for OpenAI format."""
        return cls(
            completion_tokens=usage.get("completion_tokens"),
            prompt_tokens=usage.get("prompt_tokens"),
            total_tokens=usage.get("total_tokens"),
            provider_usage=openai_chat_completions_usage.OpenAICompletionsUsage.from_dict(usage)
        )

    @classmethod
    def from_anthropic_dict(cls, usage: Dict[str, Any]) -> "OpikUsage":
        """Factory method for Anthropic format."""
        return cls(
            completion_tokens=usage.get("output_tokens"),
            prompt_tokens=usage.get("input_tokens"),
            total_tokens=usage.get("input_tokens", 0) + usage.get("output_tokens", 0),
            provider_usage=anthropic_usage.AnthropicUsage.from_dict(usage)
        )
```

## API Consistency

### Backward Compatibility

- **Always look for similar APIs** that already exist and make new ones consistent
- **Maintain backward compatibility** for public interfaces
- **Don't add default parameter values** if not required - defaults should exist in high-level APIs only

```python
# ✅ Good: Consistent API patterns
class Opik:
    def create_experiment(self, name: str, description: Optional[str] = None) -> Experiment:
        """High-level API with appropriate defaults."""
        pass

    def create_dataset(self, name: str, description: Optional[str] = None) -> Dataset:
        """Consistent pattern with experiment creation."""
        pass

    def get_experiment_by_id(self, id: str) -> Experiment:
        """Consistent naming pattern for retrieval."""
        pass

    def get_dataset(self, name: str) -> Dataset:
        """Consistent retrieval pattern."""
        pass

# ❌ Bad: Inconsistent patterns
def create_experiment(name: str, desc: str = None): pass  # Different param name
def fetch_dataset(dataset_name: str): pass               # Different verb
def retrieve_experiment_by_id(exp_id: str): pass         # Different naming
```

### Module Organization

```python
# ✅ Good: Organized by functionality (actual module structure)
opik/
├── api_objects/           # API layer focused on objects
│   ├── opik_client.py    # Main client functionality
│   ├── dataset/          # Dataset-specific operations
│   ├── experiment/       # Experiment-specific operations
│   └── span/             # Span-specific operations
├── integrations/         # Integration-specific modules
│   ├── anthropic/        # Anthropic integration
│   ├── openai/           # OpenAI integration
│   └── langchain/        # LangChain integration
├── evaluation/           # Evaluation functionality
│   ├── metrics/          # Metrics implementations
│   └── engine/           # Evaluation engine
└── message_processing/   # Message processing functionality
    ├── messages.py       # Message definitions
    └── message_processors.py  # Message processing logic

# ❌ Bad: Generic utility modules
utils/
├── helpers.py            # Too generic
├── common.py             # Unclear purpose
└── misc.py               # No clear responsibility
```

## Best Practices

### Meaningful Names

```python
# ✅ Good: Clear, descriptive names
class OpikConfigurator:          # Clear purpose
class GuardrailsTrackDecorator:  # Specific functionality
class ExperimentItemContent:     # Describes the data structure

def build_opik_usage():          # Clear action and result
def create_experiment():         # Standard CRUD naming
def get_current_trace_data():    # Descriptive function name

# ❌ Bad: Unclear or abbreviated names
class OpikConf:                  # Abbreviated
class Tracker:                   # Too generic
class Utils:                     # No specific purpose
```

### Focused Responsibilities

```python
# ✅ Good: Each class has a single, clear responsibility
class MessageProcessor:
    """Only processes messages."""
    def process(self, message: BaseMessage) -> None: pass

class ConfigValidator:
    """Only validates configuration."""
    def validate(self, config: Config) -> bool: pass

class ApiClient:
    """Only handles HTTP communication."""
    def send_request(self, request: Request) -> Response: pass

# ❌ Bad: Mixed responsibilities
class OpikManager:
    """Handles everything - configuration, API calls, validation, processing."""
    def configure(self): pass
    def send_api_request(self): pass
    def validate_data(self): pass
    def process_messages(self): pass
```

### State Management

- **Use internal state effectively** - avoid passing data that's already stored in the object
- **Minimize parameter redundancy** - if data is available via `self`, don't require it as a parameter

## Key References

- [API Design Guidelines](api-design.mdc)
- [Architecture Guidelines](architecture.mdc)
- [Code Structure Guidelines](code-structure.mdc)
- [Error Handling Guidelines](error-handling.mdc)
