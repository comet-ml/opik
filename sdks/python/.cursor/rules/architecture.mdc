---
description: Core library architecture and design patterns for the Python SDK
globs: sdks/python/src/opik/**/*
alwaysApply: false
---
# Python SDK Architecture Guidelines

Comprehensive guidelines for understanding and implementing the core architecture patterns in the Opik Python SDK.

## Core Architecture Patterns

### Three-Layer Architecture

The SDK is organized into 3 distinct layers with clear responsibilities:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Layer 1: Public API                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ   opik.Opik, @opik.track, opik_context                       ‚îÇ
‚îÇ   - User-facing interface                                    ‚îÇ
‚îÇ   - Input validation                                         ‚îÇ
‚îÇ   - Context management                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                            ‚îÇ
              ‚îÇ Observability              ‚îÇ Resource Management
              ‚îÇ (trace/span/feedback)      ‚îÇ (dataset/experiment/
              ‚îÇ                            ‚îÇ  prompt, search, etc.)
              ‚îÇ                            ‚îÇ
              ‚ñº                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Layer 2: Message Processing ‚îÇ  ‚îÇ  API Object Clients      ‚îÇ
‚îÇ  (Observability operations)  ‚îÇ  ‚îÇ  (Resource operations)   ‚îÇ
‚îÇ                              ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ  Streamer                    ‚îÇ  ‚îÇ  Dataset, Experiment,    ‚îÇ
‚îÇ    ‚Üì                         ‚îÇ  ‚îÇ  Prompt, Attachment,     ‚îÇ
‚îÇ  Queue                       ‚îÇ  ‚îÇ  Threads clients         ‚îÇ
‚îÇ    ‚Üì                         ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ  Consumers                   ‚îÇ  ‚îÇ  - Manage state          ‚îÇ
‚îÇ    ‚Üì                         ‚îÇ  ‚îÇ  - Handle complex logic  ‚îÇ
‚îÇ  MessageProcessor            ‚îÇ  ‚îÇ  - Wrap REST calls       ‚îÇ
‚îÇ                              ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ  - Background async          ‚îÇ  ‚îÇ  Delegates to ‚Üì          ‚îÇ
‚îÇ  - Batching                  ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ  - Retry logic               ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ                              ‚îÇ  ‚îÇ                          ‚îÇ
‚îÇ  Delegates to ‚Üì              ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
                ‚îÇ                                ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ       Layer 3: REST API Client                ‚îÇ
              ‚îÇ                                               ‚îÇ
              ‚îÇ  OpikApi (auto-generated from OpenAPI)        ‚îÇ
              ‚îÇ  - HTTP client                                ‚îÇ
              ‚îÇ  - Request/response serialization             ‚îÇ
              ‚îÇ  - Connection pooling                         ‚îÇ
              ‚îÇ                                               ‚îÇ
              ‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê      ‚îÇ
              ‚îÇ  ‚ïë  HTTP requests to Opik Backend      ‚ïë      ‚îÇ
              ‚îÇ  ‚ïë  (External service, not part of SDK)‚ïë      ‚îÇ
              ‚îÇ  ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê      ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Layer Responsibilities**:
- **Layer 1 (Public API)**: What users interact with directly (`opik.Opik`, `@opik.track`)
- **Layer 2 (Message Processing)**: Background workers - **only for observability operations** (trace/span/feedback)
- **API Object Clients**: Intermediate layer for resource management - handle state and complex logic
- **Layer 3 (REST API Client)**: HTTP communication layer (used by both Layer 2 and API Object Clients)
- **Opik Backend**: External service (not part of SDK) that receives HTTP requests

### Layered Architecture Flow

**Flow**: API Objects ‚Üí Message Processing (for non-blocking operations) ‚Üí REST API ‚Üí Backend

```python
# ‚úÖ Good: Layered architecture flow example
from opik.api_objects import opik_client
from opik.message_processing import messages

# API Object layer
client = opik_client.Opik()
client.trace(name="my_trace", input={"query": "test"})

# Message Processing layer (happens automatically in background)
# Creates CreateTraceMessage ‚Üí processed by OpikMessageProcessor

# REST API layer (handled by message processors)
# Calls rest_api_client.OpikApi methods

# Backend layer (external Opik server)
```

### Two Execution Paths

The SDK provides two types of operations with different execution paths:

#### Asynchronous Operations (via Layer 2: Message Processing)

**Observability operations** that use background processing:

| Operation | Purpose | Returns |
|-----------|---------|---------|
| `trace()` | Create/update trace | None (fire-and-forget) |
| `span()` | Create/update span | None (fire-and-forget) |
| `log_traces_feedback_scores()` | Add feedback to traces | None |
| `log_spans_feedback_scores()` | Add feedback to spans | None |
| `experiment.insert()` | Create experiment items | None |
| Attachment uploads | Upload files to S3 | None |

**Characteristics**:
- ‚ö° Non-blocking (returns immediately)
- üì¶ Supports batching (Create messages batch together)
- üîÅ Automatic retries
- ‚ö†Ô∏è Requires `flush()` before app exit

#### Synchronous Operations (via API Object Clients or Direct REST)

**Resource management and query operations** that bypass message processing:

| Category | Operations | Uses |
|----------|-----------|------|
| **Dataset** | `create_dataset()`, `get_dataset()`, `delete_dataset()` | Dataset client |
| **Experiment** | `create_experiment()`, `get_experiment_by_id()` | Experiment client |
| **Prompt** | `create_prompt()`, `get_prompt()`, `update_prompt()` | Prompt client |
| **Search** | `search_traces()`, `search_spans()` | Direct REST |
| **Retrieval** | `get_trace_content()`, `get_span_content()` | Direct REST |
| **Delete** | `delete_traces()`, `delete_*_feedback_score()` | Direct REST |

**Characteristics**:
- üîí Blocking (waits for response)
- ‚úÖ Returns data immediately
- üö´ No batching
- ‚è±Ô∏è No flush needed

### API Object Clients

For complex resource types, intermediate client classes provide:

- **State management**: Dataset items, experiment state, prompt versions
- **Business logic**: Item insertion, versioning, validation
- **Convenience methods**: `dataset.insert()`, `experiment.get_items()`, `prompt.format()`
- **REST abstraction**: Wrap multiple REST calls into higher-level operations

**Examples**:
- `Dataset` (`dataset/dataset.py`) - Manages dataset items, handles insertion/deletion
- `Experiment` (`experiment/experiment.py`) - Tracks experiment items, links to dataset
- `Prompt` (`prompt/prompt.py`) - Manages prompt versions and templating
- `AttachmentClient` (`attachment/client.py`) - Handles file attachments
- `ThreadsClient` (`threads/threads_client.py`) - Manages conversational threads

For simple operations (search, get), `opik.Opik` calls REST client directly without intermediate client.

### Message Processing Architecture

**Flow**: API Objects ‚Üí Message Processing (for non-blocking operations) ‚Üí REST API ‚Üí Backend

```python
# ‚úÖ Good: Message processing flow
from opik.message_processing import messages, message_processors

# 1. API calls create messages
create_trace_message = messages.CreateTraceMessage(...)

# 2. Messages are processed by OpikMessageProcessor
processor = message_processors.OpikMessageProcessor(rest_client)
processor.process(create_trace_message)

# 3. Processor maps message types to handlers
# {
#     messages.CreateTraceMessage: _process_create_trace_message,
#     messages.CreateSpanMessage: _process_create_span_message,
#     messages.AddTraceFeedbackScoresBatchMessage: _process_add_trace_feedback_scores_batch_message,
# }
```

#### Streamer Component

Routes messages to appropriate handlers (queue, batch, or upload):

```python
class Streamer:
    def put(self, message: BaseMessage) -> None:
        """Route message based on type and capabilities"""

        # 1. Check batching support
        if self._batch_manager.message_supports_batching(message):
            self._batch_manager.process_message(message)
            return

        # 2. Check file upload support
        if base_upload_manager.message_supports_upload(message):
            self._file_upload_manager.upload(message)
            return

        # 3. Default: Add to queue
        self._message_queue.put(message)
```

#### Queue and Consumer System

Thread-safe FIFO queue with backpressure handling and worker threads that process messages from the queue.

#### Message Processor

Maps message types to REST API handlers:

```python
class OpikMessageProcessor(BaseMessageProcessor):
    def __init__(self, rest_client: OpikApi):
        self._rest_client = rest_client

        # Map message types to handlers
        self._handlers: Dict[Type, MessageHandler] = {
            CreateTraceMessage: self._process_create_trace_message,
            CreateSpanMessage: self._process_create_span_message,
            UpdateTraceMessage: self._process_update_trace_message,
            UpdateSpanMessage: self._process_update_span_message,
            AddTraceFeedbackScoresBatchMessage: self._process_feedback_scores,
            CreateSpansBatchMessage: self._process_create_spans_batch,
            CreateTraceBatchMessage: self._process_create_traces_batch,
        }
```

### Batching System

#### Why Batching?

Batching reduces overhead by:
1. **Fewer HTTP requests**: 100 spans ‚Üí 1 request
2. **Lower latency**: Amortized network cost
3. **Better throughput**: More efficient use of connections
4. **Reduced backend load**: Fewer requests to process

#### Batch Manager Architecture

```python
class BatchManager:
    def process_message(self, message: BaseMessage) -> None:
        # Find or create batcher for this message type
        batcher = self._get_or_create_batcher(type(message))

        # Add to batch
        batcher.add(message)

        # Check if should flush
        if batcher.should_flush():
            self._flush_batcher(batcher)
```

#### Flush Triggers

1. **Time-based**: Periodic timer (e.g., every 1 second)
2. **Size-based**: Batch reaches size limit (e.g., 100 messages)
3. **Memory-based**: Batch reaches memory limit (e.g., 50MB)
4. **Manual**: User calls `flush()`
5. **Shutdown**: Manager stopping

### Context Storage

```python
# ‚úÖ Good: Using context storage for trace/span lifecycle
import opik.context_storage as context_storage
import opik.opik_context as opik_context

# Set trace data in context
context_storage.set_trace_data(trace_data)

# Update current trace
opik_context.update_current_trace(
    name="updated_name",
    metadata={"key": "value"}
)

# Get current trace data
current_trace = opik_context.get_current_trace_data()
```

**Why contextvars?**
- Automatic isolation across threads
- Works with async/await
- No manual cleanup needed
- Thread-safe by design

## Integration Patterns

### Integration Pattern Selection

```
Library Architecture Analysis:

Does library provide callbacks/hooks?
    ‚îÇ
    ‚îú‚îÄ‚ñ∫ Yes ‚îÄ‚ñ∫ Callbacks reliable and in-context?
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îú‚îÄ‚ñ∫ Yes ‚îÄ‚ñ∫ Pure Callback
    ‚îÇ           ‚îÇ           (LangChain, LlamaIndex, DSPy, Haystack)
    ‚îÇ           ‚îÇ
    ‚îÇ           ‚îî‚îÄ‚ñ∫ No ‚îÄ‚ñ∫ Hybrid (Callback + Patching)
    ‚îÇ                       (ADK)
    ‚îÇ
    ‚îî‚îÄ‚ñ∫ No ‚îÄ‚ñ∫ Method Patching
                (OpenAI, Anthropic, Bedrock, GenAI, AISuite)
```

### Base Decorator Classes

- **Pattern**: Extend base tracking classes for new integrations
- **Example**: `opik.integrations.anthropic` uses tracking decorators
- **Consistency**: Follow established patterns for similar libraries

```python
# ‚úÖ Good: Integration using tracking pattern (anthropic example)
import anthropic
from opik.integrations.anthropic import track_anthropic

client = anthropic.Anthropic(api_key="your_key")
tracked_client = track_anthropic(client, project_name="my_project")

# Methods are automatically tracked
response = tracked_client.messages.create(
    model="claude-3-sonnet-20240229",
    messages=[{"role": "user", "content": "Hello"}]
)
```

### Callback-Based Integrations

- **Pattern**: Use callback pattern when library supports it
- **Example**: `opik.integrations.langchain` uses `BaseTracer`
- **Implementation**: Extend library's callback/tracer classes

```python
# ‚úÖ Good: Callback-based integration (langchain example)
from langchain_core.tracers import BaseTracer
from opik.integrations.langchain import OpikTracer

class OpikTracer(BaseTracer):
    def __init__(self, project_name: Optional[str] = None):
        super().__init__()
        self._project_name = project_name

    def _persist_run(self, run: Run) -> None:
        # Process run data and create spans/traces
        pass
```

### Decorator-Based Tracking

```python
# ‚úÖ Good: Using @opik.track decorator
import opik

@opik.track
def my_llm_function(prompt: str) -> str:
    # Function automatically creates span
    # Input/output automatically captured
    return process_prompt(prompt)

# ‚úÖ Good: Nested tracking with decorators
@opik.track
def complex_function(input_data: dict) -> dict:
    # Create nested spans by decorating helper functions
    # top-level tracked function also creates a trace, not just a span
    preprocessed = preprocess_data(input_data)
    result = process_data(preprocessed)
    return result

@opik.track
def preprocess_data(data: dict) -> dict:
    # This function automatically creates a nested span
    return {"processed": data}

@opik.track
def process_data(data: dict) -> dict:
    # This function also creates a nested span
    return {"result": data["processed"]}

complex_function({"some-key": "some-value"})
```

## Evaluation Architecture

### Metrics Implementation

- **Pattern**: Implement evaluation metrics consistent with existing logic
- **Base Class**: Extend `opik.evaluation.metrics.BaseMetric`
- **Error Handling**: Use `opik.exceptions.MetricComputationError` for errors

```python
# ‚úÖ Good: Metric implementation pattern
from opik.evaluation.metrics import BaseMetric, score_result
from opik.exceptions import MetricComputationError

class CustomMetric(BaseMetric):
    def __init__(self, threshold: float = 0.5):
        super().__init__()
        self.threshold = threshold

    def score(self, input: str, output: str, context: str = None) -> score_result.ScoreResult:
        try:
            # Metric computation logic
            score_value = compute_score(input, output, context)
            return score_result.ScoreResult(
                value=score_value,
                name=self.name,
                reason="Custom metric evaluation"
            )
        except Exception as e:
            raise MetricComputationError(f"Failed to compute metric: {e}")
```

### Evaluation Functions

```python
# ‚úÖ Good: Evaluation function pattern
from opik.evaluation import evaluate

def custom_evaluate_function(dataset, model_fn, metrics):
    """Evaluation function following established patterns."""
    return evaluate(
        dataset=dataset,
        task=model_fn,
        scoring_metrics=metrics,
        experiment_name="custom_evaluation"
    )
```

### Evaluation Engine

The evaluation engine orchestrates systematic testing and provides 4 evaluation methods:

| Method | Dataset | Task Function | Data Source | Logs To |
|--------|---------|---------------|-------------|---------|
| `evaluate()` | ‚úÖ Required | ‚úÖ Required | Executes task on dataset | Experiment items |
| `evaluate_prompt()` | ‚úÖ Required | ‚ùå Auto-generated | Executes prompt on dataset | Experiment items |
| `evaluate_experiment()` | ‚ùå From experiment | ‚ùå Not needed | Existing experiment data | Experiment items (update) |
| `evaluate_threads()` | ‚ùå Not needed | ‚ùå Not needed | Existing traces from backend | Traces (feedback scores) |

## Best Practices

### Architecture Principles

1. **Separation of Concerns**: Keep API, message processing, and REST layers distinct
2. **Non-blocking Operations**: Use background processing for observability operations
3. **Synchronous Evaluation**: Evaluation framework waits for completion (unlike tracing)
4. **Context Isolation**: Use proper context management for concurrent operations
5. **Error Propagation**: Handle errors appropriately at each layer

### Integration Guidelines

1. **Follow Existing Patterns**: Study similar integrations before implementing new ones
2. **Use Library Callbacks**: Prefer callback patterns when available
3. **Maintain Consistency**: Keep parameter names and patterns consistent
4. **Handle Provider Specifics**: Account for library-specific behaviors
5. **Idempotent Tracking**: Prevent double-wrapping with markers

### Performance Considerations

```python
# ‚úÖ Good: Proper client lifecycle management
client = opik.Opik()
# Use client for operations
client.flush()  # Ensure all data is sent
```

### Evaluation Guidelines

1. **Synchronous Design**: Evaluation waits for results (unlike tracing)
2. **Parallel Execution**: Use thread pools for performance
3. **Experiment Tracking**: Automatic linkage to backend experiments
4. **Metric Composability**: Mix heuristic and LLM-based metrics
5. **Error Resilience**: Individual failures don't stop evaluation

## Key References

- [API and Data Flow Design Document](API_AND_DATA_FLOW.md)
- [API Design Guidelines](api-design.mdc)
- [Error Handling Guidelines](error-handling.mdc)
- [Code Structure Guidelines](code-structure.mdc)
- [Testing Guidelines](test-organization.mdc)
- [Integrations Design Document](INTEGRATIONS.md)
- [Evaluation Design Document](EVALUATION.md)
