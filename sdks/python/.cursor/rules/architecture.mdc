---
description: Core library architecture and design patterns for the Python SDK
globs: sdks/python/src/opik/**/*
alwaysApply: false
---
# Python SDK Architecture Guidelines

Comprehensive guidelines for understanding and implementing the core architecture patterns in the Opik Python SDK.

## Core Architecture Patterns

### Three-Layer Architecture

The SDK is organized into 3 distinct layers with clear responsibilities:

```
┌──────────────────────────────────────────────────────────────┐
│                    Layer 1: Public API                       │
│                                                              │
│   opik.Opik, @opik.track, opik_context                       │
│   - User-facing interface                                    │
│   - Input validation                                         │
│   - Context management                                       │
└─────────────┬────────────────────────────┬───────────────────┘
              │                            │
              │ Observability              │ Resource Management
              │ (trace/span/feedback)      │ (dataset/experiment/
              │                            │  prompt, search, etc.)
              │                            │
              ▼                            ▼
┌──────────────────────────────┐  ┌──────────────────────────┐
│  Layer 2: Message Processing │  │  API Object Clients      │
│  (Observability operations)  │  │  (Resource operations)   │
│                              │  │                          │
│  Streamer                    │  │  Dataset, Experiment,    │
│    ↓                         │  │  Prompt, Attachment,     │
│  Queue                       │  │  Threads clients         │
│    ↓                         │  │                          │
│  Consumers                   │  │  - Manage state          │
│    ↓                         │  │  - Handle complex logic  │
│  MessageProcessor            │  │  - Wrap REST calls       │
│                              │  │                          │
│  - Background async          │  │  Delegates to ↓          │
│  - Batching                  │  │                          │
│  - Retry logic               │  │                          │
│                              │  │                          │
│  Delegates to ↓              │  └──────────────┬───────────┘
└───────────────┬──────────────┘                 │
                │                                │
                └────────────────┬───────────────┘
                                 ▼
              ┌───────────────────────────────────────────────┐
              │       Layer 3: REST API Client                │
              │                                               │
              │  OpikApi (auto-generated from OpenAPI)        │
              │  - HTTP client                                │
              │  - Request/response serialization             │
              │  - Connection pooling                         │
              │                                               │
              │  ═══════════════════════════════════════      │
              │  ║  HTTP requests to Opik Backend      ║      │
              │  ║  (External service, not part of SDK)║      │
              │  ═══════════════════════════════════════      │
              └───────────────────────────────────────────────┘
```

**Layer Responsibilities**:
- **Layer 1 (Public API)**: What users interact with directly (`opik.Opik`, `@opik.track`)
- **Layer 2 (Message Processing)**: Background workers - **only for observability operations** (trace/span/feedback)
- **API Object Clients**: Intermediate layer for resource management - handle state and complex logic
- **Layer 3 (REST API Client)**: HTTP communication layer (used by both Layer 2 and API Object Clients)
- **Opik Backend**: External service (not part of SDK) that receives HTTP requests

### Layered Architecture Flow

**Flow**: API Objects → Message Processing (for non-blocking operations) → REST API → Backend

```python
# ✅ Good: Layered architecture flow example
from opik.api_objects import opik_client
from opik.message_processing import messages

# API Object layer
client = opik_client.Opik()
client.trace(name="my_trace", input={"query": "test"})

# Message Processing layer (happens automatically in background)
# Creates CreateTraceMessage → processed by OpikMessageProcessor

# REST API layer (handled by message processors)
# Calls rest_api_client.OpikApi methods

# Backend layer (external Opik server)
```

### Two Execution Paths

The SDK provides two types of operations with different execution paths:

#### Asynchronous Operations (via Layer 2: Message Processing)

**Observability operations** that use background processing:

| Operation | Purpose | Returns |
|-----------|---------|---------|
| `trace()` | Create/update trace | None (fire-and-forget) |
| `span()` | Create/update span | None (fire-and-forget) |
| `log_traces_feedback_scores()` | Add feedback to traces | None |
| `log_spans_feedback_scores()` | Add feedback to spans | None |
| `experiment.insert()` | Create experiment items | None |
| Attachment uploads | Upload files to S3 | None |

**Characteristics**:
- ⚡ Non-blocking (returns immediately)
- 📦 Supports batching (Create messages batch together)
- 🔁 Automatic retries
- ⚠️ Requires `flush()` before app exit

#### Synchronous Operations (via API Object Clients or Direct REST)

**Resource management and query operations** that bypass message processing:

| Category | Operations | Uses |
|----------|-----------|------|
| **Dataset** | `create_dataset()`, `get_dataset()`, `delete_dataset()` | Dataset client |
| **Experiment** | `create_experiment()`, `get_experiment_by_id()` | Experiment client |
| **Prompt** | `create_prompt()`, `get_prompt()`, `update_prompt()` | Prompt client |
| **Search** | `search_traces()`, `search_spans()` | Direct REST |
| **Retrieval** | `get_trace_content()`, `get_span_content()` | Direct REST |
| **Delete** | `delete_traces()`, `delete_*_feedback_score()` | Direct REST |

**Characteristics**:
- 🔒 Blocking (waits for response)
- ✅ Returns data immediately
- 🚫 No batching
- ⏱️ No flush needed

### API Object Clients

For complex resource types, intermediate client classes provide:

- **State management**: Dataset items, experiment state, prompt versions
- **Business logic**: Item insertion, versioning, validation
- **Convenience methods**: `dataset.insert()`, `experiment.get_items()`, `prompt.format()`
- **REST abstraction**: Wrap multiple REST calls into higher-level operations

**Examples**:
- `Dataset` (`dataset/dataset.py`) - Manages dataset items, handles insertion/deletion
- `Experiment` (`experiment/experiment.py`) - Tracks experiment items, links to dataset
- `Prompt` (`prompt/prompt.py`) - Manages prompt versions and templating
- `AttachmentClient` (`attachment/client.py`) - Handles file attachments
- `ThreadsClient` (`threads/threads_client.py`) - Manages conversational threads

For simple operations (search, get), `opik.Opik` calls REST client directly without intermediate client.

### Message Processing Architecture

**Flow**: API Objects → Message Processing (for non-blocking operations) → REST API → Backend

```python
# ✅ Good: Message processing flow
from opik.message_processing import messages, message_processors

# 1. API calls create messages
create_trace_message = messages.CreateTraceMessage(...)

# 2. Messages are processed by OpikMessageProcessor
processor = message_processors.OpikMessageProcessor(rest_client)
processor.process(create_trace_message)

# 3. Processor maps message types to handlers
# {
#     messages.CreateTraceMessage: _process_create_trace_message,
#     messages.CreateSpanMessage: _process_create_span_message,
#     messages.AddTraceFeedbackScoresBatchMessage: _process_add_trace_feedback_scores_batch_message,
# }
```

#### Streamer Component

Routes messages to appropriate handlers (queue, batch, or upload):

```python
class Streamer:
    def put(self, message: BaseMessage) -> None:
        """Route message based on type and capabilities"""

        # 1. Check batching support
        if self._batch_manager.message_supports_batching(message):
            self._batch_manager.process_message(message)
            return

        # 2. Check file upload support
        if base_upload_manager.message_supports_upload(message):
            self._file_upload_manager.upload(message)
            return

        # 3. Default: Add to queue
        self._message_queue.put(message)
```

#### Queue and Consumer System

Thread-safe FIFO queue with backpressure handling and worker threads that process messages from the queue.

#### Message Processor

Maps message types to REST API handlers:

```python
class OpikMessageProcessor(BaseMessageProcessor):
    def __init__(self, rest_client: OpikApi):
        self._rest_client = rest_client

        # Map message types to handlers
        self._handlers: Dict[Type, MessageHandler] = {
            CreateTraceMessage: self._process_create_trace_message,
            CreateSpanMessage: self._process_create_span_message,
            UpdateTraceMessage: self._process_update_trace_message,
            UpdateSpanMessage: self._process_update_span_message,
            AddTraceFeedbackScoresBatchMessage: self._process_feedback_scores,
            CreateSpansBatchMessage: self._process_create_spans_batch,
            CreateTraceBatchMessage: self._process_create_traces_batch,
        }
```

### Batching System

#### Why Batching?

Batching reduces overhead by:
1. **Fewer HTTP requests**: 100 spans → 1 request
2. **Lower latency**: Amortized network cost
3. **Better throughput**: More efficient use of connections
4. **Reduced backend load**: Fewer requests to process

#### Batch Manager Architecture

```python
class BatchManager:
    def process_message(self, message: BaseMessage) -> None:
        # Find or create batcher for this message type
        batcher = self._get_or_create_batcher(type(message))

        # Add to batch
        batcher.add(message)

        # Check if should flush
        if batcher.should_flush():
            self._flush_batcher(batcher)
```

#### Flush Triggers

1. **Time-based**: Periodic timer (e.g., every 1 second)
2. **Size-based**: Batch reaches size limit (e.g., 100 messages)
3. **Memory-based**: Batch reaches memory limit (e.g., 50MB)
4. **Manual**: User calls `flush()`
5. **Shutdown**: Manager stopping

### Context Storage

```python
# ✅ Good: Using context storage for trace/span lifecycle
import opik.context_storage as context_storage
import opik.opik_context as opik_context

# Set trace data in context
context_storage.set_trace_data(trace_data)

# Update current trace
opik_context.update_current_trace(
    name="updated_name",
    metadata={"key": "value"}
)

# Get current trace data
current_trace = opik_context.get_current_trace_data()
```

**Why contextvars?**
- Automatic isolation across threads
- Works with async/await
- No manual cleanup needed
- Thread-safe by design

## Integration Patterns

### Integration Pattern Selection

```
Library Architecture Analysis:

Does library provide callbacks/hooks?
    │
    ├─► Yes ─► Callbacks reliable and in-context?
    │           │
    │           ├─► Yes ─► Pure Callback
    │           │           (LangChain, LlamaIndex, DSPy, Haystack)
    │           │
    │           └─► No ─► Hybrid (Callback + Patching)
    │                       (ADK)
    │
    └─► No ─► Method Patching
                (OpenAI, Anthropic, Bedrock, GenAI, AISuite)
```

### Base Decorator Classes

- **Pattern**: Extend base tracking classes for new integrations
- **Example**: `opik.integrations.anthropic` uses tracking decorators
- **Consistency**: Follow established patterns for similar libraries

```python
# ✅ Good: Integration using tracking pattern (anthropic example)
import anthropic
from opik.integrations.anthropic import track_anthropic

client = anthropic.Anthropic(api_key="your_key")
tracked_client = track_anthropic(client, project_name="my_project")

# Methods are automatically tracked
response = tracked_client.messages.create(
    model="claude-3-sonnet-20240229",
    messages=[{"role": "user", "content": "Hello"}]
)
```

### Callback-Based Integrations

- **Pattern**: Use callback pattern when library supports it
- **Example**: `opik.integrations.langchain` uses `BaseTracer`
- **Implementation**: Extend library's callback/tracer classes

```python
# ✅ Good: Callback-based integration (langchain example)
from langchain_core.tracers import BaseTracer
from opik.integrations.langchain import OpikTracer

class OpikTracer(BaseTracer):
    def __init__(self, project_name: Optional[str] = None):
        super().__init__()
        self._project_name = project_name

    def _persist_run(self, run: Run) -> None:
        # Process run data and create spans/traces
        pass
```

### Decorator-Based Tracking

```python
# ✅ Good: Using @opik.track decorator
import opik

@opik.track
def my_llm_function(prompt: str) -> str:
    # Function automatically creates span
    # Input/output automatically captured
    return process_prompt(prompt)

# ✅ Good: Nested tracking with decorators
@opik.track
def complex_function(input_data: dict) -> dict:
    # Create nested spans by decorating helper functions
    # top-level tracked function also creates a trace, not just a span
    preprocessed = preprocess_data(input_data)
    result = process_data(preprocessed)
    return result

@opik.track
def preprocess_data(data: dict) -> dict:
    # This function automatically creates a nested span
    return {"processed": data}

@opik.track
def process_data(data: dict) -> dict:
    # This function also creates a nested span
    return {"result": data["processed"]}

complex_function({"some-key": "some-value"})
```

## Evaluation Architecture

### Metrics Implementation

- **Pattern**: Implement evaluation metrics consistent with existing logic
- **Base Class**: Extend `opik.evaluation.metrics.BaseMetric`
- **Error Handling**: Use `opik.exceptions.MetricComputationError` for errors

```python
# ✅ Good: Metric implementation pattern
from opik.evaluation.metrics import BaseMetric, score_result
from opik.exceptions import MetricComputationError

class CustomMetric(BaseMetric):
    def __init__(self, threshold: float = 0.5):
        super().__init__()
        self.threshold = threshold

    def score(self, input: str, output: str, context: str = None) -> score_result.ScoreResult:
        try:
            # Metric computation logic
            score_value = compute_score(input, output, context)
            return score_result.ScoreResult(
                value=score_value,
                name=self.name,
                reason="Custom metric evaluation"
            )
        except Exception as e:
            raise MetricComputationError(f"Failed to compute metric: {e}")
```

### Evaluation Functions

```python
# ✅ Good: Evaluation function pattern
from opik.evaluation import evaluate

def custom_evaluate_function(dataset, model_fn, metrics):
    """Evaluation function following established patterns."""
    return evaluate(
        dataset=dataset,
        task=model_fn,
        scoring_metrics=metrics,
        experiment_name="custom_evaluation"
    )
```

### Evaluation Engine

The evaluation engine orchestrates systematic testing and provides 4 evaluation methods:

| Method | Dataset | Task Function | Data Source | Logs To |
|--------|---------|---------------|-------------|---------|
| `evaluate()` | ✅ Required | ✅ Required | Executes task on dataset | Experiment items |
| `evaluate_prompt()` | ✅ Required | ❌ Auto-generated | Executes prompt on dataset | Experiment items |
| `evaluate_experiment()` | ❌ From experiment | ❌ Not needed | Existing experiment data | Experiment items (update) |
| `evaluate_threads()` | ❌ Not needed | ❌ Not needed | Existing traces from backend | Traces (feedback scores) |

## Best Practices

### Architecture Principles

1. **Separation of Concerns**: Keep API, message processing, and REST layers distinct
2. **Non-blocking Operations**: Use background processing for observability operations
3. **Synchronous Evaluation**: Evaluation framework waits for completion (unlike tracing)
4. **Context Isolation**: Use proper context management for concurrent operations
5. **Error Propagation**: Handle errors appropriately at each layer

### Integration Guidelines

1. **Follow Existing Patterns**: Study similar integrations before implementing new ones
2. **Use Library Callbacks**: Prefer callback patterns when available
3. **Maintain Consistency**: Keep parameter names and patterns consistent
4. **Handle Provider Specifics**: Account for library-specific behaviors
5. **Idempotent Tracking**: Prevent double-wrapping with markers

### Performance Considerations

```python
# ✅ Good: Proper client lifecycle management
client = opik.Opik()
# Use client for operations
client.flush()  # Ensure all data is sent
```

### Evaluation Guidelines

1. **Synchronous Design**: Evaluation waits for results (unlike tracing)
2. **Parallel Execution**: Use thread pools for performance
3. **Experiment Tracking**: Automatic linkage to backend experiments
4. **Metric Composability**: Mix heuristic and LLM-based metrics
5. **Error Resilience**: Individual failures don't stop evaluation

## Key References

- [API and Data Flow Design Document](API_AND_DATA_FLOW.md)
- [API Design Guidelines](api-design.mdc)
- [Error Handling Guidelines](error-handling.mdc)
- [Code Structure Guidelines](code-structure.mdc)
- [Testing Guidelines](test-organization.mdc)
- [Integrations Design Document](INTEGRATIONS.md)
- [Evaluation Design Document](EVALUATION.md)
