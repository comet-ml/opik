// This file was auto-generated by Fern from our API Definition.

import type { BaseClientOptions, BaseRequestOptions } from "../../../../BaseClient.js";
import { type NormalizedClientOptions, normalizeClientOptions } from "../../../../BaseClient.js";
import { mergeHeaders, mergeOnlyDefinedHeaders } from "../../../../core/headers.js";
import * as core from "../../../../core/index.js";
import * as environments from "../../../../environments.js";
import { handleNonStatusCodeError } from "../../../../errors/handleNonStatusCodeError.js";
import * as errors from "../../../../errors/index.js";
import * as serializers from "../../../../serialization/index.js";
import * as OpikApi from "../../../index.js";

export declare namespace LlmProviderKeyClient {
    export type Options = BaseClientOptions;

    export interface RequestOptions extends BaseRequestOptions {}
}

/**
 * LLM Provider Key
 */
export class LlmProviderKeyClient {
    protected readonly _options: NormalizedClientOptions<LlmProviderKeyClient.Options>;

    constructor(options: LlmProviderKeyClient.Options = {}) {
        this._options = normalizeClientOptions(options);
    }

    /**
     * Delete LLM Provider's ApiKeys batch
     *
     * @param {OpikApi.BatchDelete} request
     * @param {LlmProviderKeyClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmProviderKey.deleteLlmProviderApiKeysBatch({
     *         ids: ["ids"]
     *     })
     */
    public deleteLlmProviderApiKeysBatch(
        request: OpikApi.BatchDelete,
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(this.__deleteLlmProviderApiKeysBatch(request, requestOptions));
    }

    private async __deleteLlmProviderApiKeysBatch(
        request: OpikApi.BatchDelete,
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "Comet-Workspace": requestOptions?.workspaceName ?? this._options?.workspaceName,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.OpikApiEnvironment.Default,
                "v1/private/llm-provider-key/delete",
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: requestOptions?.queryParams,
            requestType: "json",
            body: serializers.BatchDelete.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
                omitUndefined: true,
            }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            withCredentials: true,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.OpikApiError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "POST",
            "/v1/private/llm-provider-key/delete",
        );
    }

    /**
     * Find LLM Provider's ApiKeys
     *
     * @param {LlmProviderKeyClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @example
     *     await client.llmProviderKey.findLlmProviderKeys()
     */
    public findLlmProviderKeys(
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): core.HttpResponsePromise<OpikApi.ProviderApiKeyPagePublic> {
        return core.HttpResponsePromise.fromPromise(this.__findLlmProviderKeys(requestOptions));
    }

    private async __findLlmProviderKeys(
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): Promise<core.WithRawResponse<OpikApi.ProviderApiKeyPagePublic>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "Comet-Workspace": requestOptions?.workspaceName ?? this._options?.workspaceName,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.OpikApiEnvironment.Default,
                "v1/private/llm-provider-key",
            ),
            method: "GET",
            headers: _headers,
            queryParameters: requestOptions?.queryParams,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            withCredentials: true,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.ProviderApiKeyPagePublic.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    skipValidation: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            throw new errors.OpikApiError({
                statusCode: _response.error.statusCode,
                body: _response.error.body,
                rawResponse: _response.rawResponse,
            });
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "GET", "/v1/private/llm-provider-key");
    }

    /**
     * Store LLM Provider's ApiKey
     *
     * @param {OpikApi.ProviderApiKeyWrite} request
     * @param {LlmProviderKeyClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link OpikApi.UnauthorizedError}
     * @throws {@link OpikApi.ForbiddenError}
     *
     * @example
     *     await client.llmProviderKey.storeLlmProviderApiKey({
     *         provider: "openai"
     *     })
     */
    public storeLlmProviderApiKey(
        request: OpikApi.ProviderApiKeyWrite,
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(this.__storeLlmProviderApiKey(request, requestOptions));
    }

    private async __storeLlmProviderApiKey(
        request: OpikApi.ProviderApiKeyWrite,
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "Comet-Workspace": requestOptions?.workspaceName ?? this._options?.workspaceName,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.OpikApiEnvironment.Default,
                "v1/private/llm-provider-key",
            ),
            method: "POST",
            headers: _headers,
            contentType: "application/json",
            queryParameters: requestOptions?.queryParams,
            requestType: "json",
            body: serializers.ProviderApiKeyWrite.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
                omitUndefined: true,
            }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            withCredentials: true,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 401:
                    throw new OpikApi.UnauthorizedError(_response.error.body, _response.rawResponse);
                case 403:
                    throw new OpikApi.ForbiddenError(
                        serializers.ErrorMessage.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                default:
                    throw new errors.OpikApiError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(_response.error, _response.rawResponse, "POST", "/v1/private/llm-provider-key");
    }

    /**
     * Get LLM Provider's ApiKey by id
     *
     * @param {string} id
     * @param {OpikApi.GetLlmProviderApiKeyByIdRequest} request
     * @param {LlmProviderKeyClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link OpikApi.NotFoundError}
     *
     * @example
     *     await client.llmProviderKey.getLlmProviderApiKeyById("id")
     */
    public getLlmProviderApiKeyById(
        id: string,
        request: OpikApi.GetLlmProviderApiKeyByIdRequest = {},
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): core.HttpResponsePromise<OpikApi.ProviderApiKeyPublic> {
        return core.HttpResponsePromise.fromPromise(this.__getLlmProviderApiKeyById(id, request, requestOptions));
    }

    private async __getLlmProviderApiKeyById(
        id: string,
        _request: OpikApi.GetLlmProviderApiKeyByIdRequest = {},
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): Promise<core.WithRawResponse<OpikApi.ProviderApiKeyPublic>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "Comet-Workspace": requestOptions?.workspaceName ?? this._options?.workspaceName,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.OpikApiEnvironment.Default,
                `v1/private/llm-provider-key/${core.url.encodePathParam(id)}`,
            ),
            method: "GET",
            headers: _headers,
            queryParameters: requestOptions?.queryParams,
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            withCredentials: true,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return {
                data: serializers.ProviderApiKeyPublic.parseOrThrow(_response.body, {
                    unrecognizedObjectKeys: "passthrough",
                    allowUnrecognizedUnionMembers: true,
                    allowUnrecognizedEnumValues: true,
                    skipValidation: true,
                    breadcrumbsPrefix: ["response"],
                }),
                rawResponse: _response.rawResponse,
            };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 404:
                    throw new OpikApi.NotFoundError(_response.error.body, _response.rawResponse);
                default:
                    throw new errors.OpikApiError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "GET",
            "/v1/private/llm-provider-key/{id}",
        );
    }

    /**
     * Update LLM Provider's ApiKey
     *
     * @param {string} id
     * @param {OpikApi.ProviderApiKeyUpdate} request
     * @param {LlmProviderKeyClient.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link OpikApi.UnauthorizedError}
     * @throws {@link OpikApi.ForbiddenError}
     * @throws {@link OpikApi.NotFoundError}
     *
     * @example
     *     await client.llmProviderKey.updateLlmProviderApiKey("id")
     */
    public updateLlmProviderApiKey(
        id: string,
        request: OpikApi.ProviderApiKeyUpdate = {},
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): core.HttpResponsePromise<void> {
        return core.HttpResponsePromise.fromPromise(this.__updateLlmProviderApiKey(id, request, requestOptions));
    }

    private async __updateLlmProviderApiKey(
        id: string,
        request: OpikApi.ProviderApiKeyUpdate = {},
        requestOptions?: LlmProviderKeyClient.RequestOptions,
    ): Promise<core.WithRawResponse<void>> {
        const _headers: core.Fetcher.Args["headers"] = mergeHeaders(
            this._options?.headers,
            mergeOnlyDefinedHeaders({
                "Comet-Workspace": requestOptions?.workspaceName ?? this._options?.workspaceName,
            }),
            requestOptions?.headers,
        );
        const _response = await core.fetcher({
            url: core.url.join(
                (await core.Supplier.get(this._options.baseUrl)) ??
                    (await core.Supplier.get(this._options.environment)) ??
                    environments.OpikApiEnvironment.Default,
                `v1/private/llm-provider-key/${core.url.encodePathParam(id)}`,
            ),
            method: "PATCH",
            headers: _headers,
            contentType: "application/json",
            queryParameters: requestOptions?.queryParams,
            requestType: "json",
            body: serializers.ProviderApiKeyUpdate.jsonOrThrow(request, {
                unrecognizedObjectKeys: "strip",
                omitUndefined: true,
            }),
            timeoutMs: (requestOptions?.timeoutInSeconds ?? this._options?.timeoutInSeconds ?? 60) * 1000,
            maxRetries: requestOptions?.maxRetries ?? this._options?.maxRetries,
            withCredentials: true,
            abortSignal: requestOptions?.abortSignal,
            fetchFn: this._options?.fetch,
            logging: this._options.logging,
        });
        if (_response.ok) {
            return { data: undefined, rawResponse: _response.rawResponse };
        }

        if (_response.error.reason === "status-code") {
            switch (_response.error.statusCode) {
                case 401:
                    throw new OpikApi.UnauthorizedError(_response.error.body, _response.rawResponse);
                case 403:
                    throw new OpikApi.ForbiddenError(
                        serializers.ErrorMessage.parseOrThrow(_response.error.body, {
                            unrecognizedObjectKeys: "passthrough",
                            allowUnrecognizedUnionMembers: true,
                            allowUnrecognizedEnumValues: true,
                            skipValidation: true,
                            breadcrumbsPrefix: ["response"],
                        }),
                        _response.rawResponse,
                    );
                case 404:
                    throw new OpikApi.NotFoundError(_response.error.body, _response.rawResponse);
                default:
                    throw new errors.OpikApiError({
                        statusCode: _response.error.statusCode,
                        body: _response.error.body,
                        rawResponse: _response.rawResponse,
                    });
            }
        }

        return handleNonStatusCodeError(
            _response.error,
            _response.rawResponse,
            "PATCH",
            "/v1/private/llm-provider-key/{id}",
        );
    }
}
